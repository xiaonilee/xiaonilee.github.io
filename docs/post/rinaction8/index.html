<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 8. Regression - xiaoni&#39;s blog</title>
  

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="Xiaoni" />
  <meta name="description" content="Notebook of Reading Books: R in Action_Chapter 8.
" />

  <meta name="keywords" content="xiaonili, xiaonilee, xiaoni" />






<meta name="generator" content="Hugo 0.79.0" />


<link rel="canonical" href="https://xiaonilee.github.io/post/rinaction8/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.f1e506a781bf25d33ffc18aa6b4e972a965c58049d27d4f92b7db2e9bf28e4bf.css" integrity="sha256-8eUGp4G/JdM//Biqa06XKpZcWASdJ9T5K32y6b8o5L8=" media="screen" crossorigin="anonymous">



<link href="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.15.1/css/all.css" rel="stylesheet">
<script src="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.15.1/js/all.js"></script>




<meta property="og:title" content="Chapter 8. Regression" />
<meta property="og:description" content="Notebook of Reading Books: R in Action_Chapter 8." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://xiaonilee.github.io/post/rinaction8/" />
<meta property="article:published_time" content="2020-10-29T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-10-29T00:00:00+00:00" />
<meta itemprop="name" content="Chapter 8. Regression">
<meta itemprop="description" content="Notebook of Reading Books: R in Action_Chapter 8.">
<meta itemprop="datePublished" content="2020-10-29T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-10-29T00:00:00+00:00" />
<meta itemprop="wordCount" content="3260">



<meta itemprop="keywords" content="R,R in Action,Bioinformatics,Book," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Chapter 8. Regression"/>
<meta name="twitter:description" content="Notebook of Reading Books: R in Action_Chapter 8."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-177860608-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Xiaoni's Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/">Home</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/post/">Archives</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/categories/">Categories</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/tags/">Tags</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/about/">About Me</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          <div class="mobile-menu-parent">
            <span class="mobile-submenu-open"></span>
            <a href="https://xiaonilee.github.io/">
              docs
            </a>
          </div>
          <ul class="mobile-submenu-list">
            
              <li>
                <a href="https://xiaonilee.github.io/post/rinactionmap/">Book: R in Action</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/firebrowse/">FireBrowse Notebook</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/gdc/">GDC Notebook</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/gscalite/">GSCALite: Gene Set Cancer Analysis</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/localxenadatahub/">Local UCSC Xena Data Hub</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/oncolnc/">OncoLnc: A straightforward Tool</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/hmwk10/">R Notebook : Application Exercises</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/ggplot2/">R Notebook : ggplot2</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/tricktcga/">R re-analysis in TCGA</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/tensorflow201/">TensorFlow2 class1: Iris</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/tensorflow202/">TensorFlow2 class2: 数据网络优化</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/tissgdb/">TissGDB: tissue-specific gene database in cancer</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/genomicsignatures/">UCSC Xena Features: Genomic Signatures</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/loaddata/">UCSC Xena: Load Data From Public Database</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/privatepublictogether/">UCSC Xena: Private and Public Data Put Together</a>
              </li>
            
          </ul>
        
      </li>
    

    
  </ul>
</nav>


  
    






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

  

  

  

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/" class="logo">
    
      Xiaoni's Blog
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/">Home</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/post/">Archives</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/categories/">Categories</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/tags/">Tags</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://xiaonilee.github.io/about/">About Me</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          <a class="menu-item-link menu-parent" href="https://xiaonilee.github.io/">docs</a>
          <ul class="submenu" >
            
              <li>
                <a href="https://xiaonilee.github.io/post/rinactionmap/">Book: R in Action</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/firebrowse/">FireBrowse Notebook</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/gdc/">GDC Notebook</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/gscalite/">GSCALite: Gene Set Cancer Analysis</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/localxenadatahub/">Local UCSC Xena Data Hub</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/oncolnc/">OncoLnc: A straightforward Tool</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/hmwk10/">R Notebook : Application Exercises</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/ggplot2/">R Notebook : ggplot2</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/tricktcga/">R re-analysis in TCGA</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/tensorflow201/">TensorFlow2 class1: Iris</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/tensorflow202/">TensorFlow2 class2: 数据网络优化</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/tissgdb/">TissGDB: tissue-specific gene database in cancer</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/genomicsignatures/">UCSC Xena Features: Genomic Signatures</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/loaddata/">UCSC Xena: Load Data From Public Database</a>
              </li>
            
              <li>
                <a href="https://xiaonilee.github.io/post/privatepublictogether/">UCSC Xena: Private and Public Data Put Together</a>
              </li>
            
          </ul>

        

      </li>
    

    
    

    
  </ul>
</nav>

  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          <article class="post bg-white">
    
    <header class="post-header">
      <h1 class="post-title">Chapter 8. Regression</h1>
      
      <div class="post-meta">
        <time datetime="2020-10-29" class="post-time">
          2020-10-29
        </time>
        <div class="post-category">
            <a href="https://xiaonilee.github.io/categories/r/"> R </a>
            <a href="https://xiaonilee.github.io/categories/bioinformatics/"> Bioinformatics </a>
            
          </div>
        

        
        

        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Table of Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#this-chapter-covers">This chapter covers</a>
      <ul>
        <li><a href="#81-the-many-faces-of-regression">8.1. The many faces of regression</a></li>
        <li><a href="#82-ols-regression">8.2. OLS regression</a></li>
        <li><a href="#83-regression-diagnostics">8.3. Regression diagnostics</a></li>
        <li><a href="#84-unusual-observations">8.4. Unusual observations</a></li>
        <li><a href="#85-corrective-measures">8.5. Corrective measures</a></li>
        <li><a href="#86-selecting-the-best-regression-model">8.6. Selecting the “best” regression model</a></li>
        <li><a href="#87-taking-the-analysis-further">8.7. Taking the analysis further</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <p>Notebook of Reading Books: R in Action_Chapter 8.</p>
<h2 id="this-chapter-covers">This chapter covers</h2>
<ul>
<li>
<p>Fitting and interpreting linear models</p>
</li>
<li>
<p>Evaluating model assumptions</p>
</li>
<li>
<p>Selecting among competing models</p>
</li>
</ul>
<h3 id="81-the-many-faces-of-regression">8.1. The many faces of regression</h3>
<h3 id="82-ols-regression">8.2. OLS regression</h3>
<p>In OLS regression, a quantitative dependent variable is predicted from a weighted sum of predictor variables, where the weights are parameters estimated from the data.</p>
<p>$$ \hat Y_{i} = \hat \beta_{0} + \hat \beta_{1} X_{1i}+ &hellip; + \hat \beta_{k}X_{ki}\ \ \ \ \ \ i = 1&hellip;n $$</p>
<h4 id="821-fitting-regression-models-with-lm">8.2.1. Fitting regression models with lm()</h4>
<p><img src="tabfun.png" alt="tabfun"></p>
<h4 id="822-simple-linear-regression">8.2.2. Simple linear regression</h4>
<ul>
<li>
<p>Figure 8.1. Scatter plot with regression line for weight predicted from height</p>
</li>
<li>
<p>with <code>lm()</code> and <code>abline()</code></p>
<p><img src="listing1.png" alt="listing1"></p>
</li>
</ul>
<h4 id="823-polynomial-regression">8.2.3. Polynomial regression</h4>
<ul>
<li>
<p>Figure 8.2. Quadratic regression for weight predicted by height</p>
<p><img src="listing2.png" alt="listing2"></p>
</li>
<li>
<p>Figure 8.3. Scatter plot of height by weight, with linear and smoothed fits, and marginal box plots</p>
</li>
<li>
<p>with <strong>scatterplot()</strong> in the &ldquo;car&rdquo; package</p>
<p><img src="listingn.png" alt="listingn"></p>
</li>
</ul>
<h4 id="824-multiple-linear-regression">8.2.4. Multiple linear regression</h4>
<ul>
<li>
<p>Figure 8.4. Scatter plot matrix of dependent and independent variables for the states data, including linear and smoothed fits, and marginal distributions (kernel density plots and rug plots)</p>
<p><img src="listing3.png" alt="listing3"></p>
</li>
</ul>
<h4 id="825-multiple-linear-regression-with-interactions">8.2.5. Multiple linear regression with interactions</h4>
<ul>
<li>
<p>Figure 8.5. Interaction plot for hp*wt. This plot displays the relationship between mpg and hp at 3 values of wt.</p>
<p><img src="effplot.png" alt="effplot"></p>
</li>
</ul>
<h3 id="83-regression-diagnostics">8.3. Regression diagnostics</h3>
<h4 id="831-a-typical-approach">8.3.1. A typical approach</h4>
<ul>
<li>
<p>Figure 8.6. Diagnostic plots for the regression of weight on height</p>
<p><img src="typ821.png" alt="typapp"></p>
</li>
<li>
<p>Figure 8.7. Diagnostic plots for the regression of weight on height and height-squared</p>
<p><img src="typ8311.png" alt="typ8311"></p>
</li>
<li>
<p>Figure 8.8. Diagnostic plots for the regression of murder rate on state characteristics</p>
<p><img src="typ8312.png" alt="typ8312"></p>
</li>
</ul>
<h4 id="832-an-enhanced-approach">8.3.2. An enhanced approach</h4>
<ul>
<li>
<p>library(car)</p>
<p><img src="tabenc.png" alt="tabenc"></p>
</li>
<li>
<p>Normality</p>
<ul>
<li>Figure 8.9. Q-Q plot for studentized residuals</li>
</ul>
<p><img src="fig89.png" alt="fig89"></p>
<ul>
<li>
<p>Figure 8.10. Distribution of studentized residuals using the residplot() function</p>
</li>
<li>
<p>with residplot()</p>
</li>
</ul>
<p><img src="fig810.png" alt="fig810"></p>
</li>
<li>
<p>Independence of Errors</p>
<ul>
<li>with durbinWatsonTest()</li>
</ul>
</li>
<li>
<p>Linearity</p>
<ul>
<li>Figure 8.11. Component plus residual plots for the regression of murder rate on state characteristics</li>
</ul>
<p><img src="fig811.png" alt="fig811"></p>
</li>
<li>
<p>Homoscedasticity</p>
<ul>
<li>Figure 8.12. Spread-level plot for assessing constant error variance</li>
</ul>
<p><img src="fig812.png" alt="fig812"></p>
</li>
</ul>
<h4 id="833-global-validation-of-linear-model-assumption">8.3.3. Global validation of linear model assumption</h4>
<ul>
<li>gvlma() in the gvlma package.</li>
</ul>
<h4 id="834-multicollinearity">8.3.4. Multicollinearity</h4>
<ul>
<li>vif()</li>
</ul>
<h3 id="84-unusual-observations">8.4. Unusual observations</h3>
<h4 id="841-outliers">8.4.1. Outliers</h4>
<ul>
<li>outlierTest()</li>
</ul>
<h4 id="842-high-leverage-points">8.4.2. High leverage points</h4>
<ul>
<li>
<p>Figure 8.13. Index plot of hat values for assessing observations with high leverage</p>
<p><img src="fig813.png" alt="fig813"></p>
</li>
</ul>
<h4 id="843-influential-observations">8.4.3. Influential observations</h4>
<ul>
<li>
<p>Figure 8.14. Cook’s D plot for identifying influential observations</p>
<p><img src="fig814.png" alt="fig814"></p>
</li>
<li>
<p>Figure 8.15. Added-variable plots for assessing the impact of influential observations</p>
<p><img src="fig815.png" alt="fig815"></p>
</li>
<li>
<p>Figure 8.16. Influence plot.</p>
<ul>
<li>
<p>States above <code>+2</code> or below <code>–2</code> on the vertical axis are considered <strong>outliers</strong>.</p>
</li>
<li>
<p>States above <code>0.2</code> or <code>0.3</code> on the horizontal axis <strong>have high leverage</strong> (unusual combinations of predictor values).</p>
</li>
<li>
<p><strong>Circle size</strong> is proportional to influence. Observations depicted by large circles may have disproportionate influence on the parameters estimates of the model.</p>
</li>
</ul>
<p><img src="fig816.png" alt="fig816"></p>
</li>
</ul>
<h3 id="85-corrective-measures">8.5. Corrective measures</h3>
<h4 id="851-deleting-observations">8.5.1. Deleting observations</h4>
<h4 id="852-transforming-variables">8.5.2. Transforming variables</h4>
<ul>
<li>with powerTransform() and boxTidwell()</li>
</ul>
<h4 id="853-adding-or-deleting-variables">8.5.3. Adding or deleting variables</h4>
<ul>
<li>sqrt(vif) &gt; 2</li>
</ul>
<h4 id="854-trying-a-different-approach">8.5.4. Trying a different approach</h4>
<h3 id="86-selecting-the-best-regression-model">8.6. Selecting the “best” regression model</h3>
<ul>
<li>The selection of a final regression model always involves a compromise between predictive accuracy (a model that fits the data as well as possible) and parsimony (a simple and replicable model).</li>
</ul>
<h4 id="861-comparing-models">8.6.1. Comparing models</h4>
<ul>
<li>with anova() and AIC()</li>
</ul>
<h4 id="862-variable-selection">8.6.2. Variable selection</h4>
<ul>
<li>
<p>selecting a final set of predictor variables from a larger pool of candidate variables</p>
<ul>
<li>
<p>Stepwise Regression</p>
<ul>
<li>stepAIC() in the MASS package</li>
</ul>
</li>
<li>
<p>all-subsets regression</p>
<ul>
<li>
<p>regsubsets() in the leaps package</p>
</li>
<li>
<p>Figure 8.17. Best four models for each subset size based on Adjusted R-square
<img src="fig817.png" alt="fig817"></p>
</li>
<li>
<p>Figure 8.18. Best four models for each subset size based on the Mallows Cp statistic
<img src="fig818.png" alt="fig818"></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="87-taking-the-analysis-further">8.7. Taking the analysis further</h3>
<h4 id="871-cross-validation">8.7.1. Cross-validation</h4>
<ul>
<li>crossval() in the bootstrap package</li>
</ul>
<h4 id="872-relative-importance">8.7.2. Relative importance</h4>
<ul>
<li>
<p>Figure 8.19. Bar plot of relative weights for the states multiple regression problem</p>
<p><img src="fig819.png" alt="fig819"></p>
</li>
</ul>
<p>Attach is the <a href="chapter8.R">Script</a> of chapter8.</p>
<p>Show me the code <i class="far fa-hand-pointer"></i></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span><span class="lnt">190
</span><span class="lnt">191
</span><span class="lnt">192
</span><span class="lnt">193
</span><span class="lnt">194
</span><span class="lnt">195
</span><span class="lnt">196
</span><span class="lnt">197
</span><span class="lnt">198
</span><span class="lnt">199
</span><span class="lnt">200
</span><span class="lnt">201
</span><span class="lnt">202
</span><span class="lnt">203
</span><span class="lnt">204
</span><span class="lnt">205
</span><span class="lnt">206
</span><span class="lnt">207
</span><span class="lnt">208
</span><span class="lnt">209
</span><span class="lnt">210
</span><span class="lnt">211
</span><span class="lnt">212
</span><span class="lnt">213
</span><span class="lnt">214
</span><span class="lnt">215
</span><span class="lnt">216
</span><span class="lnt">217
</span><span class="lnt">218
</span><span class="lnt">219
</span><span class="lnt">220
</span><span class="lnt">221
</span><span class="lnt">222
</span><span class="lnt">223
</span><span class="lnt">224
</span><span class="lnt">225
</span><span class="lnt">226
</span><span class="lnt">227
</span><span class="lnt">228
</span><span class="lnt">229
</span><span class="lnt">230
</span><span class="lnt">231
</span><span class="lnt">232
</span><span class="lnt">233
</span><span class="lnt">234
</span><span class="lnt">235
</span><span class="lnt">236
</span><span class="lnt">237
</span><span class="lnt">238
</span><span class="lnt">239
</span><span class="lnt">240
</span><span class="lnt">241
</span><span class="lnt">242
</span><span class="lnt">243
</span><span class="lnt">244
</span><span class="lnt">245
</span><span class="lnt">246
</span><span class="lnt">247
</span><span class="lnt">248
</span><span class="lnt">249
</span><span class="lnt">250
</span><span class="lnt">251
</span><span class="lnt">252
</span><span class="lnt">253
</span><span class="lnt">254
</span><span class="lnt">255
</span><span class="lnt">256
</span><span class="lnt">257
</span><span class="lnt">258
</span><span class="lnt">259
</span><span class="lnt">260
</span><span class="lnt">261
</span><span class="lnt">262
</span><span class="lnt">263
</span><span class="lnt">264
</span><span class="lnt">265
</span><span class="lnt">266
</span><span class="lnt">267
</span><span class="lnt">268
</span><span class="lnt">269
</span><span class="lnt">270
</span><span class="lnt">271
</span><span class="lnt">272
</span><span class="lnt">273
</span><span class="lnt">274
</span><span class="lnt">275
</span><span class="lnt">276
</span><span class="lnt">277
</span><span class="lnt">278
</span><span class="lnt">279
</span><span class="lnt">280
</span><span class="lnt">281
</span><span class="lnt">282
</span><span class="lnt">283
</span><span class="lnt">284
</span><span class="lnt">285
</span><span class="lnt">286
</span><span class="lnt">287
</span><span class="lnt">288
</span><span class="lnt">289
</span><span class="lnt">290
</span><span class="lnt">291
</span><span class="lnt">292
</span><span class="lnt">293
</span><span class="lnt">294
</span><span class="lnt">295
</span><span class="lnt">296
</span><span class="lnt">297
</span><span class="lnt">298
</span><span class="lnt">299
</span><span class="lnt">300
</span><span class="lnt">301
</span><span class="lnt">302
</span><span class="lnt">303
</span><span class="lnt">304
</span><span class="lnt">305
</span><span class="lnt">306
</span><span class="lnt">307
</span><span class="lnt">308
</span><span class="lnt">309
</span><span class="lnt">310
</span><span class="lnt">311
</span><span class="lnt">312
</span><span class="lnt">313
</span><span class="lnt">314
</span><span class="lnt">315
</span><span class="lnt">316
</span><span class="lnt">317
</span><span class="lnt">318
</span><span class="lnt">319
</span><span class="lnt">320
</span><span class="lnt">321
</span><span class="lnt">322
</span><span class="lnt">323
</span><span class="lnt">324
</span><span class="lnt">325
</span><span class="lnt">326
</span><span class="lnt">327
</span><span class="lnt">328
</span><span class="lnt">329
</span><span class="lnt">330
</span><span class="lnt">331
</span><span class="lnt">332
</span><span class="lnt">333
</span><span class="lnt">334
</span><span class="lnt">335
</span><span class="lnt">336
</span><span class="lnt">337
</span><span class="lnt">338
</span><span class="lnt">339
</span><span class="lnt">340
</span><span class="lnt">341
</span><span class="lnt">342
</span><span class="lnt">343
</span><span class="lnt">344
</span><span class="lnt">345
</span><span class="lnt">346
</span><span class="lnt">347
</span><span class="lnt">348
</span><span class="lnt">349
</span><span class="lnt">350
</span><span class="lnt">351
</span><span class="lnt">352
</span><span class="lnt">353
</span><span class="lnt">354
</span><span class="lnt">355
</span><span class="lnt">356
</span><span class="lnt">357
</span><span class="lnt">358
</span><span class="lnt">359
</span><span class="lnt">360
</span><span class="lnt">361
</span><span class="lnt">362
</span><span class="lnt">363
</span><span class="lnt">364
</span><span class="lnt">365
</span><span class="lnt">366
</span><span class="lnt">367
</span><span class="lnt">368
</span><span class="lnt">369
</span><span class="lnt">370
</span><span class="lnt">371
</span><span class="lnt">372
</span><span class="lnt">373
</span><span class="lnt">374
</span><span class="lnt">375
</span><span class="lnt">376
</span><span class="lnt">377
</span><span class="lnt">378
</span><span class="lnt">379
</span><span class="lnt">380
</span><span class="lnt">381
</span><span class="lnt">382
</span><span class="lnt">383
</span><span class="lnt">384
</span><span class="lnt">385
</span><span class="lnt">386
</span><span class="lnt">387
</span><span class="lnt">388
</span><span class="lnt">389
</span><span class="lnt">390
</span><span class="lnt">391
</span><span class="lnt">392
</span><span class="lnt">393
</span><span class="lnt">394
</span><span class="lnt">395
</span><span class="lnt">396
</span><span class="lnt">397
</span><span class="lnt">398
</span><span class="lnt">399
</span><span class="lnt">400
</span><span class="lnt">401
</span><span class="lnt">402
</span><span class="lnt">403
</span><span class="lnt">404
</span><span class="lnt">405
</span><span class="lnt">406
</span><span class="lnt">407
</span><span class="lnt">408
</span><span class="lnt">409
</span><span class="lnt">410
</span><span class="lnt">411
</span><span class="lnt">412
</span><span class="lnt">413
</span><span class="lnt">414
</span><span class="lnt">415
</span><span class="lnt">416
</span><span class="lnt">417
</span><span class="lnt">418
</span><span class="lnt">419
</span><span class="lnt">420
</span><span class="lnt">421
</span><span class="lnt">422
</span><span class="lnt">423
</span><span class="lnt">424
</span><span class="lnt">425
</span><span class="lnt">426
</span><span class="lnt">427
</span><span class="lnt">428
</span><span class="lnt">429
</span><span class="lnt">430
</span><span class="lnt">431
</span><span class="lnt">432
</span><span class="lnt">433
</span><span class="lnt">434
</span><span class="lnt">435
</span><span class="lnt">436
</span><span class="lnt">437
</span><span class="lnt">438
</span><span class="lnt">439
</span><span class="lnt">440
</span><span class="lnt">441
</span><span class="lnt">442
</span><span class="lnt">443
</span><span class="lnt">444
</span><span class="lnt">445
</span><span class="lnt">446
</span><span class="lnt">447
</span><span class="lnt">448
</span><span class="lnt">449
</span><span class="lnt">450
</span><span class="lnt">451
</span><span class="lnt">452
</span><span class="lnt">453
</span><span class="lnt">454
</span><span class="lnt">455
</span><span class="lnt">456
</span><span class="lnt">457
</span><span class="lnt">458
</span><span class="lnt">459
</span><span class="lnt">460
</span><span class="lnt">461
</span><span class="lnt">462
</span><span class="lnt">463
</span><span class="lnt">464
</span><span class="lnt">465
</span><span class="lnt">466
</span><span class="lnt">467
</span><span class="lnt">468
</span><span class="lnt">469
</span><span class="lnt">470
</span><span class="lnt">471
</span><span class="lnt">472
</span><span class="lnt">473
</span><span class="lnt">474
</span><span class="lnt">475
</span><span class="lnt">476
</span><span class="lnt">477
</span><span class="lnt">478
</span><span class="lnt">479
</span><span class="lnt">480
</span><span class="lnt">481
</span><span class="lnt">482
</span><span class="lnt">483
</span><span class="lnt">484
</span><span class="lnt">485
</span><span class="lnt">486
</span><span class="lnt">487
</span><span class="lnt">488
</span><span class="lnt">489
</span><span class="lnt">490
</span><span class="lnt">491
</span><span class="lnt">492
</span><span class="lnt">493
</span><span class="lnt">494
</span><span class="lnt">495
</span><span class="lnt">496
</span><span class="lnt">497
</span><span class="lnt">498
</span><span class="lnt">499
</span><span class="lnt">500
</span><span class="lnt">501
</span><span class="lnt">502
</span><span class="lnt">503
</span><span class="lnt">504
</span><span class="lnt">505
</span><span class="lnt">506
</span><span class="lnt">507
</span><span class="lnt">508
</span><span class="lnt">509
</span><span class="lnt">510
</span><span class="lnt">511
</span><span class="lnt">512
</span><span class="lnt">513
</span><span class="lnt">514
</span><span class="lnt">515
</span><span class="lnt">516
</span><span class="lnt">517
</span><span class="lnt">518
</span><span class="lnt">519
</span><span class="lnt">520
</span><span class="lnt">521
</span><span class="lnt">522
</span><span class="lnt">523
</span><span class="lnt">524
</span><span class="lnt">525
</span><span class="lnt">526
</span><span class="lnt">527
</span><span class="lnt">528
</span><span class="lnt">529
</span><span class="lnt">530
</span><span class="lnt">531
</span><span class="lnt">532
</span><span class="lnt">533
</span><span class="lnt">534
</span><span class="lnt">535
</span><span class="lnt">536
</span><span class="lnt">537
</span><span class="lnt">538
</span><span class="lnt">539
</span><span class="lnt">540
</span><span class="lnt">541
</span><span class="lnt">542
</span><span class="lnt">543
</span><span class="lnt">544
</span><span class="lnt">545
</span><span class="lnt">546
</span><span class="lnt">547
</span><span class="lnt">548
</span><span class="lnt">549
</span><span class="lnt">550
</span><span class="lnt">551
</span><span class="lnt">552
</span><span class="lnt">553
</span><span class="lnt">554
</span><span class="lnt">555
</span><span class="lnt">556
</span><span class="lnt">557
</span><span class="lnt">558
</span><span class="lnt">559
</span><span class="lnt">560
</span><span class="lnt">561
</span><span class="lnt">562
</span><span class="lnt">563
</span><span class="lnt">564
</span><span class="lnt">565
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># Remove most objects from the working environment</span>
<span class="nf">rm</span><span class="p">(</span><span class="n">list</span> <span class="o">=</span> <span class="nf">ls</span><span class="p">())</span>
<span class="nf">options</span><span class="p">(</span><span class="n">stringsAsFactors</span> <span class="o">=</span> <span class="bp">F</span><span class="p">)</span>


<span class="c1"># 8.2.1. Fitting regression models with lm()</span>
<span class="n">myfit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="c1"># 8.2.2. Simple linear regression</span>
<span class="c1"># code listing Simple linear regression</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">weight</span> <span class="o">~</span> <span class="n">height</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">women</span><span class="p">)</span>
<span class="nf">colnames</span><span class="p">(</span><span class="n">women</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="c1"># Call:</span>
<span class="c1">#   lm(formula = weight ~ height, data = women)</span>
<span class="c1"># </span>
<span class="c1"># Residuals:</span>
<span class="c1">#   Min      1Q  Median      3Q     Max </span>
<span class="c1"># -1.7333 -1.1333 -0.3833  0.7417  3.1167 </span>
<span class="c1"># </span>
<span class="c1"># Coefficients:</span>
<span class="c1">#   Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="c1"># (Intercept) -87.51667    5.93694  -14.74 1.71e-09 ***</span>
<span class="c1">#   height        3.45000    0.09114   37.85 1.09e-14 ***</span>
<span class="c1">#   ---</span>
<span class="c1">#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="c1"># </span>
<span class="c1"># Residual standard error: 1.525 on 13 degrees of freedom</span>
<span class="c1"># Multiple R-squared:  0.991, Adjusted R-squared:  0.9903 </span>
<span class="c1"># F-statistic:  1433 on 1 and 13 DF,  p-value: 1.091e-14</span>


<span class="nf">fitted</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="n">women</span><span class="o">$</span><span class="n">weight</span>
<span class="nf">residuals</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Figure 8.1. </span>
<span class="nf">plot</span><span class="p">(</span><span class="n">women</span><span class="o">$</span><span class="n">height</span><span class="p">,</span> <span class="n">women</span><span class="o">$</span><span class="n">weight</span><span class="p">,</span>
     <span class="n">xlab</span> <span class="o">=</span> <span class="s">&#34;Height (in inches)&#34;</span><span class="p">,</span>
     <span class="n">ylab</span> <span class="o">=</span> <span class="s">&#34;Weight (in pounds)&#34;</span><span class="p">)</span>
<span class="nf">abline</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># 8.2.3. Polynomial regression</span>
<span class="n">fit2</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">weight</span> <span class="o">~</span> <span class="n">height</span> <span class="o">+</span> <span class="nf">I</span><span class="p">(</span><span class="n">height^2</span><span class="p">),</span> <span class="n">data</span><span class="o">=</span><span class="n">women</span><span class="p">)</span>

<span class="c1"># code listing 8.2. Polynomial regression</span>
<span class="n">fit2</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">weight</span> <span class="o">~</span> <span class="n">height</span> <span class="o">+</span> <span class="nf">I</span><span class="p">(</span><span class="n">height^2</span><span class="p">),</span> <span class="n">data</span> <span class="o">=</span> <span class="n">women</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit2</span><span class="p">)</span>
<span class="c1"># Call:</span>
<span class="c1">#   lm(formula = weight ~ height + I(height^2), data = women)</span>
<span class="c1"># </span>
<span class="c1"># Residuals:</span>
<span class="c1">#   Min       1Q   Median       3Q      Max </span>
<span class="c1"># -0.50941 -0.29611 -0.00941  0.28615  0.59706 </span>
<span class="c1"># </span>
<span class="c1"># Coefficients:</span>
<span class="c1">#   Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="c1"># (Intercept) 261.87818   25.19677  10.393 2.36e-07 ***</span>
<span class="c1">#   height       -7.34832    0.77769  -9.449 6.58e-07 ***</span>
<span class="c1">#   I(height^2)   0.08306    0.00598  13.891 9.32e-09 ***</span>
<span class="c1">#   ---</span>
<span class="c1">#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="c1"># </span>
<span class="c1"># Residual standard error: 0.3841 on 12 degrees of freedom</span>
<span class="c1"># Multiple R-squared:  0.9995, Adjusted R-squared:  0.9994 </span>
<span class="c1"># F-statistic: 1.139e+04 on 2 and 12 DF,  p-value: &lt; 2.2e-16</span>

<span class="c1"># Figure 8.2</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">women</span><span class="o">$</span><span class="n">height</span><span class="p">,</span> <span class="n">women</span><span class="o">$</span><span class="n">weight</span><span class="p">,</span>
     <span class="n">xlab</span> <span class="o">=</span> <span class="s">&#34;Height (in inches)&#34;</span><span class="p">,</span>
     <span class="n">ylab</span> <span class="o">=</span> <span class="s">&#34;Weight (in pounds)&#34;</span><span class="p">)</span>
<span class="nf">lines</span><span class="p">(</span><span class="n">women</span><span class="o">$</span><span class="n">height</span><span class="p">,</span> <span class="n">women</span><span class="o">$</span><span class="n">weight</span><span class="p">)</span>


<span class="c1"># with library(car) in the &#34;car&#34; package</span>
<span class="c1"># Figure 8.3.</span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">scatterplot</span><span class="p">(</span><span class="n">weight</span> <span class="o">~</span> <span class="n">height</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">women</span><span class="p">,</span>
            <span class="n">spread</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span> <span class="n">smoother</span><span class="o">=</span><span class="nf">list</span><span class="p">(</span><span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">),</span>
            <span class="n">pch</span><span class="o">=</span><span class="m">19</span><span class="p">,</span>
            <span class="n">main</span><span class="o">=</span><span class="s">&#34;Women Age 30-39&#34;</span><span class="p">,</span>
            <span class="n">xlab</span><span class="o">=</span><span class="s">&#34;Height (inches)&#34;</span><span class="p">,</span>
            <span class="n">ylab</span><span class="o">=</span><span class="s">&#34;Weight (lbs.)&#34;</span><span class="p">)</span>

<span class="c1"># 8.2.4. Multiple linear regression</span>

<span class="c1"># code listing 8.3 Examining bivariate relationships</span>
<span class="n">states</span> <span class="o">&lt;-</span> <span class="nf">as.data.frame</span><span class="p">(</span><span class="n">state.x77[</span><span class="p">,</span><span class="nf">c</span><span class="p">(</span><span class="s">&#34;Murder&#34;</span><span class="p">,</span> <span class="s">&#34;Population&#34;</span><span class="p">,</span>
                                     <span class="s">&#34;Illiteracy&#34;</span><span class="p">,</span> <span class="s">&#34;Income&#34;</span><span class="p">,</span> <span class="s">&#34;Frost&#34;</span><span class="p">)</span><span class="n">]</span><span class="p">)</span>

<span class="nf">cor</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="c1"># Figure 8.4.</span>
<span class="nf">scatterplotMatrix</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">spread</span><span class="o">=</span><span class="bp">F</span><span class="p">,</span> <span class="n">lty.smooth</span><span class="o">=</span><span class="m">2</span><span class="p">,</span>
                  <span class="n">main</span> <span class="o">=</span> <span class="s">&#34;Scatter Plot Matrix&#34;</span><span class="p">)</span>


<span class="c1"># code listing 8.4 Multiple linear regression</span>
<span class="n">states</span> <span class="o">&lt;-</span> <span class="nf">as.data.frame</span><span class="p">(</span><span class="n">state.x77[</span><span class="p">,</span><span class="nf">c</span><span class="p">(</span><span class="s">&#34;Murder&#34;</span><span class="p">,</span> <span class="s">&#34;Population&#34;</span><span class="p">,</span>
                                     <span class="s">&#34;Illiteracy&#34;</span><span class="p">,</span> <span class="s">&#34;Income&#34;</span><span class="p">,</span> <span class="s">&#34;Frost&#34;</span><span class="p">)</span><span class="n">]</span><span class="p">)</span>

<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span>
          <span class="n">data</span> <span class="o">=</span> <span class="n">states</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="c1"># Call:</span>
<span class="c1">#   lm(formula = Murder ~ Population + Illiteracy + Income + Frost, </span>
<span class="c1">#      data = states)</span>
<span class="c1"># </span>
<span class="c1"># Residuals:</span>
<span class="c1">#   Min      1Q  Median      3Q     Max </span>
<span class="c1"># -4.7960 -1.6495 -0.0811  1.4815  7.6210 </span>
<span class="c1"># </span>
<span class="c1"># Coefficients:</span>
<span class="c1">#   Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="c1"># (Intercept) 1.235e+00  3.866e+00   0.319   0.7510    </span>
<span class="c1"># Population  2.237e-04  9.052e-05   2.471   0.0173 *  </span>
<span class="c1">#   Illiteracy  4.143e+00  8.744e-01   4.738 2.19e-05 ***</span>
<span class="c1">#   Income      6.442e-05  6.837e-04   0.094   0.9253    </span>
<span class="c1"># Frost       5.813e-04  1.005e-02   0.058   0.9541    </span>
<span class="c1"># ---</span>
<span class="c1">#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="c1"># </span>
<span class="c1"># Residual standard error: 2.535 on 45 degrees of freedom</span>
<span class="c1"># Multiple R-squared:  0.567, Adjusted R-squared:  0.5285 </span>
<span class="c1"># F-statistic: 14.73 on 4 and 45 DF,  p-value: 9.133e-08</span>

<span class="c1">#===================================================================</span>
<span class="c1"># 8.2.5. Multiple linear regression with interactions</span>
<span class="c1"># code listing 8.5 Multiple linear regression with a significant interaction term</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="n">hp</span> <span class="o">+</span> <span class="n">wt</span> <span class="o">+</span> <span class="n">hp</span><span class="o">:</span><span class="n">wt</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="c1"># Call:</span>
<span class="c1">#   lm(formula = mpg ~ hp + wt + hp:wt, data = mtcars)</span>
<span class="c1"># </span>
<span class="c1"># Residuals:</span>
<span class="c1">#   Min      1Q  Median      3Q     Max </span>
<span class="c1"># -3.0632 -1.6491 -0.7362  1.4211  4.5513 </span>
<span class="c1"># </span>
<span class="c1"># Coefficients:</span>
<span class="c1">#   Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="c1"># (Intercept) 49.80842    3.60516  13.816 5.01e-14 ***</span>
<span class="c1">#   hp          -0.12010    0.02470  -4.863 4.04e-05 ***</span>
<span class="c1">#   wt          -8.21662    1.26971  -6.471 5.20e-07 ***</span>
<span class="c1">#   hp:wt        0.02785    0.00742   3.753 0.000811 ***</span>
<span class="c1">#   ---</span>
<span class="c1">#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="c1"># </span>
<span class="c1"># Residual standard error: 2.153 on 28 degrees of freedom</span>
<span class="c1"># Multiple R-squared:  0.8848, Adjusted R-squared:  0.8724 </span>
<span class="c1"># F-statistic: 71.66 on 3 and 28 DF,  p-value: 2.981e-13</span>

<span class="c1">#====================================================================</span>

<span class="c1"># install.packages(&#34;effects&#34;)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">effects</span><span class="p">)</span>
<span class="c1"># Figure 8.5.</span>
<span class="nf">plot</span><span class="p">(</span><span class="nf">effect</span><span class="p">(</span><span class="s">&#34;hp:wt&#34;</span><span class="p">,</span> <span class="n">fit</span><span class="p">,</span>
            <span class="n">vcov.</span> <span class="o">=</span> <span class="n">vcov</span><span class="p">,</span>
            <span class="nf">list</span><span class="p">(</span><span class="n">wt</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2.2</span><span class="p">,</span><span class="m">3.2</span><span class="p">,</span><span class="m">4.2</span><span class="p">))),</span>
     <span class="n">multiline</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>


<span class="c1"># 8.3. Regression diagnostics</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="nf">confint</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="c1"># 2.5 %       97.5 %</span>
<span class="c1">#   (Intercept) -6.552191e+00 9.0213182149</span>
<span class="c1"># Population   4.136397e-05 0.0004059867</span>
<span class="c1"># Illiteracy   2.381799e+00 5.9038743192</span>
<span class="c1"># Income      -1.312611e-03 0.0014414600</span>
<span class="c1"># Frost       -1.966781e-02 0.0208304170</span>


<span class="c1"># 8.3.1. A typical approach</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">weight</span> <span class="o">~</span> <span class="n">height</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">women</span><span class="p">)</span>
<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">))</span>
<span class="c1"># Figure 8.6.</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="n">fit2</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">weight</span> <span class="o">~</span> <span class="n">height</span> <span class="o">+</span> <span class="nf">I</span><span class="p">(</span><span class="n">height^2</span><span class="p">),</span> <span class="n">data</span><span class="o">=</span><span class="n">women</span><span class="p">)</span>
<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">))</span>
<span class="c1"># Figure 8.7.</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">fit2</span><span class="p">)</span>

<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">))</span>
<span class="c1"># Figure 8.8.</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># 8.3.2. An enhanced approach</span>

<span class="c1"># Normality</span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="c1"># Figure 8.9.</span>
<span class="nf">qqPlot</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="nf">row.names</span><span class="p">(</span><span class="n">states</span><span class="p">),</span> <span class="n">id.method</span><span class="o">=</span><span class="s">&#34;identify&#34;</span><span class="p">,</span>
       <span class="n">simulate</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span> <span class="n">main</span><span class="o">=</span><span class="s">&#34;Q-Q Plot&#34;</span><span class="p">)</span>

<span class="n">states[</span><span class="s">&#34;Nevada&#34;</span><span class="p">,</span><span class="n">]</span>
<span class="c1">#         Murder Population Illiteracy Income Frost</span>
<span class="c1"># Nevada   11.5        590        0.5   5149   188</span>

<span class="nf">fitted</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span><span class="n">[</span><span class="s">&#34;Nevada&#34;</span><span class="n">]</span>
<span class="c1">#   Nevada </span>
<span class="c1"># 3.878958 </span>

<span class="nf">residuals</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span><span class="n">[</span><span class="s">&#34;Nevada&#34;</span><span class="n">]</span>
<span class="c1">#   Nevada </span>
<span class="c1"># 7.621042 </span>

<span class="nf">rstudent</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span><span class="n">[</span><span class="s">&#34;Nevada&#34;</span><span class="n">]</span>
<span class="c1">#   Nevada </span>
<span class="c1"># 3.542929 </span>

<span class="c1"># Normality</span>
<span class="c1"># code listing 8.6. Function for plotting studentized residuals</span>
<span class="n">residplot</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">nbreaks</span><span class="o">=</span><span class="m">10</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">z</span> <span class="o">&lt;-</span> <span class="nf">rstudent</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
  <span class="nf">hist</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">breaks</span><span class="o">=</span><span class="n">nbreaks</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span>
       <span class="n">xlab</span><span class="o">=</span><span class="s">&#34;Studentized Residual&#34;</span><span class="p">,</span>
       <span class="n">main</span><span class="o">=</span><span class="s">&#34;Distribution of Errors&#34;</span><span class="p">)</span>
  <span class="nf">rug</span><span class="p">(</span><span class="nf">jitter</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">col</span><span class="o">=</span><span class="s">&#34;brown&#34;</span><span class="p">)</span>
  <span class="nf">curve</span><span class="p">(</span><span class="nf">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="nf">mean</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">sd</span><span class="o">=</span><span class="nf">sd</span><span class="p">(</span><span class="n">z</span><span class="p">)),</span>
        <span class="n">add</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">&#34;blue&#34;</span><span class="p">,</span> <span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>
  <span class="nf">lines</span><span class="p">(</span><span class="nf">density</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">$</span><span class="n">x</span><span class="p">,</span> <span class="nf">density</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">$</span><span class="n">y</span><span class="p">,</span>
        <span class="n">col</span><span class="o">=</span><span class="s">&#34;red&#34;</span><span class="p">,</span> <span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span> <span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>
  <span class="nf">legend</span><span class="p">(</span><span class="s">&#34;topright&#34;</span><span class="p">,</span>
         <span class="n">legend</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span> <span class="s">&#34;Normal Curve&#34;</span><span class="p">,</span> <span class="s">&#34;Kernel Density Curve&#34;</span><span class="p">),</span>
         <span class="n">lty</span><span class="o">=</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s">&#34;blue&#34;</span><span class="p">,</span><span class="s">&#34;red&#34;</span><span class="p">),</span> <span class="n">cex</span><span class="o">=</span><span class="m">.7</span><span class="p">)</span>
<span class="p">}</span>
<span class="c1"># Figure 8.10.</span>
<span class="nf">residplot</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Independence of Errors</span>
<span class="nf">durbinWatsonTest</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="c1"># lag Autocorrelation D-W Statistic p-value</span>
<span class="c1"># 1      -0.2006929      2.317691   0.306</span>
<span class="c1"># Alternative hypothesis: rho != 0</span>


<span class="c1"># Linearity</span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="c1"># Figure 8.11.</span>
<span class="nf">crPlots</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Homoscedasticity</span>
<span class="c1"># code listing  8.7. Assessing homoscedasticity</span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">ncvTest</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="c1"># Non-constant Variance Score Test </span>
<span class="c1"># Variance formula: ~ fitted.values </span>
<span class="c1"># Chisquare = 1.746514, Df = 1, p = 0.18632</span>

<span class="c1"># Figure 8.12.</span>
<span class="nf">spreadLevelPlot</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Suggested power transformation:  1.209626 </span>


<span class="c1"># 8.3.3. Global validation of linear model assumption</span>
<span class="c1"># code listing 8.8. Global test of linear model assumptions</span>
<span class="c1"># install.packages(gvlma)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">gvlma</span><span class="p">)</span>
<span class="n">gvmodel</span> <span class="o">&lt;-</span> <span class="nf">gvlma</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">gvmodel</span><span class="p">)</span>
<span class="c1"># Call:</span>
<span class="c1">#   lm(formula = Murder ~ Population + Illiteracy + Income + Frost, </span>
<span class="c1">#      data = states)</span>
<span class="c1"># </span>
<span class="c1"># Residuals:</span>
<span class="c1">#   Min      1Q  Median      3Q     Max </span>
<span class="c1"># -4.7960 -1.6495 -0.0811  1.4815  7.6210 </span>
<span class="c1"># </span>
<span class="c1"># Coefficients:</span>
<span class="c1">#   Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="c1"># (Intercept) 1.235e+00  3.866e+00   0.319   0.7510    </span>
<span class="c1"># Population  2.237e-04  9.052e-05   2.471   0.0173 *  </span>
<span class="c1">#   Illiteracy  4.143e+00  8.744e-01   4.738 2.19e-05 ***</span>
<span class="c1">#   Income      6.442e-05  6.837e-04   0.094   0.9253    </span>
<span class="c1"># Frost       5.813e-04  1.005e-02   0.058   0.9541    </span>
<span class="c1"># ---</span>
<span class="c1">#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="c1"># </span>
<span class="c1"># Residual standard error: 2.535 on 45 degrees of freedom</span>
<span class="c1"># Multiple R-squared:  0.567, Adjusted R-squared:  0.5285 </span>
<span class="c1"># F-statistic: 14.73 on 4 and 45 DF,  p-value: 9.133e-08</span>
<span class="c1"># </span>
<span class="c1"># </span>
<span class="c1"># ASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS</span>
<span class="c1"># USING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:</span>
<span class="c1">#   Level of Significance =  0.05 </span>
<span class="c1"># </span>
<span class="c1"># Call:</span>
<span class="c1">#   gvlma(x = fit) </span>
<span class="c1"># </span>
<span class="c1"># Value p-value                Decision</span>
<span class="c1"># Global Stat        2.7728  0.5965 Assumptions acceptable.</span>
<span class="c1"># Skewness           1.5374  0.2150 Assumptions acceptable.</span>
<span class="c1"># Kurtosis           0.6376  0.4246 Assumptions acceptable.</span>
<span class="c1"># Link Function      0.1154  0.7341 Assumptions acceptable.</span>
<span class="c1"># Heteroscedasticity 0.4824  0.4873 Assumptions acceptable.</span>


<span class="c1">#============================================================</span>

<span class="c1"># 8.3.4. Multicollinearity</span>
<span class="c1"># code listing 8.9. Evaluating multicollinearity</span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">vif</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="c1"># Population Illiteracy     Income      Frost </span>
<span class="c1">#   1.245282   2.165848   1.345822   2.082547 </span>


<span class="nf">sqrt</span><span class="p">(</span><span class="nf">vif</span><span class="p">(</span><span class="n">fit</span><span class="p">))</span> <span class="o">&gt;</span> <span class="m">2</span>
<span class="c1"># Population Illiteracy     Income      Frost </span>
<span class="c1">#      FALSE      FALSE      FALSE      FALSE </span>

<span class="c1">#============================================================</span>

<span class="c1"># 8.4. Unusual observations</span>

<span class="c1"># 8.4.1. Outliers</span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">outlierTest</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># 8.4.2. High leverage points</span>

<span class="c1"># Figure 8.13.</span>
<span class="n">hat.plot</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">p</span> <span class="o">&lt;-</span> <span class="nf">length</span><span class="p">(</span><span class="nf">coefficients</span><span class="p">(</span><span class="n">fit</span><span class="p">))</span>
  <span class="n">n</span> <span class="o">&lt;-</span> <span class="nf">length</span><span class="p">(</span><span class="nf">fitted</span><span class="p">(</span><span class="n">fit</span><span class="p">))</span>
  <span class="nf">plot</span><span class="p">(</span><span class="nf">hatvalues</span><span class="p">(</span><span class="n">fit</span><span class="p">),</span> <span class="n">main</span><span class="o">=</span><span class="s">&#34;Index Plot of Hat Values&#34;</span><span class="p">)</span>
  <span class="nf">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">)</span><span class="o">*</span><span class="n">p</span><span class="o">/</span><span class="n">n</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">&#34;red&#34;</span><span class="p">,</span> <span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>
  <span class="nf">identify</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">,</span> <span class="nf">hatvalues</span><span class="p">(</span><span class="n">fit</span><span class="p">),</span> <span class="nf">names</span><span class="p">(</span><span class="nf">hatvalues</span><span class="p">(</span><span class="n">fit</span><span class="p">)))</span>
<span class="p">}</span>
<span class="nf">hat.plot</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># 8.4.3. Influential observations</span>

<span class="c1"># Figure 8.14.</span>
<span class="n">cutoff</span> <span class="o">&lt;-</span> <span class="m">4</span><span class="o">/</span><span class="p">(</span><span class="nf">nrow</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">-</span><span class="nf">length</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">)</span><span class="m">-2</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="m">4</span><span class="p">,</span> <span class="n">cook.levels</span><span class="o">=</span><span class="n">cutoff</span><span class="p">)</span>
<span class="nf">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="n">cutoff</span><span class="p">,</span> <span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">&#34;red&#34;</span><span class="p">)</span>

<span class="c1"># Figure 8.15. </span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">avPlots</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">ask</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span> <span class="n">onepage</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span> <span class="n">id.method</span><span class="o">=</span><span class="s">&#34;identify&#34;</span><span class="p">)</span>

<span class="c1"># Figure 8.16. Influence plot.</span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">influencePlot</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">id.method</span><span class="o">=</span><span class="s">&#34;identify&#34;</span><span class="p">,</span> <span class="n">main</span><span class="o">=</span><span class="s">&#34;Influence Plot&#34;</span><span class="p">,</span>
              <span class="n">sub</span><span class="o">=</span><span class="s">&#34;Circle size is proportional to Cook&#39;s distance&#34;</span><span class="p">)</span>


<span class="c1"># 8.5.2. Transforming variables</span>
<span class="c1"># code listing 8.10. Box–Cox transformation to normality</span>
<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="nf">powerTransform</span><span class="p">(</span><span class="n">states</span><span class="o">$</span><span class="n">Murder</span><span class="p">))</span>
<span class="c1"># bcPower Transformation to Normality </span>
<span class="c1"># Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd</span>
<span class="c1"># states$Murder    0.6055           1       0.0884       1.1227</span>
<span class="c1"># </span>
<span class="c1"># Likelihood ratio test that transformation parameter is equal to 0</span>
<span class="c1"># (log transformation)</span>
<span class="c1"># LRT df     pval</span>
<span class="c1"># LR test, lambda = (0) 5.665991  1 0.017297</span>
<span class="c1"># </span>
<span class="c1"># Likelihood ratio test that no transformation is needed</span>
<span class="c1"># LRT df    pval</span>
<span class="c1"># LR test, lambda = (1) 2.122763  1 0.14512</span>


<span class="nf">boxTidwell</span><span class="p">(</span><span class="n">Murder</span><span class="o">~</span><span class="n">Population</span><span class="o">+</span><span class="n">Illiteracy</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="c1">#             MLE of lambda Score Statistic (z) Pr(&gt;|z|)</span>
<span class="c1"># Population       0.86939             -0.3228   0.7468</span>
<span class="c1"># Illiteracy       1.35812              0.6194   0.5357</span>
<span class="c1"># </span>
<span class="c1"># iterations =  19 </span>

<span class="c1"># 8.6.1. Comparing models</span>
<span class="c1"># code listing 8.11. Comparing nested models using the anova() function</span>
<span class="n">fit1</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span>
           <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="n">fit2</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>

<span class="nf">anova</span><span class="p">(</span><span class="n">fit1</span><span class="p">,</span><span class="n">fit2</span><span class="p">)</span>
<span class="c1"># Analysis of Variance Table</span>
<span class="c1"># </span>
<span class="c1"># Model 1: Murder ~ Population + Illiteracy + Income + Frost</span>
<span class="c1"># Model 2: Murder ~ Population + Illiteracy</span>
<span class="c1"># Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)</span>
<span class="c1"># 1     45 289.17                           </span>
<span class="c1"># 2     47 289.25 -2 -0.078505 0.0061 0.9939</span>

<span class="c1"># code listing 8.12. Comparing models with the AIC</span>
<span class="n">fit1</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span>
           <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="n">fit2</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>

<span class="nf">AIC</span><span class="p">(</span><span class="n">fit1</span><span class="p">,</span> <span class="n">fit2</span><span class="p">)</span>
<span class="c1">#       df      AIC</span>
<span class="c1"># fit1  6 241.6429</span>
<span class="c1"># fit2  4 237.6565</span>


<span class="c1"># 8.6.2. Variable selection</span>
<span class="c1"># code listing 8.13. Backward stepwise selection</span>
<span class="nf">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span>
<span class="n">fit1</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span>
           <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="nf">stepAIC</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">direction</span> <span class="o">=</span> <span class="s">&#34;backward&#34;</span><span class="p">)</span>
<span class="c1"># Start:  AIC=97.75</span>
<span class="c1"># Murder ~ Population + Illiteracy + Income + Frost</span>
<span class="c1"># </span>
<span class="c1"># Df Sum of Sq    RSS     AIC</span>
<span class="c1"># - Frost       1     0.021 289.19  95.753</span>
<span class="c1"># - Income      1     0.057 289.22  95.759</span>
<span class="c1"># &lt;none&gt;                    289.17  97.749</span>
<span class="c1"># - Population  1    39.238 328.41 102.111</span>
<span class="c1"># - Illiteracy  1   144.264 433.43 115.986</span>
<span class="c1"># </span>
<span class="c1"># Step:  AIC=95.75</span>
<span class="c1"># Murder ~ Population + Illiteracy + Income</span>
<span class="c1"># </span>
<span class="c1"># Df Sum of Sq    RSS     AIC</span>
<span class="c1"># - Income      1     0.057 289.25  93.763</span>
<span class="c1"># &lt;none&gt;                    289.19  95.753</span>
<span class="c1"># - Population  1    43.658 332.85 100.783</span>
<span class="c1"># - Illiteracy  1   236.196 525.38 123.605</span>
<span class="c1"># </span>
<span class="c1"># Step:  AIC=93.76</span>
<span class="c1"># Murder ~ Population + Illiteracy</span>
<span class="c1"># </span>
<span class="c1"># Df Sum of Sq    RSS     AIC</span>
<span class="c1"># &lt;none&gt;                    289.25  93.763</span>
<span class="c1"># - Population  1    48.517 337.76  99.516</span>
<span class="c1"># - Illiteracy  1   299.646 588.89 127.311</span>
<span class="c1"># </span>
<span class="c1"># Call:</span>
<span class="c1">#   lm(formula = Murder ~ Population + Illiteracy, data = states)</span>
<span class="c1"># </span>
<span class="c1"># Coefficients:</span>
<span class="c1">#   (Intercept)   Population   Illiteracy  </span>
<span class="c1"># 1.6515497    0.0002242    4.0807366  </span>


<span class="c1"># code listing 8.14. All subsets regression</span>
<span class="c1"># install.packages(&#34;leaps&#34;)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">leaps</span><span class="p">)</span>
<span class="n">leaps</span> <span class="o">&lt;-</span><span class="nf">regsubsets</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span>
                     <span class="n">Frost</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">,</span> <span class="n">nbest</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">leaps</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="s">&#34;adjr2&#34;</span><span class="p">)</span> <span class="c1"># Figure 8.17</span>

<span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">subsets</span><span class="p">(</span><span class="n">leaps</span><span class="p">,</span> <span class="n">statistic</span><span class="o">=</span><span class="s">&#34;cp&#34;</span><span class="p">,</span>
        <span class="n">main</span><span class="o">=</span><span class="s">&#34;Cp Plot for All Subsets Regression&#34;</span><span class="p">)</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s">&#34;red&#34;</span><span class="p">)</span>


<span class="c1"># 8.7.1. Cross-validation</span>
<span class="c1"># code listing 8.15. Function for k-fold cross-validated R-square</span>
<span class="n">shrinkage</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="m">10</span><span class="p">){</span>
  <span class="nf">require</span><span class="p">(</span><span class="n">bootstrap</span><span class="p">)</span>
  
  <span class="n">theta.fit</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">){</span><span class="nf">lsfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)}</span>
  <span class="n">theta.predict</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="n">x</span><span class="p">){</span><span class="nf">cbind</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">x</span><span class="p">)</span><span class="o">%*%</span><span class="n">fit</span><span class="o">$</span><span class="n">coef</span><span class="p">}</span>
  
  <span class="n">x</span> <span class="o">&lt;-</span> <span class="n">fit</span><span class="o">$</span><span class="n">model[</span><span class="p">,</span><span class="m">2</span><span class="o">:</span><span class="nf">ncol</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">model</span><span class="p">)</span><span class="n">]</span>
  <span class="n">y</span> <span class="o">&lt;-</span> <span class="n">fit</span><span class="o">$</span><span class="n">model[</span><span class="p">,</span><span class="m">1</span><span class="n">]</span>
  
  <span class="n">results</span> <span class="o">&lt;-</span> <span class="nf">crossval</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta.fit</span><span class="p">,</span> <span class="n">theta.predict</span><span class="p">,</span> <span class="n">ngroup</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
  <span class="n">r2</span> <span class="o">&lt;-</span> <span class="nf">cor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">fit</span><span class="o">$</span><span class="n">fitted.values</span><span class="p">)</span><span class="n">^2</span>
  <span class="n">r2cv</span> <span class="o">&lt;-</span> <span class="nf">cor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">results</span><span class="o">$</span><span class="n">cv.fit</span><span class="p">)</span><span class="n">^2</span>
  <span class="nf">cat</span><span class="p">(</span><span class="s">&#34;Original R-square =&#34;</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="s">&#34;\n&#34;</span><span class="p">)</span>
  <span class="nf">cat</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="s">&#34;Fold Cross-Validated R-square =&#34;</span><span class="p">,</span> <span class="n">r2cv</span><span class="p">,</span> <span class="s">&#34;\n&#34;</span><span class="p">)</span>
  <span class="nf">cat</span><span class="p">(</span><span class="s">&#34;Change =&#34;</span><span class="p">,</span> <span class="n">r2</span><span class="o">-</span><span class="n">r2cv</span><span class="p">,</span> <span class="s">&#34;\n&#34;</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="nf">shrinkage</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="c1"># Original R-square = 0.5669502</span>
<span class="c1"># 10 Fold Cross-Validated R-square = 0.4240783</span>
<span class="c1"># Change = 0.1428719</span>


<span class="n">fit2</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="nf">shrinkage</span><span class="p">(</span><span class="n">fit2</span><span class="p">)</span>
<span class="c1"># Original R-square = 0.5668327</span>
<span class="c1"># 10 Fold Cross-Validated R-square = 0.5332059</span>
<span class="c1"># Change = 0.03362679</span>


<span class="c1"># 8.7.2. Relative importance</span>
<span class="n">zstates</span> <span class="o">&lt;-</span> <span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">scale</span><span class="p">(</span><span class="n">states</span><span class="p">))</span>
<span class="n">zfit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span><span class="o">~</span><span class="n">Population</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">zstates</span><span class="p">)</span>
<span class="nf">coef</span><span class="p">(</span><span class="n">zfit</span><span class="p">)</span>
<span class="c1">#   (Intercept)    Population        Income    Illiteracy         Frost</span>
<span class="c1"># -2.054026e-16  2.705095e-01  1.072372e-02  6.840496e-01  8.185407e-03</span>


<span class="c1"># code listing 8.16. relweights() function </span>
<span class="c1"># for calculating relative importance of predictors</span>
<span class="n">relweights</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="kc">...</span><span class="p">){</span>
  <span class="n">R</span> <span class="o">&lt;-</span> <span class="nf">cor</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">model</span><span class="p">)</span>
  <span class="n">nvar</span> <span class="o">&lt;-</span> <span class="nf">ncol</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
  <span class="n">rxx</span> <span class="o">&lt;-</span> <span class="n">R[2</span><span class="o">:</span><span class="n">nvar</span><span class="p">,</span> <span class="m">2</span><span class="o">:</span><span class="n">nvar]</span>
  <span class="n">rxy</span> <span class="o">&lt;-</span> <span class="n">R[2</span><span class="o">:</span><span class="n">nvar</span><span class="p">,</span> <span class="m">1</span><span class="n">]</span>
  <span class="n">svd</span> <span class="o">&lt;-</span> <span class="nf">eigen</span><span class="p">(</span><span class="n">rxx</span><span class="p">)</span>
  <span class="n">evec</span> <span class="o">&lt;-</span> <span class="n">svd</span><span class="o">$</span><span class="n">vectors</span>
  <span class="n">ev</span> <span class="o">&lt;-</span> <span class="n">svd</span><span class="o">$</span><span class="n">values</span>
  <span class="n">delta</span> <span class="o">&lt;-</span> <span class="nf">diag</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">ev</span><span class="p">))</span>
  <span class="n">lambda</span> <span class="o">&lt;-</span> <span class="n">evec</span> <span class="o">%*%</span> <span class="n">delta</span> <span class="o">%*%</span> <span class="nf">t</span><span class="p">(</span><span class="n">evec</span><span class="p">)</span>
  <span class="n">lambdasq</span> <span class="o">&lt;-</span> <span class="n">lambda</span> <span class="n">^</span> <span class="m">2</span>
  <span class="n">beta</span> <span class="o">&lt;-</span> <span class="nf">solve</span><span class="p">(</span><span class="n">lambda</span><span class="p">)</span> <span class="o">%*%</span> <span class="n">rxy</span>
  <span class="n">rsquare</span> <span class="o">&lt;-</span> <span class="nf">colSums</span><span class="p">(</span><span class="n">beta</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span>
  <span class="n">rawwgt</span> <span class="o">&lt;-</span> <span class="n">lambdasq</span> <span class="o">%*%</span> <span class="n">beta</span> <span class="n">^</span> <span class="m">2</span>
  <span class="n">import</span> <span class="o">&lt;-</span> <span class="p">(</span><span class="n">rawwgt</span> <span class="o">/</span> <span class="n">rsquare</span><span class="p">)</span> <span class="o">*</span> <span class="m">100</span>
  <span class="n">lbls</span> <span class="o">&lt;-</span> <span class="nf">names</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">model[2</span><span class="o">:</span><span class="n">nvar]</span><span class="p">)</span>
  <span class="nf">rownames</span><span class="p">(</span><span class="n">import</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="n">lbls</span>
  <span class="nf">colnames</span><span class="p">(</span><span class="n">import</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="s">&#34;Weights&#34;</span>
  <span class="nf">barplot</span><span class="p">(</span><span class="nf">t</span><span class="p">(</span><span class="n">import</span><span class="p">),</span><span class="n">names.arg</span><span class="o">=</span><span class="n">lbls</span><span class="p">,</span>
          <span class="n">ylab</span><span class="o">=</span><span class="s">&#34;% of R-Square&#34;</span><span class="p">,</span>
          <span class="n">xlab</span><span class="o">=</span><span class="s">&#34;Predictor Variables&#34;</span><span class="p">,</span>
          <span class="n">main</span><span class="o">=</span><span class="s">&#34;Relative Importance of Predictor Variables&#34;</span><span class="p">,</span>
          <span class="n">sub</span><span class="o">=</span><span class="nf">paste</span><span class="p">(</span><span class="s">&#34;R-Square=&#34;</span><span class="p">,</span> <span class="nf">round</span><span class="p">(</span><span class="n">rsquare</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">3</span><span class="p">)),</span>
          <span class="kc">...</span><span class="p">)</span>
  <span class="nf">return</span><span class="p">(</span><span class="n">import</span><span class="p">)</span>
<span class="p">}</span>


<span class="n">relweights2</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="kc">...</span><span class="p">){</span>
  <span class="n">R</span> <span class="o">&lt;-</span> <span class="nf">cor</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">model</span><span class="p">)</span>
  <span class="n">nvar</span> <span class="o">&lt;-</span> <span class="nf">ncol</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
  <span class="n">rxx</span> <span class="o">&lt;-</span> <span class="n">R[2</span><span class="o">:</span><span class="n">nvar</span><span class="p">,</span> <span class="m">2</span><span class="o">:</span><span class="n">nvar]</span>
  <span class="n">rxy</span> <span class="o">&lt;-</span> <span class="n">R[2</span><span class="o">:</span><span class="n">nvar</span><span class="p">,</span> <span class="m">1</span><span class="n">]</span>
  <span class="n">svd</span> <span class="o">&lt;-</span> <span class="nf">eigen</span><span class="p">(</span><span class="n">rxx</span><span class="p">)</span>
  <span class="n">evec</span> <span class="o">&lt;-</span> <span class="n">svd</span><span class="o">$</span><span class="n">vectors</span>
  <span class="n">ev</span> <span class="o">&lt;-</span> <span class="n">svd</span><span class="o">$</span><span class="n">values</span>
  <span class="n">delta</span> <span class="o">&lt;-</span> <span class="nf">diag</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">ev</span><span class="p">))</span>
  <span class="n">lambda</span> <span class="o">&lt;-</span> <span class="n">evec</span> <span class="o">%*%</span> <span class="n">delta</span> <span class="o">%*%</span> <span class="nf">t</span><span class="p">(</span><span class="n">evec</span><span class="p">)</span>
  <span class="n">lambdasq</span> <span class="o">&lt;-</span> <span class="n">lambda</span> <span class="n">^</span> <span class="m">2</span>
  <span class="n">beta</span> <span class="o">&lt;-</span> <span class="nf">solve</span><span class="p">(</span><span class="n">lambda</span><span class="p">)</span> <span class="o">%*%</span> <span class="n">rxy</span>
  <span class="n">rsquare</span> <span class="o">&lt;-</span> <span class="nf">colSums</span><span class="p">(</span><span class="n">beta</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span>
  <span class="n">rawwgt</span> <span class="o">&lt;-</span> <span class="n">lambdasq</span> <span class="o">%*%</span> <span class="n">beta</span> <span class="n">^</span> <span class="m">2</span>
  <span class="n">import</span> <span class="o">&lt;-</span> <span class="p">(</span><span class="n">rawwgt</span> <span class="o">/</span> <span class="n">rsquare</span><span class="p">)</span> <span class="o">*</span> <span class="m">100</span>
  <span class="n">lbls</span> <span class="o">&lt;-</span> <span class="nf">names</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">model[2</span><span class="o">:</span><span class="n">nvar]</span><span class="p">)</span>
  <span class="nf">rownames</span><span class="p">(</span><span class="n">import</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="n">lbls</span>
  <span class="nf">colnames</span><span class="p">(</span><span class="n">import</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="s">&#34;Weights&#34;</span>
  <span class="nf">dotplot</span><span class="p">(</span><span class="nf">t</span><span class="p">(</span><span class="n">import</span><span class="p">),</span><span class="n">names.arg</span><span class="o">=</span><span class="n">lbls</span><span class="p">,</span>
          <span class="n">ylab</span><span class="o">=</span><span class="s">&#34;% of R-Square&#34;</span><span class="p">,</span>
          <span class="n">xlab</span><span class="o">=</span><span class="s">&#34;Predictor Variables&#34;</span><span class="p">,</span>
          <span class="n">main</span><span class="o">=</span><span class="s">&#34;Relative Importance of Predictor Variables&#34;</span><span class="p">,</span>
          <span class="n">sub</span><span class="o">=</span><span class="nf">paste</span><span class="p">(</span><span class="s">&#34;R-Square=&#34;</span><span class="p">,</span> <span class="nf">round</span><span class="p">(</span><span class="n">rsquare</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="m">3</span><span class="p">)),</span>
          <span class="kc">...</span><span class="p">)</span>
  <span class="nf">return</span><span class="p">(</span><span class="n">import</span><span class="p">)</span>
<span class="p">}</span>
<span class="c1"># code listing 8.17. Applying the relweights() function</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">Murder</span> <span class="o">~</span> <span class="n">Population</span> <span class="o">+</span> <span class="n">Illiteracy</span> <span class="o">+</span> <span class="n">Income</span> <span class="o">+</span> <span class="n">Frost</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="nf">relweights</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">&#34;lightgrey&#34;</span><span class="p">)</span>
<span class="c1">#             Weights</span>
<span class="c1"># Population 14.723401</span>
<span class="c1"># Illiteracy 59.000195</span>
<span class="c1"># Income      5.488962</span>
<span class="c1"># Frost      20.787442</span>
</code></pre></td></tr></table>
</div>
</div>
    </div>

    
    


    
    

    <footer class="post-footer">
      <div class="post-tags">
          <a href="https://xiaonilee.github.io/tags/r/">R</a>
          <a href="https://xiaonilee.github.io/tags/r-in-action/">R in Action</a>
          <a href="https://xiaonilee.github.io/tags/bioinformatics/">Bioinformatics</a>
          <a href="https://xiaonilee.github.io/tags/book/">Book</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/rinaction9/">
            
            <i class="iconfont">
              <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

            </i>
            <span class="prev-text nav-default">Chapter 9. Analysis of variance</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/rinaction7/">
            <span class="next-text nav-default">Chapter 7. Basic statistics</span>
            <span class="prev-text nav-mobile">Next</span>
            
            <i class="iconfont">
              <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

            </i>
          </a>
      </nav>
    </footer>
  </article>

  
  

  
  

  

  
  

  

  

  

    

  

        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="icon-links">
  
  
    <a href="mailto:xiaoni0601@gmail.com" rel="me noopener" class="iconfont"
      title="email" >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://github.com/xiaonilee" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>


<a href="https://xiaonilee.github.io/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
   
</div>

<div class="copyright">

  <span class="copyright-year">
    &copy;
    2020
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        xiaonilee
        
      </span></span>

  
  

  
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont">
        
        <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

      </i>
    </div>
  </div>
  
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js" integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin="anonymous"></script>



  <script type="text/javascript">
    window.MathJax = {
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script>









  
    <script type="text/javascript" src="/js/load-photoswipe.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  















</body>
</html>
