{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow2class2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzXuP0YcTxF0"
      },
      "source": [
        "# Class2: 神经网络优化\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "### Setup virtul environment\n",
        "\n",
        "- `python3.6.9` + `TensorFlow2.3.0` + `sklearn` + `pandas` + `matplotlib`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRsUsITYWDnd"
      },
      "source": [
        "## 2.1 预备知识\n",
        "\n",
        "- tf.where(条件语句, 真返回A, 假返回B)\n",
        "- np.random.RandomState.rand(), 返回一个[0,1)之间的随机数\n",
        "- np.vstack(),将两个数组按照垂直方向叠加\n",
        "- np.mgrid[起始值:结束值:步长, 起始值:结束值:步长]; [起始值:结束值)\n",
        "- .ravel(), 将x变为一维数组，把.前变量拉直\n",
        "- np.c_[],使得返回的间隔数值点配对"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsC54XSTTdPQ",
        "outputId": "84d5662e-cc92-4665-b487-0291d292a9fe"
      },
      "source": [
        "# p4_where.py\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "a = tf.constant([1, 2, 3, 1, 1])\n",
        "b = tf.constant([0, 1, 3, 4, 5])\n",
        "c = tf.where(tf.greater(a, b), a, b)  # 若a>b，返回a对应位置的元素，否则返回b对应位置的元素\n",
        "print(\"c：\", c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c： tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGHN7sKjXsIa",
        "outputId": "99a74852-46ff-4d66-8c3a-ff2936655742"
      },
      "source": [
        "# p5_RandomState.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "rdm = np.random.RandomState(seed=1)\n",
        "a = rdm.rand()      # 返回一个随机标量\n",
        "b = rdm.rand(2, 3)  # 返回维度为2行3列的随机数矩阵\n",
        "print(\"a:\", a)\n",
        "print(\"b:\", b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a: 0.417022004702574\n",
            "b: [[7.20324493e-01 1.14374817e-04 3.02332573e-01]\n",
            " [1.46755891e-01 9.23385948e-02 1.86260211e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT3Mb_9TalZ1",
        "outputId": "002755e2-863e-4ad2-ad7f-3e79e30ff40f"
      },
      "source": [
        "# p6_vstack.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "c = np.vstack((a, b))\n",
        "print(\"a:\\n\", a)\n",
        "print(\"c:\\n\", c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a:\n",
            " [1 2 3]\n",
            "c:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcYLV94xcTRB",
        "outputId": "d694635e-a30f-4a88-8f08-f561cd076f15"
      },
      "source": [
        "# p7_mgrid.py\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 生成等间隔数值点\n",
        "x, y = np.mgrid[1:3:1, 2:4:0.5]\n",
        "# 将x, y拉直，并合并配对为二维张量，生成二维坐标点\n",
        "grid = np.c_[x.ravel(), y.ravel()]\n",
        "print(\"x:\\n\", x)\n",
        "print(\"y:\\n\", y)\n",
        "print(\"x.ravel():\\n\", x.ravel())\n",
        "print(\"y.ravel():\\n\", y.ravel())\n",
        "print('grid:\\n', grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x:\n",
            " [[1. 1. 1. 1.]\n",
            " [2. 2. 2. 2.]]\n",
            "y:\n",
            " [[2.  2.5 3.  3.5]\n",
            " [2.  2.5 3.  3.5]]\n",
            "x.ravel():\n",
            " [1. 1. 1. 1. 2. 2. 2. 2.]\n",
            "y.ravel():\n",
            " [2.  2.5 3.  3.5 2.  2.5 3.  3.5]\n",
            "grid:\n",
            " [[1.  2. ]\n",
            " [1.  2.5]\n",
            " [1.  3. ]\n",
            " [1.  3.5]\n",
            " [2.  2. ]\n",
            " [2.  2.5]\n",
            " [2.  3. ]\n",
            " [2.  3.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INWGNzredkyh"
      },
      "source": [
        "## 2.2 复杂度学习率\n",
        "- 神经网络(**NN**)复杂度:多用NN层数和NN参数的个数表示\n",
        "  - 空间复杂度, 层数 = 隐藏层的层数 + 1个输出层\n",
        "  - 时间复杂度, 乘加运算次数\n",
        "- **指数**衰减学习率\n",
        "  - 初始学习率 * 学习率衰减率 ^ (当前轮数 / 多少轮衰减一次)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wsxDj-Bh5NP",
        "outputId": "f48e3a79-2130-43c7-fbff-d400d78ab6a0"
      },
      "source": [
        "# p10_backpropagation_decaylr.py\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "w = tf.Variable(tf.constant(5, dtype=tf.float32))\n",
        "\n",
        "epoch = 40\n",
        "LR_BASE = 0.2  # 最初学习率\n",
        "LR_DECAY = 0.99  # 学习率衰减率\n",
        "LR_STEP = 1  # 喂入多少轮BATCH_SIZE后，更新一次学习率\n",
        "\n",
        "for epoch in range(epoch):  # for epoch 定义顶层循环，表示对数据集循环epoch次，此例数据集数据仅有1个w,初始化时候constant赋值为5，循环100次迭代。\n",
        "    lr = LR_BASE * LR_DECAY ** (epoch / LR_STEP)\n",
        "    with tf.GradientTape() as tape:  # with结构到grads框起了梯度的计算过程。\n",
        "        loss = tf.square(w + 1)\n",
        "    grads = tape.gradient(loss, w)  # .gradient函数告知谁对谁求导\n",
        "\n",
        "    w.assign_sub(lr * grads)  # .assign_sub 对变量做自减 即：w -= lr*grads 即 w = w - lr*grads\n",
        "    print(\"After %s epoch,w is %f,loss is %f,lr is %f\" % (epoch, w.numpy(), loss, lr))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 0 epoch,w is 2.600000,loss is 36.000000,lr is 0.200000\n",
            "After 1 epoch,w is 1.174400,loss is 12.959999,lr is 0.198000\n",
            "After 2 epoch,w is 0.321948,loss is 4.728015,lr is 0.196020\n",
            "After 3 epoch,w is -0.191126,loss is 1.747547,lr is 0.194060\n",
            "After 4 epoch,w is -0.501926,loss is 0.654277,lr is 0.192119\n",
            "After 5 epoch,w is -0.691392,loss is 0.248077,lr is 0.190198\n",
            "After 6 epoch,w is -0.807611,loss is 0.095239,lr is 0.188296\n",
            "After 7 epoch,w is -0.879339,loss is 0.037014,lr is 0.186413\n",
            "After 8 epoch,w is -0.923874,loss is 0.014559,lr is 0.184549\n",
            "After 9 epoch,w is -0.951691,loss is 0.005795,lr is 0.182703\n",
            "After 10 epoch,w is -0.969167,loss is 0.002334,lr is 0.180876\n",
            "After 11 epoch,w is -0.980209,loss is 0.000951,lr is 0.179068\n",
            "After 12 epoch,w is -0.987226,loss is 0.000392,lr is 0.177277\n",
            "After 13 epoch,w is -0.991710,loss is 0.000163,lr is 0.175504\n",
            "After 14 epoch,w is -0.994591,loss is 0.000069,lr is 0.173749\n",
            "After 15 epoch,w is -0.996452,loss is 0.000029,lr is 0.172012\n",
            "After 16 epoch,w is -0.997660,loss is 0.000013,lr is 0.170292\n",
            "After 17 epoch,w is -0.998449,loss is 0.000005,lr is 0.168589\n",
            "After 18 epoch,w is -0.998967,loss is 0.000002,lr is 0.166903\n",
            "After 19 epoch,w is -0.999308,loss is 0.000001,lr is 0.165234\n",
            "After 20 epoch,w is -0.999535,loss is 0.000000,lr is 0.163581\n",
            "After 21 epoch,w is -0.999685,loss is 0.000000,lr is 0.161946\n",
            "After 22 epoch,w is -0.999786,loss is 0.000000,lr is 0.160326\n",
            "After 23 epoch,w is -0.999854,loss is 0.000000,lr is 0.158723\n",
            "After 24 epoch,w is -0.999900,loss is 0.000000,lr is 0.157136\n",
            "After 25 epoch,w is -0.999931,loss is 0.000000,lr is 0.155564\n",
            "After 26 epoch,w is -0.999952,loss is 0.000000,lr is 0.154009\n",
            "After 27 epoch,w is -0.999967,loss is 0.000000,lr is 0.152469\n",
            "After 28 epoch,w is -0.999977,loss is 0.000000,lr is 0.150944\n",
            "After 29 epoch,w is -0.999984,loss is 0.000000,lr is 0.149434\n",
            "After 30 epoch,w is -0.999989,loss is 0.000000,lr is 0.147940\n",
            "After 31 epoch,w is -0.999992,loss is 0.000000,lr is 0.146461\n",
            "After 32 epoch,w is -0.999994,loss is 0.000000,lr is 0.144996\n",
            "After 33 epoch,w is -0.999996,loss is 0.000000,lr is 0.143546\n",
            "After 34 epoch,w is -0.999997,loss is 0.000000,lr is 0.142111\n",
            "After 35 epoch,w is -0.999998,loss is 0.000000,lr is 0.140690\n",
            "After 36 epoch,w is -0.999999,loss is 0.000000,lr is 0.139283\n",
            "After 37 epoch,w is -0.999999,loss is 0.000000,lr is 0.137890\n",
            "After 38 epoch,w is -0.999999,loss is 0.000000,lr is 0.136511\n",
            "After 39 epoch,w is -0.999999,loss is 0.000000,lr is 0.135146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WdhPcrikNp3"
      },
      "source": [
        "## 2.3 激活函数\n",
        "- 非线性函数\n",
        "- 大大提升列模型的表达力\n",
        "- 优秀的激活函数特征\n",
        "  - 非线性, 多层神经网络可逼近所有函数\n",
        "  - 可微性, 优化器大多用梯度下降更新参数\n",
        "  - 单调性, 保证单层网络的损失函数是凸函数\n",
        "  - 近似恒等性: f(x)≈x, 神经网络更稳定\n",
        "- Sigmoid函数\n",
        "  - tf.nn. sigmoid(x)\n",
        "- Tanh函数\n",
        "  - tf.math. tanh(x)\n",
        "- Relu函数,对于初学者首选该函数\n",
        "  - tf.nn.relu(x)\n",
        "- Leaky Relu函数\n",
        "  - tf.nn.leaky_relu(x)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMLGSVzzqQ0U"
      },
      "source": [
        "## 2.4 损失函数\n",
        "- 预测值(**y**)与已知答案(**y_**)的差距\n",
        "- NN 优化的**终极**, **重点**目标, 使得**loss**最小\n",
        "  - MSE\n",
        "    - loss_mse = tf.reduce_mean()\n",
        "  - 自定义\n",
        "    - tf.reduce_sum(tf.where(tf.greater())\n",
        "  - CE\n",
        "    - tf.losses.categorical_crossentropy()\n",
        "- 案例\n",
        "  - 预测酸奶日销量y，x1、x2是影响日销量的因素\n",
        "  - 没有真实数据集，现通过随机生成来拟造"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOh-rUx8HXl4",
        "outputId": "65fd5c04-89c2-4d93-924f-189841c4354d"
      },
      "source": [
        "# p19_mse.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "SEED = 23455\n",
        "\n",
        "rdm = np.random.RandomState(seed=SEED)  # 生成[0,1)之间的随机数\n",
        "x = rdm.rand(32, 2)\n",
        "y_ = [[x1 + x2 + (rdm.rand() / 10.0 - 0.05)] for (x1, x2) in x]  # 生成随机噪声[0,1)/10=[0,0.1); [0,0.1)-0.05=[-0.05,0.05)\n",
        "x = tf.cast(x, dtype=tf.float32)      # 强制转变x数据类型为tf\n",
        "\n",
        "w1 = tf.Variable(tf.random.normal([2, 1], stddev=1, seed=1))    # 随机初始化参数w1为2行1列\n",
        "\n",
        "epoch = 15000\n",
        "lr = 0.002\n",
        "\n",
        "for epoch in range(epoch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y = tf.matmul(x, w1)    # 求前向传播计算结果y\n",
        "        loss_mse = tf.reduce_mean(tf.square(y_ - y))\n",
        "\n",
        "    grads = tape.gradient(loss_mse, w1)   # loss函数，对待训练参数w1求偏导\n",
        "    w1.assign_sub(lr * grads)   # 更新参数w1\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(\"After %d training steps,w1 is \" % (epoch))\n",
        "        print(w1.numpy(), \"\\n\")\n",
        "print(\"Final w1 is: \", w1.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 0 training steps,w1 is \n",
            "[[-0.8096241]\n",
            " [ 1.4855157]] \n",
            "\n",
            "After 500 training steps,w1 is \n",
            "[[-0.21934734]\n",
            " [ 1.6984866 ]] \n",
            "\n",
            "After 1000 training steps,w1 is \n",
            "[[0.08939707]\n",
            " [1.673225  ]] \n",
            "\n",
            "After 1500 training steps,w1 is \n",
            "[[0.2836882]\n",
            " [1.5853056]] \n",
            "\n",
            "After 2000 training steps,w1 is \n",
            "[[0.42324296]\n",
            " [1.4906038 ]] \n",
            "\n",
            "After 2500 training steps,w1 is \n",
            "[[0.531055 ]\n",
            " [1.4053345]] \n",
            "\n",
            "After 3000 training steps,w1 is \n",
            "[[0.61725086]\n",
            " [1.3328412 ]] \n",
            "\n",
            "After 3500 training steps,w1 is \n",
            "[[0.68720096]\n",
            " [1.2725208 ]] \n",
            "\n",
            "After 4000 training steps,w1 is \n",
            "[[0.7443261]\n",
            " [1.2227542]] \n",
            "\n",
            "After 4500 training steps,w1 is \n",
            "[[0.7910986]\n",
            " [1.1818361]] \n",
            "\n",
            "After 5000 training steps,w1 is \n",
            "[[0.8294352]\n",
            " [1.1482395]] \n",
            "\n",
            "After 5500 training steps,w1 is \n",
            "[[0.86087203]\n",
            " [1.1206709 ]] \n",
            "\n",
            "After 6000 training steps,w1 is \n",
            "[[0.8866551]\n",
            " [1.098054 ]] \n",
            "\n",
            "After 6500 training steps,w1 is \n",
            "[[0.9078028]\n",
            " [1.0795006]] \n",
            "\n",
            "After 7000 training steps,w1 is \n",
            "[[0.9251489]\n",
            " [1.0642821]] \n",
            "\n",
            "After 7500 training steps,w1 is \n",
            "[[0.9393773]\n",
            " [1.0517985]] \n",
            "\n",
            "After 8000 training steps,w1 is \n",
            "[[0.9510481]\n",
            " [1.041559 ]] \n",
            "\n",
            "After 8500 training steps,w1 is \n",
            "[[0.9606211]\n",
            " [1.0331596]] \n",
            "\n",
            "After 9000 training steps,w1 is \n",
            "[[0.96847343]\n",
            " [1.02627   ]] \n",
            "\n",
            "After 9500 training steps,w1 is \n",
            "[[0.9749144]\n",
            " [1.0206192]] \n",
            "\n",
            "After 10000 training steps,w1 is \n",
            "[[0.9801975]\n",
            " [1.0159837]] \n",
            "\n",
            "After 10500 training steps,w1 is \n",
            "[[0.9845312]\n",
            " [1.0121814]] \n",
            "\n",
            "After 11000 training steps,w1 is \n",
            "[[0.9880858]\n",
            " [1.0090628]] \n",
            "\n",
            "After 11500 training steps,w1 is \n",
            "[[0.99100184]\n",
            " [1.0065047 ]] \n",
            "\n",
            "After 12000 training steps,w1 is \n",
            "[[0.9933934]\n",
            " [1.0044063]] \n",
            "\n",
            "After 12500 training steps,w1 is \n",
            "[[0.9953551]\n",
            " [1.0026854]] \n",
            "\n",
            "After 13000 training steps,w1 is \n",
            "[[0.9969639]\n",
            " [1.0012728]] \n",
            "\n",
            "After 13500 training steps,w1 is \n",
            "[[0.99828357]\n",
            " [1.0001147 ]] \n",
            "\n",
            "After 14000 training steps,w1 is \n",
            "[[0.9993659]\n",
            " [0.999166 ]] \n",
            "\n",
            "After 14500 training steps,w1 is \n",
            "[[1.0002553 ]\n",
            " [0.99838644]] \n",
            "\n",
            "Final w1 is:  [[1.0009792]\n",
            " [0.9977485]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yAYjQmoPY5h",
        "outputId": "a1909177-6810-46f9-ec74-491b9b6a2a0b"
      },
      "source": [
        "# p20_custom.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "SEED = 23455\n",
        "COST = 1\n",
        "PROFIT = 99\n",
        "\n",
        "rdm = np.random.RandomState(SEED)\n",
        "x = rdm.rand(32, 2)\n",
        "y_ = [[x1 + x2 + (rdm.rand() / 10.0 - 0.05)] for (x1, x2) in x]  # 生成噪声[0,1)/10=[0,0.1); [0,0.1)-0.05=[-0.05,0.05)\n",
        "x = tf.cast(x, dtype=tf.float32)\n",
        "\n",
        "w1 = tf.Variable(tf.random.normal([2, 1], stddev=1, seed=1))\n",
        "\n",
        "epoch = 10000\n",
        "lr = 0.002\n",
        "\n",
        "for epoch in range(epoch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y = tf.matmul(x, w1)\n",
        "        loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y - y_) * COST, (y_ - y) * PROFIT))   # 自定义损失函数\n",
        "\n",
        "    grads = tape.gradient(loss, w1)\n",
        "    w1.assign_sub(lr * grads)\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(\"After %d training steps,w1 is \" % (epoch))\n",
        "        print(w1.numpy(), \"\\n\")\n",
        "print(\"Final w1 is: \", w1.numpy())\n",
        "\n",
        "# 自定义损失函数\n",
        "# 酸奶成本1元， 酸奶利润99元\n",
        "# 成本很低，利润很高，人们希望多预测些，生成模型系数大于1，往多了预测"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 0 training steps,w1 is \n",
            "[[2.8786578]\n",
            " [3.2517848]] \n",
            "\n",
            "After 500 training steps,w1 is \n",
            "[[1.1460369]\n",
            " [1.0672572]] \n",
            "\n",
            "After 1000 training steps,w1 is \n",
            "[[1.1364173]\n",
            " [1.0985414]] \n",
            "\n",
            "After 1500 training steps,w1 is \n",
            "[[1.1267972]\n",
            " [1.1298251]] \n",
            "\n",
            "After 2000 training steps,w1 is \n",
            "[[1.1758107]\n",
            " [1.1724023]] \n",
            "\n",
            "After 2500 training steps,w1 is \n",
            "[[1.1453722]\n",
            " [1.0272155]] \n",
            "\n",
            "After 3000 training steps,w1 is \n",
            "[[1.1357522]\n",
            " [1.0584993]] \n",
            "\n",
            "After 3500 training steps,w1 is \n",
            "[[1.1261321]\n",
            " [1.0897831]] \n",
            "\n",
            "After 4000 training steps,w1 is \n",
            "[[1.1751455]\n",
            " [1.1323601]] \n",
            "\n",
            "After 4500 training steps,w1 is \n",
            "[[1.1655253]\n",
            " [1.1636437]] \n",
            "\n",
            "After 5000 training steps,w1 is \n",
            "[[1.1350871]\n",
            " [1.0184573]] \n",
            "\n",
            "After 5500 training steps,w1 is \n",
            "[[1.1254673]\n",
            " [1.0497413]] \n",
            "\n",
            "After 6000 training steps,w1 is \n",
            "[[1.1158477]\n",
            " [1.0810255]] \n",
            "\n",
            "After 6500 training steps,w1 is \n",
            "[[1.1062276]\n",
            " [1.1123092]] \n",
            "\n",
            "After 7000 training steps,w1 is \n",
            "[[1.1552413]\n",
            " [1.1548865]] \n",
            "\n",
            "After 7500 training steps,w1 is \n",
            "[[1.1248026]\n",
            " [1.0096996]] \n",
            "\n",
            "After 8000 training steps,w1 is \n",
            "[[1.1151826]\n",
            " [1.0409834]] \n",
            "\n",
            "After 8500 training steps,w1 is \n",
            "[[1.1055626]\n",
            " [1.0722672]] \n",
            "\n",
            "After 9000 training steps,w1 is \n",
            "[[1.1545763]\n",
            " [1.1148446]] \n",
            "\n",
            "After 9500 training steps,w1 is \n",
            "[[1.144956]\n",
            " [1.146128]] \n",
            "\n",
            "Final w1 is:  [[1.1255957]\n",
            " [1.0237043]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ozp6sNLT0P8",
        "outputId": "d9d4f46a-19dc-478d-f999-676f08e1a77a"
      },
      "source": [
        "# p22_ce.py\n",
        "# 已知答案y_=(1,0), 预测y1=(0.6, 0.4), y2=(0.8, 0.2)--> y2更准确\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "loss_ce1 = tf.losses.categorical_crossentropy([1, 0], [0.6, 0.4])\n",
        "loss_ce2 = tf.losses.categorical_crossentropy([1, 0], [0.8, 0.2])\n",
        "print(\"loss_ce1:\", loss_ce1)\n",
        "print(\"loss_ce2:\", loss_ce2)\n",
        "\n",
        "# 交叉熵损失函数"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_ce1: tf.Tensor(0.5108256, shape=(), dtype=float32)\n",
            "loss_ce2: tf.Tensor(0.22314353, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy4tAR22VCOb",
        "outputId": "f12d5ffb-38d9-4a4d-f401-c30ac176d791"
      },
      "source": [
        "# p23_softmaxce.py\n",
        "\n",
        "# softmax与交叉熵损失函数的结合\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "y_ = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]])\n",
        "y = np.array([[12, 3, 2], [3, 10, 1], [1, 2, 5], [4, 6.5, 1.2], [3, 6, 1]])\n",
        "y_pro = tf.nn.softmax(y)\n",
        "loss_ce1 = tf.losses.categorical_crossentropy(y_,y_pro)\n",
        "loss_ce2 = tf.nn.softmax_cross_entropy_with_logits(y_, y)\n",
        "\n",
        "print('分步计算的结果:\\n', loss_ce1)\n",
        "print('结合计算的结果:\\n', loss_ce2)\n",
        "\n",
        "\n",
        "# 输出的结果相同"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "分步计算的结果:\n",
            " tf.Tensor(\n",
            "[1.68795487e-04 1.03475622e-03 6.58839038e-02 2.58349207e+00\n",
            " 5.49852354e-02], shape=(5,), dtype=float64)\n",
            "结合计算的结果:\n",
            " tf.Tensor(\n",
            "[1.68795487e-04 1.03475622e-03 6.58839038e-02 2.58349207e+00\n",
            " 5.49852354e-02], shape=(5,), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwMwgaJGWHjQ"
      },
      "source": [
        "## 2.5 缓解过拟合\n",
        "- 欠拟合, 学习不够彻底\n",
        "  - 增加输入特征项\n",
        "  - 增加网络参数\n",
        "  - 减少正则化参数\n",
        "- 过拟合, 缺乏泛化力\n",
        "  - 数据清洗，减少集中噪声\n",
        "  - 增大训练集\n",
        "  - 采用正则化\n",
        "  - 增大正则化参数\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXomorcDk6A-"
      },
      "source": [
        "### upload the file to sample_data\n",
        "- `dot.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4FpjKqBkAt4",
        "outputId": "e154e119-c2e7-4768-ad8f-ab3f78343114"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "HZtYlAqBiwxg",
        "outputId": "04ddf6e0-2a8a-49e7-e555-5db77faf873e"
      },
      "source": [
        "# p29_regularizationfree.py\n",
        "\n",
        "# 导入所需模块\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 读入数据/标签 生成x_train y_train\n",
        "df = pd.read_csv('./sample_data/dot.csv')\n",
        "x_data = np.array(df[['x1', 'x2']])\n",
        "y_data = np.array(df['y_c'])\n",
        "\n",
        "x_train = np.vstack(x_data).reshape(-1, 2)\n",
        "y_train = np.vstack(y_data).reshape(-1, 1)\n",
        "\n",
        "Y_c = [['red' if y else 'blue'] for y in y_train]\n",
        "\n",
        "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型问题报错\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "y_train = tf.cast(y_train, tf.float32)\n",
        "\n",
        "# from_tensor_slices函数切分传入的张量的第一个维度，生成相应的数据集，使输入特征和标签值一一对应\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "\n",
        "# 生成神经网络的参数，输入层为2个神经元，隐藏层为11个神经元(数字11是作者随便选的隐藏层神经元个数)，1层隐藏层，输出层为1个神经元\n",
        "# 用tf.Variable()保证参数可训练\n",
        "w1 = tf.Variable(tf.random.normal([2, 11]), dtype=tf.float32)\n",
        "b1 = tf.Variable(tf.constant(0.01, shape=[11]))\n",
        "\n",
        "w2 = tf.Variable(tf.random.normal([11, 1]), dtype=tf.float32)\n",
        "b2 = tf.Variable(tf.constant(0.01, shape=[1]))\n",
        "\n",
        "lr = 0.005  # 学习率\n",
        "epoch = 800  # 循环轮数\n",
        "\n",
        "# 训练部分\n",
        "for epoch in range(epoch):\n",
        "    for step, (x_train, y_train) in enumerate(train_db):\n",
        "        with tf.GradientTape() as tape:  # 记录梯度信息\n",
        "\n",
        "            h1 = tf.matmul(x_train, w1) + b1  # 记录神经网络乘加运算\n",
        "            h1 = tf.nn.relu(h1)\n",
        "            y = tf.matmul(h1, w2) + b2\n",
        "\n",
        "            # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
        "            loss = tf.reduce_mean(tf.square(y_train - y))\n",
        "\n",
        "        # 计算loss对各个参数的梯度\n",
        "        variables = [w1, b1, w2, b2]\n",
        "        grads = tape.gradient(loss, variables)\n",
        "\n",
        "        # 实现梯度更新\n",
        "        # w1 = w1 - lr * w1_grad tape.gradient是自动求导结果与[w1, b1, w2, b2] 索引为0，1，2，3 \n",
        "        w1.assign_sub(lr * grads[0])\n",
        "        b1.assign_sub(lr * grads[1])\n",
        "        w2.assign_sub(lr * grads[2])\n",
        "        b2.assign_sub(lr * grads[3])\n",
        "\n",
        "    # 每20个epoch，打印loss信息\n",
        "    if epoch % 20 == 0:\n",
        "        print('epoch:', epoch, 'loss:', float(loss))\n",
        "\n",
        "# 预测部分\n",
        "print(\"*******predict*******\")\n",
        "# xx在-3到3之间以步长为0.01，yy在-3到3之间以步长0.01,生成间隔数值点\n",
        "xx, yy = np.mgrid[-3:3:.1, -3:3:.1]\n",
        "# 将xx , yy拉直，并合并配对为二维张量，生成二维坐标点\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "grid = tf.cast(grid, tf.float32)\n",
        "# 将网格坐标点喂入神经网络，进行预测，probs为输出\n",
        "probs = []\n",
        "for x_test in grid:\n",
        "    # 使用训练好的参数进行预测\n",
        "    h1 = tf.matmul([x_test], w1) + b1\n",
        "    h1 = tf.nn.relu(h1)\n",
        "    y = tf.matmul(h1, w2) + b2  # y为预测结果\n",
        "    probs.append(y)\n",
        "\n",
        "# 取第0列给x1，取第1列给x2\n",
        "x1 = x_data[:, 0]\n",
        "x2 = x_data[:, 1]\n",
        "# probs的shape调整成xx的样子\n",
        "probs = np.array(probs).reshape(xx.shape)\n",
        "plt.scatter(x1, x2, color=np.squeeze(Y_c))  # squeeze去掉纬度是1的纬度,相当于去掉[['red'],[''blue]],内层括号变为['red','blue']\n",
        "# 把坐标xx yy和对应的值probs放入contour函数，给probs值为0.5的所有点上色  plt.show()后 显示的是红蓝点的分界线\n",
        "plt.contour(xx, yy, probs, levels=[.5])\n",
        "plt.show()\n",
        "\n",
        "# 读入红蓝点，画出分割线，不包含正则化\n",
        "# 不清楚的数据，建议print出来查看"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 loss: 3.359421968460083\n",
            "epoch: 20 loss: 0.14054758846759796\n",
            "epoch: 40 loss: 0.0627439022064209\n",
            "epoch: 60 loss: 0.055414676666259766\n",
            "epoch: 80 loss: 0.05218261480331421\n",
            "epoch: 100 loss: 0.049857307225465775\n",
            "epoch: 120 loss: 0.047774478793144226\n",
            "epoch: 140 loss: 0.04552215337753296\n",
            "epoch: 160 loss: 0.04336363449692726\n",
            "epoch: 180 loss: 0.04179024696350098\n",
            "epoch: 200 loss: 0.040529899299144745\n",
            "epoch: 220 loss: 0.03829295188188553\n",
            "epoch: 240 loss: 0.03566500544548035\n",
            "epoch: 260 loss: 0.03310241922736168\n",
            "epoch: 280 loss: 0.031065234914422035\n",
            "epoch: 300 loss: 0.02935774065554142\n",
            "epoch: 320 loss: 0.02770671807229519\n",
            "epoch: 340 loss: 0.02633594535291195\n",
            "epoch: 360 loss: 0.025345345959067345\n",
            "epoch: 380 loss: 0.024579279124736786\n",
            "epoch: 400 loss: 0.02422640286386013\n",
            "epoch: 420 loss: 0.02379726432263851\n",
            "epoch: 440 loss: 0.02342306822538376\n",
            "epoch: 460 loss: 0.023213056847453117\n",
            "epoch: 480 loss: 0.023089075461030006\n",
            "epoch: 500 loss: 0.023002395406365395\n",
            "epoch: 520 loss: 0.023047184571623802\n",
            "epoch: 540 loss: 0.0230239424854517\n",
            "epoch: 560 loss: 0.023023387417197227\n",
            "epoch: 580 loss: 0.02304433099925518\n",
            "epoch: 600 loss: 0.023065946996212006\n",
            "epoch: 620 loss: 0.0230039581656456\n",
            "epoch: 640 loss: 0.022957799956202507\n",
            "epoch: 660 loss: 0.022930903360247612\n",
            "epoch: 680 loss: 0.022932475432753563\n",
            "epoch: 700 loss: 0.022949421778321266\n",
            "epoch: 720 loss: 0.02298574335873127\n",
            "epoch: 740 loss: 0.02302846871316433\n",
            "epoch: 760 loss: 0.023059045895934105\n",
            "epoch: 780 loss: 0.023044252768158913\n",
            "*******predict*******\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "-kqRyyXji9bw",
        "outputId": "c9939468-d5bf-4190-b2f5-6f291bc94072"
      },
      "source": [
        "# p29_regularizationcontain.py\n",
        "# 相比P28, 添加l2正则化\n",
        "\n",
        "# 导入所需模块\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 读入数据/标签 生成x_train y_train\n",
        "df = pd.read_csv('./sample_data/dot.csv')\n",
        "x_data = np.array(df[['x1', 'x2']])\n",
        "y_data = np.array(df['y_c'])\n",
        "\n",
        "x_train = x_data\n",
        "y_train = y_data.reshape(-1, 1)\n",
        "\n",
        "Y_c = [['red' if y else 'blue'] for y in y_train]\n",
        "\n",
        "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型问题报错\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "y_train = tf.cast(y_train, tf.float32)\n",
        "\n",
        "# from_tensor_slices函数切分传入的张量的第一个维度，生成相应的数据集，使输入特征和标签值一一对应\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "\n",
        "# 生成神经网络的参数，输入层为2个神经元，隐藏层为11个神经元(数字11是作者随便选的隐藏层神经元个数)，2层隐藏层，输出层为1个神经元\n",
        "# 用tf.Variable()保证参数可训练\n",
        "w1 = tf.Variable(tf.random.normal([2, 11]), dtype=tf.float32)\n",
        "b1 = tf.Variable(tf.constant(0.01, shape=[11]))\n",
        "\n",
        "w2 = tf.Variable(tf.random.normal([11, 1]), dtype=tf.float32)\n",
        "b2 = tf.Variable(tf.constant(0.01, shape=[1]))\n",
        "\n",
        "lr = 0.005  # 学习率\n",
        "epoch = 800  # 循环轮数\n",
        "\n",
        "# 训练部分\n",
        "for epoch in range(epoch):\n",
        "    for step, (x_train, y_train) in enumerate(train_db):\n",
        "        with tf.GradientTape() as tape:  # 记录梯度信息\n",
        "\n",
        "            h1 = tf.matmul(x_train, w1) + b1  # 记录神经网络乘加运算\n",
        "            h1 = tf.nn.relu(h1)\n",
        "            y = tf.matmul(h1, w2) + b2\n",
        "\n",
        "            # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
        "            loss_mse = tf.reduce_mean(tf.square(y_train - y))\n",
        "            # 添加l2正则化\n",
        "            loss_regularization = []\n",
        "            # tf.nn.l2_loss(w)=sum(w ** 2) / 2\n",
        "            loss_regularization.append(tf.nn.l2_loss(w1))\n",
        "            loss_regularization.append(tf.nn.l2_loss(w2))\n",
        "            # 求和\n",
        "            # 例：x=tf.constant(([1,1,1],[1,1,1]))\n",
        "            #   tf.reduce_sum(x)\n",
        "            # >>>6\n",
        "            loss_regularization = tf.reduce_sum(loss_regularization)\n",
        "            loss = loss_mse + 0.03 * loss_regularization  # REGULARIZER = 0.03\n",
        "\n",
        "        # 计算loss对各个参数的梯度\n",
        "        variables = [w1, b1, w2, b2]\n",
        "        grads = tape.gradient(loss, variables)\n",
        "\n",
        "        # 实现梯度更新\n",
        "        # w1 = w1 - lr * w1_grad\n",
        "        w1.assign_sub(lr * grads[0])\n",
        "        b1.assign_sub(lr * grads[1])\n",
        "        w2.assign_sub(lr * grads[2])\n",
        "        b2.assign_sub(lr * grads[3])\n",
        "\n",
        "    # 每20个epoch，打印loss信息\n",
        "    if epoch % 20 == 0:\n",
        "        print('epoch:', epoch, 'loss:', float(loss))\n",
        "\n",
        "# 预测部分\n",
        "print(\"*******predict*******\")\n",
        "# xx在-3到3之间以步长为0.01，yy在-3到3之间以步长0.01,生成间隔数值点\n",
        "xx, yy = np.mgrid[-3:3:.1, -3:3:.1]\n",
        "# 将xx, yy拉直，并合并配对为二维张量，生成二维坐标点\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "grid = tf.cast(grid, tf.float32)\n",
        "# 将网格坐标点喂入神经网络，进行预测，probs为输出\n",
        "probs = []\n",
        "for x_predict in grid:\n",
        "    # 使用训练好的参数进行预测\n",
        "    h1 = tf.matmul([x_predict], w1) + b1\n",
        "    h1 = tf.nn.relu(h1)\n",
        "    y = tf.matmul(h1, w2) + b2  # y为预测结果\n",
        "    probs.append(y)\n",
        "\n",
        "# 取第0列给x1，取第1列给x2\n",
        "x1 = x_data[:, 0]\n",
        "x2 = x_data[:, 1]\n",
        "# probs的shape调整成xx的样子\n",
        "probs = np.array(probs).reshape(xx.shape)\n",
        "plt.scatter(x1, x2, color=np.squeeze(Y_c))\n",
        "# 把坐标xx yy和对应的值probs放入contour函数，给probs值为0.5的所有点上色  plt.show()后 显示的是红蓝点的分界线\n",
        "plt.contour(xx, yy, probs, levels=[.5])\n",
        "plt.show()\n",
        "\n",
        "# 读入红蓝点，画出分割线，包含正则化\n",
        "# 不清楚的数据，建议print出来查看"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 loss: 4.62708044052124\n",
            "epoch: 20 loss: 0.6793822050094604\n",
            "epoch: 40 loss: 0.6112563610076904\n",
            "epoch: 60 loss: 0.5640512704849243\n",
            "epoch: 80 loss: 0.5263250470161438\n",
            "epoch: 100 loss: 0.49437621235847473\n",
            "epoch: 120 loss: 0.4656562805175781\n",
            "epoch: 140 loss: 0.43941962718963623\n",
            "epoch: 160 loss: 0.41513344645500183\n",
            "epoch: 180 loss: 0.39242789149284363\n",
            "epoch: 200 loss: 0.3710271716117859\n",
            "epoch: 220 loss: 0.3511165678501129\n",
            "epoch: 240 loss: 0.332616925239563\n",
            "epoch: 260 loss: 0.31543758511543274\n",
            "epoch: 280 loss: 0.2993297576904297\n",
            "epoch: 300 loss: 0.28413155674934387\n",
            "epoch: 320 loss: 0.26965054869651794\n",
            "epoch: 340 loss: 0.2561817467212677\n",
            "epoch: 360 loss: 0.24375618994235992\n",
            "epoch: 380 loss: 0.23206184804439545\n",
            "epoch: 400 loss: 0.2212413251399994\n",
            "epoch: 420 loss: 0.21108479797840118\n",
            "epoch: 440 loss: 0.20160576701164246\n",
            "epoch: 460 loss: 0.19277164340019226\n",
            "epoch: 480 loss: 0.18442083895206451\n",
            "epoch: 500 loss: 0.17665664851665497\n",
            "epoch: 520 loss: 0.16934287548065186\n",
            "epoch: 540 loss: 0.16243009269237518\n",
            "epoch: 560 loss: 0.15600809454917908\n",
            "epoch: 580 loss: 0.15001140534877777\n",
            "epoch: 600 loss: 0.1444663107395172\n",
            "epoch: 620 loss: 0.1392861306667328\n",
            "epoch: 640 loss: 0.13447260856628418\n",
            "epoch: 660 loss: 0.1299467831850052\n",
            "epoch: 680 loss: 0.12570960819721222\n",
            "epoch: 700 loss: 0.12174537032842636\n",
            "epoch: 720 loss: 0.11807073652744293\n",
            "epoch: 740 loss: 0.11468444764614105\n",
            "epoch: 760 loss: 0.11149851232767105\n",
            "epoch: 780 loss: 0.10852241516113281\n",
            "*******predict*******\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gUVReHf7O9JYTem9IEpIOIqJTQERVCk6KIoCj2guinKNgLgg1QUaogiChIRHqvofceeg0Q0jfZPd8fh3XbzLZs+n2fZx7I7sy9d2Z3zz333FMkIoJAIBAICi6qvB6AQCAQCLKHEOQCgUBQwBGCXCAQCAo4QpALBAJBAUcIcoFAICjgaPKi01KlSlG1atXyomuBQCAosOzYseMaEZX2fD1PBHm1atUQFxeXF10LBAJBgUWSpNNyrwvTikAgEBRwhCAXCASCAo4Q5AKBQFDAEYJcIBAICjhCkAsEAkEBRwhyQba4dQsYNw5o0ABo3Rr47TdA5GETCHKXPHE/FBQOUlOBFi2A06eB9HR+bfduYPNmYMKEvB2bQFCUEBq5IGRmzgTOnnUKcQBISQEmT+bXBQJB7iAEuSBk/v2XtXJPdDpgy5bcH49AUFQRglwQMpUrAxoF41zZsrk7FoGgKCMEuSBkRoxg7dsVlQooVYo3PgUCQe6QbUEuSZJBkqRtkiTtkSTpgCRJ74djYIL8T506wJw5QIkSQEQEYDQCd98NrFrFAl0gEOQO4fBayQDQjoiSJUnSAtggSdI/RCSspEWAHj2Ay5eB/ftZmN95Z16PSCAoemRbkBNXb06+/af29iE8iYsQGg3QqFFej0IgKLqEZQEsSZJakqTdAK4AWE5EW2XOGS5JUpwkSXFXr14NR7cCgUAgQJgEORHZiKgRgEoAWkiSVF/mnB+IqBkRNStd2isvukAgEAhCJKxbUkR0E8BqAJ3D2a5AIBAIlAmH10ppSZKibv/fCKADgMPZbVcgEAgEgREOr5XyAKZLkqQGTwzziOjvMLQrEAgEggAIh9fKXgCNwzAWgUAgEISACNsQCASCAo5IY5vPsNk4DWxGBtCqFUdLCgQCgS+EIM9HbNsGdO/OaWElCbDbgenTgZ4983pkAoEgPyMEeT4hNRXo2BFITHR/feBA4MABoHr1vBmXQCDI/wgbeT5hyRLWwD2x2VgrLyicOsWFJWbM8J6UBAJBziAEeT7hxg0W2p5YrUBByWjw3ntA3brAK68Azz0HVKwILFuW16MSCAo/wrSST2jXTl4jt1iAbt1yfzzBsmkT8Pnn7mXfAKBXL86OaDLlzbgCISWF0/Hu3g3Urw8MGMCZHAWCgoLQyPMJNWoAw4cDZrPzNbMZuPdeoHMBSHgwfTqQlub9uiRxSbj8yrlzQM2awEsvAd99B7z2GqfijY/P65EJBIEjNPJ8xIQJvOH5448sFAcMAB57rGAUabBaAVJIXpyZmbtjCYYXXwSuXHGatVJS+Nk/8wywdGnejk0gCBSJlH59OUizZs0oLi4u1/sV5BxLlwIxMSwIXTEYgAsXgOLF82Zc/jAY2GffE7WaJyBJyv0xCQRKSJK0g4iaeb5eAHQ9QUGgUyfgkUfYHCRJgFbLwUzff59/hTigXDxarc7dcQgE2UGYVgRhQZKAmTOBdeuARYt4s3DAALY/52f69eNxW63O17Ra3qQV2rigoCBMK4IiTWIi0KYNcPw428nVaqBqVZ6QSpTI69EJBO4omVaERi4o0hQrBuzcCaxZAxw8CNSpA7RtWzA2mAUCB+LrKigSnD7NAUvPPAMsXAhkZTnfkyQW3s89B7RvH5gQt9mATz8FKlXiyaBnT9bqBYK8QGjkgkJPbCzQuzcLb6sVmD0baNAAWLUK0OtDa3PoUGD+fM6RAwB//QWsXs1affny4Ru7QBAIQiMXhJ3kZGDqVOCNNzhiUs69L7fIzOTEY6mpzg3N5GSO4pw6NbQ2z50D5s51CnGAo3LT0oCvv87+mAWCYBEauSCsnDwJtGzJQi4lhVMMvP02p+gtVSr3x7Njh3wOm9RUYNYs4Nlng2/zwAF5//OMDM4lLxDkNkIjF4SVoUOBhARnYFByMmuwb7yRN+PR6+Vz2AChF+244w53d0UHGg0nDRMIchshyAVh48IFYO1ab8GZmQksWJA3Y2rUSN6N0GwGnn46tDZr1gTuu8/bvq7Xc84WgSC3EYJcEBaOH+fMgUphCXkVKSlJwOLFQMmSHKRkMrEm3r8/b3gePqw8Zl8sXAj06QPodKyJ33UXpymoVSv89yAQ+EPYyAsh8fHAt9+yLffee4ERI4DSpXO2z5EjlQtJ6PUc5ZlXNGgAnD/P3ivXrvGzePVV4NdfWdCXLs0eKM28wiyUsVi4eMZPP7FtXKS9FeQlIrKzkLF1K/tCW61s0jAYWAuNi8vZcnFarbtvtisNG3KkZGRkzvUfKElJQOXK3pNOZCT7mkdF5c24BIJAEEmzigjDhvFGoyN1bHo6cPNmzm82Kvlj6/UcOZkfhDjAtnq5CcdmA+bNy/3xCAThQAjyQkRKCnDokPfrdnvOl1wbNEh+82/w4PwV7n7pkncVI4DdES9ezP3xCAThINs/MUmSKkuStFqSpIOSJB2QJOnFcAxMEDxarbLQdK08lBN8/jnQogX3Y7Hwv02bAuPH52y/wXLffWxu8sRsBlq3zv3xCAThIBy6UhaAV4moLoCWAJ6TJEl40+YBOh0Xd/DUjI3G0AJfgsFiYTv42rXApEmchGrjRn49P9G6NQtz1xqiRiNPOu3a5d24BILskG2vFSK6CODi7f8nSZJ0CEBFAAez27YgeCZNAs6e5YhGjYY3PR96CBg1Knf6b9qUj9wiIwP44w++35o12a3Qlz1ekoC//wYmT+YQfSJgyBD27BH5xwUFlbB6rUiSVA3AOgD1ieiWx3vDAQwHgCpVqjQ9ffp02PoVeLN/P3DiBHD33RyJWBhJSACaN2fbdno6m0f0emDTJqB27bwenUAQfpS8VsImyCVJsgBYC+BDIvrD17nC/VCQXYiAJk04+ZUnLVuKnCeCwkmOuh9KkqQFsADAbH9CPNxYrcDYsUDFihyKPXgwh4oXRqxW1rQvXcrrkeQ9v/4qL8QB9plPTs7d8QgEeUk4vFYkAFMBHCKiXPdRiIkBPvmEhfeNG5w2tVkz4NYt/9cWJH75hSMQW7UCqlXjYsc3buT1qPKOL79Ufo8of7k8CgQ5TTi+7vcBGASgnSRJu28fXcPQrl8OHABWrOA80A6ysjhqb9q03BhB7rB2LYfA37rFkYkZGewVEhOT1yPLOxISlN9r2dLdK0UgKOxkW5AT0QYikoioARE1un3EhmNw/ti9Wz4ZU2oqu77lFDduAB98wG5sffvmvD32s8/cixgAbGbZtAk4cyZn+iTi6vJNmnBo/3PP5S+TTufO7JXjiUrFZheBoChRoBegSt4Yej0X0c0JEhI4d8iHH7IgnT8fiI7O2RXAuXPyr+t0OSdc33iDXfJ27eIkXD/+yClhfWnCucm77wLFizt95iWJ///bb0CVKnk7NoEgtynQgrxlS+DOOzmi0RWdLvRc0/746ivgyhVnmDcRa8svvJBzJc06dOB78iQrC6hXL/z9XbnC2RMdxSEAzt2SmAh8/334+wuFihV54/fVV/l70L8/r8KKsrlJUHQp0IJckoCVK4EuXVjQabWcsnT1aqBChcDbSUriWovdunEE5EEfoUyLFysL7P37gxt/oLz2Gge5uE5YJhN76+RE6P3u3fJJsNLTeU8iv1CmDK+MNm/mgsq5GYgkEOQnCnw+8pIluYJ5aiprjcWKBXf9jRssAC5f5jbUamD6dPZ+6dHD+3ylupNZWfKVaMJBuXLAnj3Axx8D//7LVdpfe40jNnOCihXlJyu1mldAAoEgf1HgBbmDUL0UvviCXRcdgstmY4E+dCjbnz03U195hXN+u5odNBpeCeRkvu8KFYBvvvF+/a+/ODHV1atA9+7A669nv4hEZqZ8TUq1GnhRpEQTCPIdhUaQh8off8hrn+npnBK2fn3317t146rwY8eyOScri8PB//wzd8brygcfsA+9Y1I5cYI9NrZvZ3PD1avAAw9wGbLDh4ElSzjzX69erOUr8frr8gWLIyN5wsoLrOlWHN8dj/NHL6JCjXK4o0EVGC2+qyfb7WwK2ryZJ8K+ffNPXnSBIJwU+QpBLVuyhu2JwQAcOaLsAXHzJnt0lC2bN5XTb95kE4tnbm2djjVnjYZXF0RAjRrAsWMs2BwrjOnTgd695dsuVkw+oEqr5Y3Q7FTRIfKfnMpms+HMofM4sv0Ejmw7hiNxJ3Byz2nYsmz/nSNJEirWLIcajaujXqs6uKd7E5SvXva/99PTuVLS3r0c5Wk28zNZs4a9bwSCgkiO51oJhvwkyOfMcVbVcaBWs91cTsDnF1avBh59VLlOpj+MRjYpyQnlmjW5mLLcNYmJ3l5CgXDkCPuir1nDk82gQRydabGwtr133SHsWrkPh7cdw9G4E0hP4WWSKdKIWs3uRJ3mNVC7RQ1UrlMRF45fwvFdp3BiTzyO7zyFy6evAgCq1q2Ee7o1xb0PNcVfa2rhw4/UbsFijns7ckRkOhQUTIQgV4CI7d6TJrGnht0OVKrES/KKFfN6dMocOsSpCDwDhQIlIoJTuT72mPd7P/4IvPSSe9tGI094EycG39e1a1xd/uZNZ8X6SN1lNK4Uh1Z19mDvmgPISLNCq9PgzsbVUbvZnajdogZqN6+BSrXKQ+Un3v7csYvYtmQntizZgb1rD8KWZYNNZcEVW2NcQ1MkoCGyYPnvPg4cCH4/g4g9Yz7+mFclrVrx//NiNSYoughB7ocLF4Bt29hc0aJFwdDYmjdnbxZHfc5gsFhYkMtVtyfiPYDPPuPVSWYmC/xJk+T92f3x8cfcnjU9A2WwBRWwGiWkAwCA0lUroPXDjdCsUyM0eLAuDCaF4p8BkpKYgrhle/HWsB3QJO6ETkqCnVRIRB1cRVMk65si7lAFVK8e3Af80Ufs6uiY3CSJzTU7dvAkJRDkBoVakJ88ycvlOnVy1nMkv3HlCm9cxsWxuUOSeEURSOY/gwE4f97dZdJu50CgiRPZRt6+PfDUU2xmKl48tDESEXpFH8XhVatRFpugkdKQSmVxAW2RbG6NCVPKyk4mnsTHA+PGsWmmUiVg9GgO01fi88+BMe/aoEs/jlLYgVLYiQiJc+BXqFEOLbs1xT3dm+Lu++tAq/NtK0pNZU8gz9WPWs0T3IwZ/scvEISDQinIMzLYE+Hff9kskpHBP+65c5WruhdGzp4Frl9n75Q1a9h2brPx87BY+EhMZJdCtZqPKVPYTu3K8OFsPnAILLWaBfjBg8G7NF67cB0rZq7DsmmrcfbIBdigx2W6FxfQFjdxFwAJJhOwYQPQuLHvtk6d4pwvSUl8XwC7m44f7xLBS8QDTUkBGjdGhl2Lzp15kktLY5OKWXMV7z23E2d27cDuVfuRmZEJU4QRTTs1xL3dm6F5l0aIKu0diLBvH+fVSUryHtsdd3B06fHjvELq2bNoffcEuUuhFOSvvsrLfdcNLYOBN9W++CLbzRdYzp5lr5QLFzi8/6GHOOp08WIWaH36eHvjnD/PwT6erpgGA5eJe+89//1mWjOxZfEOLP1lFeKW7obdTqjfug5axbTFs+/di4Sbxv9s5Ho9cM89nNnRH08+yVqvzeb+emQku1jq4o/yTZ4/z1mz1Gpg2jRQj4exdi27H1asyKsXRyRsWko6dq3ch61/78CWJTtx/eINSJKEu1rWRMvuzdCyexNUq18FkiQhIUE5SEqjYXNTaipPmOXK8SZ5TgWHCYo2hVKQR0bKa0kREYUvH3lOExvLZgI5L5i2bYFVq5SvPbEnHv/+shorZ6/HrYQklKxQHB0Gt0GnJ9qgUi3OlXDsGPD885xSQa/nAiCffx5YioE77mCt3BOLBdi+xYY6HatwvTfX77LRyLkGAjBg2+12HN91Clv/5g3To3EnAABlqpT6zwvmq2n18OcinZvSoFJ5+9trtbwp/N13/u9LIAiWQinI1Wr5wBW1mgN1BIFz8CCbBjztwBoNCybPZFm3ridh1a8bsGzaahzbeQpanQb3PtwcnYe0RZMODaCWyy8cIvffzyYYT/R64PzsNSg5pIf3jK5SAa1bc1rKIDdOEi7ewNYlO7Hl7zjsWrEP6akZ0Jv0UJVqgL0XmuK6qgmMxYrj2jX571/p0rx/IRCEGyVBXqAjO++7D1i/Xv71ooDdHr5KOHXrsh162zb38HydzhmWb7PZsHP5Xvw7bTU2/bkdmdYs1GhcHc9NfBLtHmuNyJIR4RmMB6NHc/CS6ySj13OUbckMhbp+djtL/3r12Jj+zDMB9UUEzJ5fHJ980h5XrrRH2dJW9H70AKpH7MD2f3aiZtZ2AEDNqjWxLKEZLqE5UlDZrQ25POkCQY5CRLl+NG3alMLB7t1EERFEWi0RQKTT8d979oSl+XxLbCxRrVp8zyVKEH3yCZHNlv12b9wg6tmTn6NeT3THHUSrVhGdPXqBpr41m/pVGk7RUgz1LDWEvn1hKh3bdTL7nQbId9/xZxsRwWPr2ZMoKYmI4uOJDAZ+GEqHwUB07lxA/bz3HpHR6N1E+fJEFy/a6cSeeJo17nd6rsUoipZiKFqKoeZ4k8pjFamQQQYD0ahRgd3Tvn1EX3xB9MMPRNeuhf5sBEUHAHEkI1MLtGkF4Ao5EycCO3eyRvniiwW7sMCRI6xIli3LdTk9oyjXreO0va7aqcnEQU3jxsm3ScTBOGZzYH7gycnAzetWHF63FbE/Lse+9YegUklo1rkROj3RFi0fagadPoTwTl9kZrIq68OBPyOD88mUKeORhfKll4CffnIPz3XFaOTd72ef9TmE9HRuV6mZmBguJOJgX9x1DOy4GRGJy2Gk87CiGKRKHfHr2o6oUF05jwER7xf8/DNv4Gq1/Noff/BnLhAooWRaKdAaeWHCZiN6/HFWHs1m1jzLliU6fNj9vAcekFc6TSaitDTvdhctIqpcmbVso5Ho2WeJ0tOVx3H26AWa8tp06llqCEVLMfR49adpzuhpdPV8Qljv9z9iY4lq1iSSJKLISKIxY4iysoJrw24n+v13omrV5B+O0Uj0/fd+mzl1ip+9kmKv03FXrmRmEv31l53+9+weeubeDylaiqEu+n70+ZDv6MSeeNl+/v1Xvh+LhSg1NbhbFxQtoKCRC0GeT5g+3fvHLUlEdeq4C4+yZZUF+enT7m1u2uRtJjAaiQYP9u7/0Naj9Hb3jyhaiqFO2r70/oOjaEepu8hmNPHs0qwZmzHCyYYNPHDPG3nlldDa27dP3i5iMBCdP+/38tRU7+H4E+SenDl8jiaO+IG6mwdQtBRDr7V/jzYt2k42F9vXY4/Jtx8ZSbRkSWi3LigaCEGez2nZUllAHzniPK9dO/nzLBZvTbtrV/lzDQaihNsK9tkj52lMz88oWoqhR0s+QTPen0fXtu31nlVUKqKqVcNjjHcQHS0/QKORKDk5tDY/+IBv0GHoNxiIpkwJ+PJRo4jUau8hqdVEvXoFPozEhFs055OF1L/y07yyqfU8/fntP5SalEp9+yoL8sWLQ7hnQZFBCPJ8TsOGygJ6927neRs3emuNZjPR2LHebdasKd9mRATRhlXX6ZuRP1EnbV96KGIgzRw7n1Ju3V7Xv/02C0K5C1esCN9NV6qkfNPHjoXe7tGjRJ9/TvTVV97LFD/YbESjR/O85TqvVK1KdPFi8EPJtGbSqjkbaGTL0RQtxdAjxR+nUT1nUHHjFa/bNptDn78ERQMhyHMBq5Vo/nyi//2PaNo0opSUwK/99FN5q0CZMt4m45UrWfBrNOxN8fXX8kv+AQO8tUstEqmOZgZ1NT1GHTV9aMIzU+j6pRveFyoJ2Bkzgn8wSnTrxvYjuWVIXhqL7XbKSEyjuXPs9P77RL/9RpSRkf1mD2w6TGP7fEkd1b0pWtWHGmm+pGLSEdLr+bP/44/s9yEo3AhBnsNcu8YasMXi1K7KlCE6GaCHXkoKUePGTouGTsfybNmy0Md0+LBzPFok0p2YTW2lgRQt9aaPB02kc8cuyF84dar8bpzR6G7nCZTFi4nuv5/ozjuJnn6a6MwZfj0uTt5G/u67od90drDbib75hqhUKVbJy5Yl+umnsHdzKf4KTX5tOnWPGEzRUgz1qjqa/pi00c2OLhDIkaOCHMDPAK4A2B/I+YVRkA8d6vRndzUrt2sXeBtWK9GcOdzWmDFBWwVkWb/yOnWoPp3aSgOovdSbhjT/kk7tP+P7otRUdlTX6503YzYTDRoU/AAmTHAX1hoNO7+fPcvvb9hA1KIF91WxovLyIhDS0oiWLmVPmFA0+u+/l59YZs4MbTx+SE1KpT+//YcG1xxJ0VIMjWw5mg5sDmGiFLiRlkZ06BDR9et5PZLwk9OC/AEATYqyIC9WTN4aoVb7dvcLlIwMolu3Aj//ytlr9O3zU6mrsT91VPemjwdOpPgDfgS4Kzdvsq28Zk2iRo14wzBYjTE1VV6z12qJRo4Mri1/LFvGu4WOw2Jh38tgUHIJql49vGP1wGaz0b/TVlOfCsMoWoqhjwZMoCtnQ4sQslrZjTIpKbxjLCh8+SV/9BYL6waDBsm75RZUcty0AqBaURbkxYvLywCNJnuC/NYt/jLqdNxW3bqsxCpx8dRl+urpKdRF3486afvSF09+p2xCyWl27mShKvdg7rrL+/zkZN6oDFabvnZN3m/QaCS6EOC9Z2XJj9PxIeYCqUmp9PPbv1IXQ3/qZnqMls1YE9T1U6YQRUXxozAYiJ58MjxKREFh3jzvr4HRyM+hsJDnghzAcABxAOKqVKmSKzedm4wY4e3ooVYTde6cvXbbtXO3cDisHJ5OHWePnKfPhnxLHTV9qIu+H014ZgpdPHXZeUJ6OtHatURbtoTXhdAXFy4oh8937Og8LyuLfceNRlalHHbyQE0sU6bIC3KDgT1XAqVy5cAnHVfsdral16/P5qGhQwNOCSDHxVOX6dnmo+jRkk+QPcBnsGiRvBAbOjTkYRQ4GjWS//gMhsLjDZTngtz1KIwa+c2bRHffzXJIo2FPvcqVs/V7psOH5T1ZNBqi557jc07tP0MfPvYVdVT3pq7G/vTdiz/T1XMey/K//nKaHCIi2NUlLi70gQVDly7eM5HJxHbszEw+Z8wYedv0118H1sdnn3lvUADsETNmTOBjnT1bXhr6M9G89JK7CUmj4Q3TK1cC79uDv75bStFSDF0+czWg81u0UBZiRcXMUqaM/DMwGp1bMgUdIchzAZuN6J9/OInVggVsr1Ti6lWigQP5S2YwEPXrR3Tpkvs5sbHKtve2zU7Se70+p2gphrpbBtAPr8/wdiMkYoOp3GwQFeVtPLTbiX7+mWekSpWIhg8PKCLSJ4mJRN27szC3WFjgVa/OyxWtlqh3b55c5G6yYsXA+ti9W/4ezWaizZuDG++CBUS1a/OHUr8+0d9/+z7/8mXviQrg1955J7i+Xdi34RBFSzG0eXFgE2758vKP0GTir0BRoGdPeW/WUqWCz/oQbux2dl7I7gasEOT5iMxM3kN0VSI1Gk4V4uqvfOaMt2UiEkepsepjipZiqEexQfTL/+ZQ4jUfu6BjxigH98yf737uyy97a5ZlyvCsk10uXyZat857ZpLTpF2FYaAMH+4+drOZY+FD9YAJlGXLlGfb++8PudnkxBSKlmJo1ge/B3S+khCLivKtUBQmDh7kr7VrMFcOOh0FzL//sk5iNPJXunPn0LNdKgnysGSzliRpDoDNAGpLknROkqSh4Wi3sBIbC1y6xAn/HGRlAdeuAQsXOl+rXJnzcJtMQBQOoTHGoYX0ForhCHq93hez4yfhiXH9fOcBv3rVPcG4A5uNC306uHKF6+a5pv7LyuJSS4GWu8nKAv7+G/jqKy4F5Fp1oUwZTt3oWS8tM1M542HDhvzvsWOceN5R9iktDViyhPtKTeXf7KBBXLC1bl1OITh7NjBrls9sitkiK4v7rVxZ/vmq1UCNGiE3b440oVz1Mojffyag88eN4+yWrrdrMgGffuqdQbOwctddwPbtQL9+QLVqQJs2wKJFwMCBeTemQ4e4hu758/y1zcjgn0aXLuHtJywp8ImofzjaKSocPOhdiQfg9LEHDri/9upTh5G28VfcPHUImVIx6OsOxIRZHVGvoTGwzjp3Bn75xb2wKcBCtm1b59+7d3O1hvR09/PS07nO25gxvvu5dIkrely9yt9WnQ6oWZOrQUdG8jkHDni3D7BAlCT+F+D/Gwycy1ej4UlHo+Gjf3/OJeuoqGGzAS1bAlu28EPVaLguXO/eTqlmtwO7dvG5TZq4V344dYrHfvfdXDvOH3/+yTmD4+OBqCguaNqkCUsQV4Gu1wMvv+y/PR/c0aAqTu49HdC5detyrdB33+UapZUrA2+/zaVMixK1a/Mcnl+YOFFedzlwgIt63313mDqSU9Nz+ijqppWFC+XNwhYL0a+/8jmZ1kz6bMi3FC3FUJ8Kw2jBhL8pLSUEX7K//nJfazqO3r3dzzt4UN7zQ60mGjLEfz/du7MpxtM0MmKE8xzP4CDPHdxy5dg23707uyDI2QoCPQwGXr9u2cIGZId93mDgDGVjxhDdey+vd4sV438//dT3PS5bJr8pO2qUcx/AaCSqUCEsaQx/eWcOdVT3pvTUdLp+nWjyZKKPPuJbymmLkSA8tG8v//UMNdMlRIh+/sFq5f0+V7mnVrMMS0/nAJGPB02kaCmGfho9m1KTQ4xosNuVc3TLhZy2bOltszaZiPbu9X9DnkLc1Ujr4OZNZdcCgG356elE27fLb14Gc0REsEugkh+73OQGsF3d4U0j93zkrrFYeHPjxg3e0QqTe+fquRsoWoqh+b+c/s8rU63m+ah379zzIhWEzrhx8h64AWZW9kJJkIep4qMgGLRaXv4+/LDTYtC9O1sH9Hrgp1GzsHLWegz5oD+GfvQYjGZDaB0lJwPnzsm/t22b92tLlgDR0TwIkwkoXx6YN8//+s/x/ZTDZnP+v1gxIC5O2WhLxKaXn37yNgWFws6d8tWRAeXX57rX97YAACAASURBVM5Vru957Jj86zYbkJDAppYqVcJWSLVc9TIAgDdeuILkZLYc2Wy8jREby0MV5G9GjOCvvas1z2QChgwBKlQIXz9CkOcRZcsCv//OZlWrlU2vFSsC879cjPlfLsbDz3VG/9GPZq+TixeV3ytd2vu1EiVYQly4wEa8c+e4wrE/dDoude8pwDQa4JFH3F+rXJkNt3LC7o47gB9/BKZP99+nP+x2fqByG5H+rps9Gzh6lHcQ772X7e2bNrEhWg6t1qP2XHhwCHK19bLXeykpvPUhyN+ULMnbM0OH8texbl32BQjUfyBg5NT0nD6KumlFiQObDlMHVW8a2+dLygrW8fX8eaIff+RSQ9evE61fz2twOTuz2Uw0aVJ4B3/iBFHp0k4XQIuFzTqXL3ufe/w45zRw+F9rNHzd8uXOdI1Kh9Ho22UR4HueOlU+u2KgZpnSpd3XxFot+/h5rpNNJq6gnAPY7XbqpO1LdXUzZYfZvn2OdCvIx0DYyPM31gwrPVX/Zepf5WlngYdAmTDBWezTYuH/lysnL6TUak6YnhO7ZUlJPJm8+irRrFm+E31cuED05ptchPSZZziM9ehRZUEuSRxBFR9P9Oij/gV5s2bcT58+vgtxKtnP5XzvARbwdevy+5UrE/3wQ47tPGZlZVG0FEP1jL/JzsWzZuVIt4J8jBDk+ZyZY+dTtBRDW/4OMnR+//7gNgZLlsyZG3BgtbLrTd++nOFw714WdF98wdkF1WquirF6tfOaQ4eInniCqF49ZU8VtZq1X6OR6JFHAhPOK1bwjuDMmUStWvE1arWzD7mITIcXiy8h36FDzj7D26TcSqVoKYY+HrGIzGYemkrFt9GzZ95HKwpyHyHI8xCbjYMaf/9dfqf6UvwV6qLvRx/0Gx9846NHyxeZVDoCScm6fj1HSg4ZwmFprhqnzcZad8OGRDVqsOudI+44PZ1d+hxCVq1m6dOjh7zb3pYtRNu2OQVsoPeg17OLjz+zyR13uI/9iy+8TSN6PRe8kCReDbz+OlGbNr7b1WhypYLR1fMJFC3F0OLJy+jaNaLvvuOSfhs3CvfDoooQ5HnEyZMsOyMi2BPOYGDLg+sPccpr06mjpk/ACZKIiKsnDx2qbAJQqbyFo8nECZt9MXo0n+fQWs1m1pYdAx4yxF0b1utZYCYns7tfMDbpTp2UXfoCORzJqZTeNxicWcuystgVUu68pk15gnLc499/+74PjSZX0umdPXKeoqUYWjl7XY73JSgYKAly4bWSw/ToAZw+DSQlcYR5ejoweTLwxx/8flpKOv6Zugr397oHZSoH6PlgswGtWwMzZyp7ZWi1QP36HLcdGcmRkr16AS++qNzusWO8pe4IewfYPWLePPaXPHkSmDPHPYw/IwO4fJnHMneufMiqEvv3sztiqGRlcX9qtfz7RE5Xx8RE5bEdO8ZeNI5I0G7dgHfekW9XpQLuuYefqyvp6RxaefhwaPciQ1oyR8EaLIG7n167BixYACxb5p4CQlC4EYI8Bzl6lGWfp8tySgrwzTf8/xUz1yH5Zgoeeb5r4A3HxnJouS/XOpuNXQJXr2Z3vkOHgBkzWDgRsYtdixYc0/zGG+wHvXSpfFtpacDixex7LucD7nBsPn488HsA2BerWLHgrvEkNZXzuOh07q9LErdfhl34UKwYO/DKUbmy92tvvsn3U7Gi8zqzmV00Pf3+Zs3ifjp2BJo2Zb/704GF1vsiNYl96VVaI8aM4dQttWsDn30m/9GPH8+3MmQIEBPDQ9+5M9vDEBQE5NT0nD6KimklLk45Q2ujRuxe9mTdF2lE09cDLiBARETDhgVmejAaiQYP9r7eM3+2TkdUtSoXHpbbRNRoiD78kAtTyHmVqFS+w+ktFu8NWZOJaNMmovff92/GcN2glDsqV+aUco7QR4DPd6SaS0zk+/7sM/nrVSp225QjI4Pot9/Yw+ann7yTe+/Y4T1+lYrTArz7LqcFDtEMs+XvOIqWYqh57aNupn2jkV0PXb8ymzfLP8bSpZUDVQUFDwgbee5jtcqbZQ0Glos7lu+haCmGlk1f431xQgILgqZNOY/HqlXO95RKoSjZiV1zZl64oOyt8cEH8tJAkngD1GbjDc5gNiajolhgN23q3teUKTyezEyip57icUZEcF8aDU8uFgt7sqxbR9Stm7ww12h4Y5aIBbXnnoFOxzmD69cnqlNHOTTfYOAUAsEyZIhym452S5Zk98ogWTWHQ/RLmc56NWs2u5f8GzJE/vFERrLzjqBwoCTIhWklRK5eBT78EOjZExg7ls3Enmi1HG1uNDrNrSYTp9h8/nlg4TexiCodiQf7tnK/8Pp1TuH66afAjh2crrV7d+D77/l9RzrXQNDpnGH6p09zzHBWlvd5aWnAhg3yWQ4lCXj6af63Z09vW5GvVLEvv8xmiv373ft6/XWOIN26FahenR/mggWc7/PPP4GPPuLQ17172UT0999sqzeZnP3pdBwW/+67/PeCBd42B6uVbeD797P9Wik0X5I4y6ODs2eB4cN5bPfcw2OR4/x55TYBtp0nJISUS9VhI09K9c50mZnJj87BjRvObQ1PkpKC7lpQ0JCT7jl9FHSN/OhRDkx0LHcNBnY9PnhQ/vwDB9il+uGHOYNdSgrR+eMXqYOqN/3yzhwiYlfqXr3Y1XpymXcoUyOjNWs07AYzYIBvLdBT0751i938HHXo5M5TqzkwJyZG/n2Vis0USjU4lcwicmXcAF4V1KjhdD00m1kj91fRZ9s29lFv3pxdH13LKiklCAvkMJmc1YDOn2ct2vVZmUy8jPLk668D89TR6ZwroyNH+Fk/8ACbbBQKRP8+fjFFSzEUYUyS/ThcA0pnz5a3ihkM2a9KI8g/QJhWgsNmYxfqN94g+vxzoosXne916uS9jJUkdj8OlO9f+oU6afvStQvX6ehR98omcWiiLBDKlOHSZhaL+yAMBm+zgslE9NZb3KE/c4zJxDNO69ahC0PPQ5LY9hxMBsLy5UNP6/fUU8oTlb8jMtJZ+u7ll+XdOh2ToivJyUS1asmbqzwFeUIC7zOYzc5x6vWsFRw/7nU7jiCxyIgsxSE75gCrlecFhzBXqfgj/eab0B6lIH8iBHkQWK1E0dHOfT2DgX8Uy5fz+75ctwPZs0y5lUo9ig2ijwZMICKOPHc1Oy9GV98Cd/p0on372G5cvDjXmJw2jWjXLo46jIhg5/VJk3hAaWm+7dqlShF9/z3PWs2aKd9gsIdWy8sUuchTpc1Ls5lo587QPrjTp4lKlPCfi8VzHCaTe6Rpw4bKwn7LFu9+ExN5P8PXhmzLlvxZ1Kol/8Xp1cur2R9en0Fdjf1p3jz5pvV67taB1Uo0dy4vqoYP52zAgsKFEORB8OOP8qvlEiV4b07JE8VoDEyQL/wmlqKlGDq45SgRscx1bacdVlA6fAjTF14I7oYyM5U1xpIlOYTdaHRqidkp6OB5nDjhbZKRJN8TS3aSiJw9y8+nfn0Oy/e8b42GqEEDokWL2GNm1ixvLfvhh+XHZTDwZKHECy/IT1oOjfvmTeVJplgxr+YmjviBepUeQvPnKy9quncP/VEJCh5KglxsdsowY4Z87EhmJu89PvEEx9e4otfzfpa/EpF2ux1/ffsPaje/E3fdUxMAZ291ZRXa4yc8CZJrwGwG6tUL9FYYjYYLGer17q8bjbyh98wzvAHp2AQlCqzWpUrFm4+eD8OVn3/mQqQjR/LGpF4PdO0KvP++cl7yt97iMYRCpUpcX2vfPmDjRmDqVPYhj4jg+23alP3lH3qIN0kHDOD3HKxfz2XvPHGk6q1SRbnv8eN5Yzcqiv8uW5brrV24ANx5Jz8npefqKIfnQmpyGowRRtStKx/cYzAAzZv7eBaCooOcdM/pI79r5G3byms/Fgv7hqeksB+vycTaucnE9klPF2M5tv2zk6KlGFoxyxl2vXKl9wrAbMiiS+Y73DVXlYrNIJ4aZCAkJfGNmUys/RkMvAaPjQ2+io5Gw2adoUP5gTz4oLJ23a8fbzAcP+5u+05OVl7aSBLf5/PPs105u2RksLnm1Cnf5x06JL8UU6lY9Q3GPVHJzt+/v7fpSqPhLI0e/uZjHv2UhjV4hYh4X8ZzURMV5b7XKyj8oKiYVux2NmP++aeiM4BflDwAKlRw/33u3cs2yd27A297dNcPqU/5p8iaYXV7fdYsll1GI/9gn3iCKO30Zc70p9WyQG/ThujYsdBuysGBA1zH88QJ/nvdOmWBWrq0/OsmE9+4g99/Vxb4VaqwecNk4gcYG0v07LN8k/5MOFotp+N98UX2EQ/2A01MZPOJw8wyZ4687Sszk3e227SRn7z0evYWyg5WK9+H0aicI75UKbfP940O79ML971NRJyj66WXeM7Valmwh+CaLijgFAlBfvYsx3xYLPyF1+vZASHYTHE2G3v4mUzchsXCSuy2bdkb35nD5yhaiqEZ78+TfT8ri+/BKxAwM5O1ynCQnMybpR9/TLRmDbctV0fTbCZ67TVld8NBg5xt2u284eopBFUq79fU6uBcGF2FqckUeHRLSgpvLLr2ZTZ77y8cPsyeMhERynb7YsUC79dq5RzlrVvzMm3mTP5CDR3qP92wSkV0333/NfX8vaNpVKdxgfUrKBIUCUHevLn3b1Gr5dXs0aPBt7dxI9Enn7C2HI5kdxOf/ZG66PvR9Us3st9YKOzdyxtvDn9ys5nNLZs38+sREc5K86NGcZlvOW1dq2Xt8uOPOQVsVBQ7wFetyu9pNCxEs1tAWe4oWTKwmPPJk5X918+c4ePCBfZl97cy0OsDWw3Y7UQdO7r3azZzIQx/7omuz/a2je6p+i/T+zGfZ+8zFxQqlAS5xrcFveBw+jTvb7nW+gV4k2juXN5vGzuWAwr9ceIEMHgwsH07/92iBZdu9NyUDIakG8lYPmMN2vS/D8XLRoXeUKgQce3JGzecr2VlccXnjRu5vufSpfx+u3Z88y+/LB8WqNEAy5dzUinXSEpJAiwWYM0afohDhwY+PpOJP7yMDN/nWa1cBNHfLt/SpfI71hoNf6A3b3J/Nhs/G1/j6tePC1H7Y+VKfpau/aakcFFrTRA/tdsbomnJ6UFlPhQUXQqN10pSkvJvhYgjpd99V7kQuoPUVKBVK5ZvmZl8bN7Mr6Wnhz6+jX9uR3pKBh4Z2SX0RrJDfDxw5oz362lpwKhRnBLgyBGgf39g7VqeyY4edT/XZGIPjxEjuC3PcHgi/iA++IAFbaB5VFUq9mQpX145Ja1rH4EIxSpV5M9LSQEuXeIPMzNTObxepeL0gWPGAD/84L8/gEP8XVP8OrBaA0vvq1ZzeuLbKXJTk9JgNAtBLvBPWAS5JEmdJUk6IknScUmS3gxHm8FSp453JlNPbDZnHnAlFizg35zr79tu59f8XeuL9Nt5M8pVKxN6I9nBl9Zps7EQf+89oEsXdqGTEzzly3OSmfR0IDlZub21azmhzMCB7qljHblRXF+TJP77/ffZ9a91az5PrZZ31YuKAho18ne3PNn4+0IoYTQCX37JOWreeMP/5OKgTBnfrpieqFTcl0bDE2S5csC0af+9nZ6cDlOEd56VYPGVCkZQOMi2IJckSQ3gOwBdANQF0F+SpLrZbTdYNBp2WXbNqRQKp07JK1UpKfxegaV6ddYwfZGWxpmYLl6Uf//cOfYDr1TJ2yfdlZIl+d8pU4AJE4AGDbj/55/nJdEPPwB33QUUL84Tx8aNnDu8UiU2y1y+zMmoHnuMP1C9nrVUi4X9shMSlPs+cgQYPZoLZLz6KucPj4jwL2BVt38KZjNrBcOH+z5fjsce8y309XqeDCMigPbtOb/7n39ywrCff+bk9bf91DOtmci0ZoVsWsnK4hVoVBT/Nho04PlVUEiRM5wHcwC4F8C/Ln+PBjDa1zWhbHYmJnIU+vjxvt399u9XzillMPj33lu8WD7ltsXCe3/+WLuWo9z1ek6TPXky74Et+n4pRUsxdPV8CH7Rq1bxTq7FwhXcFywIvg0i9qX2l2xLo1FOAlWjBrcTH+/bx3zyZGefN25wgqioKPb+GDYsON/wnTu5DqjrLrYksSO/a3peIqIZM9wjVC0W9tPbsYPolVd83/eAAbwrPnNm9jyEVq1S3ti0WLgwdQAkJtyiaCmGFkz4O6RhjBghXyY11OwHgvwBcsprBUAMgJ9c/h4E4FuZ84YDiAMQV6VKlaAGv3EjuxOazRxLYTKx95uv3EoTJzrzSOl0/H9/5SqJ2AXw7rvdYzb0ek6/4a9q+ZYt8j+ejz4iOrT1KHVQ9aZ1v/vJ7ueJXLSQI9+Kg2vX+Jdbtiz7bY8bpyyMWrXyLdAsFn64cn3O4UyNNH26sguhRuN08cvK4nzirg9Tp2OPFqtVfnyefPWVfF+SxPlLHNy6JT8Bmc3s896+vfI9q1TK/d+8SXQ1iFqqRKxxyI3ZYGBvmQC4FH+FoqUYiv0p+GTi168rPzKZlC6CAkSeC3LXIxiNPCtLPi7FbObCLb44eZKF9xdfOONfAiExkYMvypRh2fjyy4EFU0ZHy8uJiAii1NQs6ltxGP2vx8ey154+zcpgbKyHjGvWTL7RcuVY1U9N5WQtrjk8jEbOb+KKzUa0dSsLeSWNW5L4Yaem8tKnRAnWhMuVI5o61dlWt26+JwODgV3o/v5b3n3RYnFfVSxfzn7XFSoQPfSQ+5LLV2pak4mTctntRM89p+xG+PDDnEVK6f2+fb0/kHPnOEDIoQnUrx+4OnvkCC/HXCcws5lXBQFyav8ZipZiaM1vGwO+xsHu3crBurVqBd2cIB+Rk4I8R00rmzYpBx527JitZxJ2ypZVljenT3M2u07avnT9sjPU224nevVVln0WC99rmTJsIiIiZaGr0fCMM3KkfOpW13X0vn1ElSo5I6W0Wj4cqXAdZdEaNOAwddfBpaR4R1R17OhbkFssLMw++kg5yGbMGG5rzhz3e3RkI4yL4/eLF1fuJzKSaNkynql9+Wk/9hj3I2cOiozkicuVrCyeHD3HHhnpXzt/7z3+MI1GFuQqFVGTJkQLFwYVmXZg8xGKlmJoa2zwtpCbN+U1cpWKqHfvoJsT5CNyUpBrAJwEUB2ADsAeAPV8XROMIF+/Xlm7aNcum08lzCil8jaZOJOsQ8ta8JXT7vnXX/LpAKpWvf27r11bvtFixVigKuXfNpk4jaPVKh+5aTAQ/fILh+yfPs0aaKD4M8+YTDwBzJunrJHPnMk3WK6cfBvt23NfXboo9yNJ/Bx82f3NZjZ1yD3kUqXkBfM//8iP22jk5PRKbNwoP/Hykizw50vOMoB71h4I6joHL7wgbx3buzek5gT5BCVBnm2vFSLKAjASwL8ADgGYR0QHstuug3vucToUuGI2A48/Hq5ewsPYsd6F2k0m4IUX2GmiWr3KqNmkOlbMcroPTJok7yWTkMBxL4qNdu3K3h5yZdsA9p6oWpWDVNLSvN/PyuIyanXrsqeEP48WV65fV35PrQY6dOB/H36YMw+6enJIErtRdO/OwUdKbcXF8b9Vqyr3RQQkJvr2r3vxRXZrlAsCSE52+roTcdRY9+7AK6/IByalpfkORJg2Tf5ZSxIHUAWBo8xbqO6HX30FvPMOULq0MwZq5Urg7rtDak6QzwmLHzkRxRJRLSK6k4g+DEebDrRa4Lff3LOlWizAgw+yt1d+om1bYM4c9rSTJJZhb77J3mUOOgxug2M7T+HUfg7O8eWOnZICoE8f4Ouv+Rep1XKj//sfCxq5GcBBmTLs4nb9OgspT7Ky5AuNBkLLlspudjYbC62mTXmMmzcD0dFOn1CVivu+806ODFUK7nFEUman4GTx4vzwd+/2DvkF2B3w+HH+//DhwKBBHIV56JB3sBPAX7z77lPuLy1N/llnZvqPWPUgNYknBGNEaO6HKhV/965ccdb3bNkypKYEBQE5NT2nj1DcDy9e5P230aPZwyvYRFi5TUaG/BhvXLlJnbR96ZOhM+jUKTYjy1kEVCpn5TEi4sYSE52uOoMH+zY5OAqInj0rbzA1mwN2hfPCUZvOV44Sg4HtxURsx5YzbRQvzulb5WwAM2fytdOny18byKHV8gcxbJi8rV6v5y/Wvn3+88LodER33OHxoXh8Pl19VHYKspS9w1014aIouClwgoJeWKJcOU798dFHrPlmJ+gnN9Dp5Me491Ax3NQ0Ruwv61H3LhsmTFC+ftculxckiYsPOOxMw4bJ25wA1hwvXOD/V6oEvPTSf2HfADiasHx51liVTDMnTrBpxGwGSpXiYg8OrbJmTda0u3bl4Ba5G01P5+UJwAFAcquHGzeAxYv5PhxBPxERwLhxzqrzffvyEsc1oCfQD99uZy154EDvIhZGI7ddrhzbHJTMM46Iy+HDOYDHM7Bo/37giy84pcHKlcpjGT8+oCGfPMmWoPNn2LRSu64RZcqwtcfX6k1QxJGT7jl95PfCEjnF+fOsXJbBZoqWYqgEdisqcBZLABXP6teXv9hkYi3TldhYdu2rWpU3SCMi+ChXzsVF5jaXL3tHRRmNfL0n8fHK2myjRnxO586+tV1JYtfD48fl/d+TkriCfYMGHBw0cmRglesBdpV05CJ2eOhERRH973/OLIpKWr9eT/Tpp/LP3m7ncRiNrPn7y6BYqZLPj/LGDfZ2NBp5c/9OaQ61l3oTYP9vKM2a5f+VqCBnQVFIY5vf+eAD/kFKsNKDeJzqYYLi795o9JbFXmze7G020WicAtSTpUu9BZYkcRCRq4Ro0kR5UHLVDBo29PYcMZuJpkzh96dN8y94IyK4yIUcSUlsVnJl8mT2c9frfZtFPE0qBgP7nLvy44/KE+L58/JjmjxZ2WNI7vDjK9utm7vbeU38Qm0wyGtyX7nSZzOCQo6SIC8wppXCwJkzbJ0gaHEJ96EMtkEN7+RUKhXQpg1Qv76Pxmw2NqG8/z4v/yMj2VzQuDEQGyt/jZyLDBFnA9y8mf8+cEC+ZiXAJo39+71fX7DAmUPEbOZxPPww8NRT/H5iov/UkZLknmIX4Nwu0dGcL6VUKXZhOnSI33v6ad7JO3eOk4i4mo5c8dzkTE/nvCZE/Pfly5wDRo6yZT3sW7f591/gueeUzVKeGI2ckEyBhATeH3bdX9UgHTa4m3GsVuWPBuDH4fkIBUUEOeme00dR1cjnzHFaLCLBAR8VsNJLeYuKIkpP99HQsmXsG26xsDZarx4HnBw7xptqn37KPtyejbRpo6wxtmrF53zzjXIQj0ZDtGeP/JgyM9l8M3Wqc6OViHemAykwYTC452DJzGQzkGeOleLFvWtnXrjg37ThuQpxhM9OmeJ7teDwx3dgt3PUZqB9GQz8eflg/37vMp718RXdi+e9Fi0LFzqvs9m46WefJapY0RmE+sADvMedW6SmcjzEvHmcHkCQc0CYVvKejAzO48LWEDvdi+epKd7xsgQMGeKjkZMnvc0pKhXbmB2JtRw28HLl3GtNfv+9eyi/p8A5eJA9WZS8RKpVC/6mGzf2L+xMJq7J6cqiRfJBOSYT0XffuZ/71VfKk4/c0aSJ+zPxN9FERTnt6RcvBleqzs8zO3lSPl6rIT6iFnjd7XtRubJz/klN5VQzch+VWs1zoL/cQOFgxQr+mCIj+V+DwT2bgyC8CEGegyQmcpR427ZEAwf6ru2ZlEQ0dizXFm1Y7HeKlmLIgEv//QCjonwUe9+2je3CcgJDq/VW6zxqQFJamnLIe0QELxlSUjhaUk46BFPt98IFtuH70pRLlmSXvTVrvK+fOFE57P7ll93PbdhQ/jydzrvYsVbLEZgOzpwJTDBPmuT8AAMt2yZJfH8+ePBB+cDUptK71Ex6hzQanpfbt3fXsseM8T3siAheIGWHa9c4QrRiRfa8/Owz9zxAt27JTyRGI2doEIQfIchziJs3+UvuUOocqUKmTfN/7eXTnOGuTbX5VL06a+KKQvzSJfn8uq5CQ0nAu5oi3npLfpPOYuH0jURE27c7CxI7Kk//809gD+TMGVYV9Xpl7d91coiMlP/Vr10rrynLpYJV0vqNRm+zicFA1K+f+/VffeVfKzcanZuxMTHewlySvO/XZOJEZQqkpCjvl7ZUvU6vRn9ISUl8nifVq/sfrmPuCYWUFO7DVTcwmYh69HCeM3u2/FdSo2GnIEH4URLkYrMzm3z9NbtsOyKzibi4zvPP+w/mK1OlNBq1rYcq2rU4cYLw889cWEeWX37xvblGpPyew0f66lXe7PT0mdbp2De8RQv+u1kz3kRcvhz45x++rnNn3zeTlQVMnw7Urs1hhBkZ/ku92WzsHP32297jnTzZ+wFqNOzT3bOn++tDh3qnMXDcl+cY0tO5mMPZs87XXnoJ2LmTa3MqRZqmpXEJOwCYOpUrGRmNHGlrMAAjR3IlhxIleOO2fn32kXc8Uxl8ucNrpHQUL2WExSJ/a/5Qqfhj9FeSVIk5c3jz1HUDNjUVWLGCa+MC8l8lgPu8dSv4PgXZQE665/RRmDRyJU+9yEinguuLf6etpmgphvZtOOT7xGHDlNUvnY4LTshpic2asTbdvTuf56k1ajTsj16xImvg3bq5b1YSsbF11ix2oevalWj+fHd3RZuNfcWDsR27HmXKuPc3f778ml2n45WJJ1Yr92828/1YLGyjUtLUJYltYA67tyvvvKM8zjvucD/32DH2B7xyxf31IJy927f3Nu/r9USdzcPoi6HfK1737rvKj9toZHf7e+5xJrZ86imi5OSAh0WPPy7fttnstIHHxysHDQs3yZwBwrSSM3ToIP+FN5kCsxOm3Eql7uYB9NXwyb5PVApaUamI3n+f3QXq1XOudc1mtkEPGOA7xN1kcjcrSBLPQvHx3K/dzutp1zbMZv6lO/jnH99mH39H/fru96qU7zwykmj1avnnY7cTbdjAHjvTp7PUUkrx65gU5HaVU1Lk/aYhLAAAIABJREFUzSwqFafDDTNnzjjnUMcc1KABUY9ig+i7F39WvC4lhahFC2eckyMmqXx5otdf994n1umcCSUDYdw4ZSG9fLnzvPfe46+Qw7JnNnPWBRG4lDMIQZ5DLFnibYZVq5VjcuT4eNBEejhqMGWk+SgxlpZGVLOmt9Gye3d+b8YMoiefZMH94ousNm3fHpjrn+eh1TqDZtaskZ8ITCZnAYgXXghdiLvmVXGgJMjNZrZnK+U78eTECe8NYE/VV07Df/117z0HrdY9V3sYychg171PPuENyqwsO3XU9KGpb832eZ3NxjFeY8dyRmKHxi03fIAF84EAs+JeuCA/N0sSL/6OH3eeu3EjLxgHDeJaIr4qdwmyhxDkOYhDe3GUo6tblz0M1qxhLahaNdZSPC0WDuKW7Q6sGsyNG0SvvcZ+aDVqsBvBunVsRnCszx3h6Js3E02YELiHhefh+Izeflv+fZ2OXXWIWJL4EphKh0bDqwlP9U3JtAI4UwvMnx/Yh3Pnncr9K0WTNm7sLQmNxsD7zCYZ6VaKlmJo9oeh1WatUUP+dtVqoj/+CLydrVvlN1VVKg4GFgI791ES5GKzMwz8739c9H3ePE54tH8/sGUL55RauRKIjwd+/533vfbu9b6+Ubv6KFWxBJbP9FPmPCoK+PxzDhFds4Z3nh54ALh50xnBmJHBG4gDBnC0p9LmnS9UKq5yDwAlS8pXoNdqeWMP4IRRvqrHy2E0cn7id9/13vXr2RPo0YN3+TzbTUriY/Bg37nBHciN3YHVyul0XTl5Ejh8mGWWK2lpwMSJ3m1cvcofciBjCZCMVN7kNZj0IV1/5Yr86zabj810GVq0AB55xPsrZLdzBOlaP19XQe4hBHmYKFEC6NSJI+QBLiaR6hJ9b7fzLv+bb3pfq1ar0X7A/di+dDduXL4JgGXJl19yVL3XDzM+nr0ili1THtDFi0Dz5oFlCvQUlgYD8MYb/P/+/eWzLEoS0KsX/79qVWDuXA7R98wyKIfBADRowFJCDpUKmD0bWL2a+9fLCLSsLA6190VmpnLKQEni/itUcH/91i3lye/mTef/iYBXX+WiHL16AQ0bcl6FxETfYwoAhyDXGXUhXa/0EUiS7zodcpw7p+wsFWo6e0H4EYI8B0hIkC98Q8SauhwdHm8Du82OVb9uwKhRQJMmnDn2tddYi1q40OXkd97x799lt3MxikWLnC5yckgSUKcOv6/RADVqsNuco5RMuXLAH39wG5GRfJQsyW6JkZHOdnr04BmnXDn5fnQ6Fno1arC74apVLLAzM7myTocOwEMPcd9EPK4WLTjXipxgzcz0L0kWLgSuXZN/r0cPYMYM79fr1ZPvT693TlwATyKTJ7M7Y2Iia+ybN4elbFVGGvv86U2hCfKePeVvoW5d5yIqULp0kU9jk5kJtGoV0vAEOYGcvSWnj8JmI/ckPV15j7FOHeXrnmsxigbUfFU29YfJ5JIAsHx5//bne+5xH9DcufIBOmYzB99YrRyqp0RGBhv916+Xd9tz8OCD8uMxGLwzCWZlceFVT4+YF15wnnPqlLz7hMVC9PvvyuMgUvahM5nYs0WJ33/ncxz7DiYT29pv3HCeU7eu8t6BZy6YIDmxJ56ipRhaO39TSNdfvsw2bMdjNRh4O2DHjuDbSktjZyjX77PnRyTIPSBs5DkHEWel276dl6F6PfDEE2wGdsVsZi1biehBD+Ly8dNQp532ek+tBpYuvf1HqVL+BzVpkvP/ej0XURg/ngel0bDGazZzvbz77+f1eESEcns6HdfXa93at9399de9I1i0Wi6R5mnGiI3lYg2uGRlTUrgQxYkT/Hfp0lzUwVUtNJmARo04O+GwYWx++eMP70yHZcrI2xnUal5VKNGrFy+dhg5llfSTT/gDjopynqOUZlCtznY0jKPMmykyhEgg8G0fPMimuccf522IY8d4lRcsBgM/ijFj2Gz4wAO8GFEqiCLII+Ske04fhUkj372btR+LhbWeEiWI/v2XFdghQ5zakNnMZd18+dfevJpI0aq+VFOaJutgMWfO7RNnzPCdsS8ykmjnTu8OFi7kJYHRyFmVpk4Nn8NvSooze+H48Ty+yEh+AG3auGc2dPDMM8oa89ixnJFRo2HNuHFj1t7vu48zFn7wgbcDc9eu7q4UsbHKqQtGj87evT/xhHyirgoVsu3OsTV2J0VLMXRwy9FstSMofEC4H4aftDT5HFYmE9G5c3zOjRvsfpyaGlibz7b+lB6QhpKELC/vt/9W9nY7uwXKZVtyrKU9CzH88IN8bcxQ1tuuXL9O9OijzhyqdeoQbdrETs1btjgDi+R45x15c4/F4ox0cX3dEaZYtqxyvphFi7jtlBSiUqWUJzuz2b9pxhdnznD7DvdOlYqf55Ilobd5m1kfcDK1+IO5mItWUCAQgjwHmDdPPtOqXs+VyUJh3YItnKdcv5NUKmcCP9myb9u2yRvja9Z0ziREbItWyprYuTOfY7Ox/XvJEndbsD+aN/f2IbdYfGT/cuHECfnxG42hBTIBzmjNWbP8R5u6ZoYMhUuXOAlZq1ZcDFspV3uA2O12mvH+PIqWYuiNjmPJJhy1BR4oCfIQnIwFDq5elXfNysjgojuhcE+3JogoYUH/ZmsRcW9jmExs3q5SRebk5s2BjRthvb8dpJRkWKGDGpkwnDjB7x0/zvbky5edWb08iYtjg2qnTux9IUnsX/3555wIyhe7dvG1rpmVAP77u++4DSWI2LetY0f2rCHi11UqoGVLdj0MFrWavWsAduz3V5UoISH4PlwpWxb48MPstXGbTGsmJjzzA5ZNW4MOjz+Il6c8DZVScW2BwAMhyLPBgw/Kv26xsDddKOj0WrTtdx+W/rwKv866hWKlIn2e//NsPZ5LuQAtMgEQ7FDjd3sMOidt5ICbIUN8+5xVrszC9Px599dHjeL0eS1bKl976pR8IJDVyo7wSmRlsfvfqlXeGQ7tdmDjRp6AUr3L4PlEp+P7BXjcer2yE7ROx2PwJDGRNysrVpT3n88BUhJTMLb3l9i5Yh8Gj+mDge/GQArE/18guE22vqmSJPWWJOmAJEl2SZKahWtQBYV69YA+feQdKrp2Db3dbsM7wG6z49U2Y3DlzFXF844eBUZ+XRPpMCIJkUhCMaTAgl5YgJvJameBR4OBa1x6utGoVEDbtvJeFmlp7p4vDrKy2I1h61YOSvLUxgHup3Vr5RscN4790JXy/Nrt7BkTSHARwA/dYGA3jQYN+LX77+dViec9A3xumTLsYeMgMZEdsMuU4VS8FSvySiEIrl3jSzZulE/vKsfFk5fx4n3/w541B/Haz89i0JjeQogLgkfO3hLoAeAuALUBrAHQLNDrCouNnIhNy7Nns2NGy5ZE337rp95mgOxatY8ejhpMfSoMo2M7T8qeM2YMkUZt897zwy2aphvmXmvSauVsiJ6bh44aXXI25G7d3DtcvZrbcOQ7KV2aPUlcN1HVak5LK+elQsT2en8FJwCi6GjOxFS8OLfvq2K9Tief0Co9nbMh1q7N+WkaNiRq3Zro44+9i0u2b++dl8ZoDHgz2DXfTkQE59dxTSwlx74Nh6hX6SH0aInHadeqfQH1IyjaICc3O4uyIM9JTu0/Q/2rPE1d9P3o+5d+oRtX3ANNXn2VSJLs3nuFSKbvLa9zWTIHq1bJb/4pCUmTiehnlzSqV6/KJ7KyWDiXaZUqvKE6aJB7TbJz5zg137x57Mmybp3/+ppGozMhFxF76UybxjVIlbx0JkwI/UErbboCnHDej5vi0qXej0aSiGrVUr50xax11EXfjx6v9TydPXKezp7lCnbNm3MCS0diyexy/jznVnvjDU4/K9LLFmyEIC+gJFy8Tl8M/Z46qnvTQxEDafqY3yg5kWt/rVsnL1v1qgw6stLDdW3SJGVhde+93j7ZzZq5Ly2++Ub+erOZ6Kef5Af/4YcsZM1mZ9m4zz7z7ZGi0XCCbrnoyM8+k9fmJYkrLYTK2rXydUodbZco4Uz5JxMR6ivrrqdAttls9Ms7cyhaiqFX246hxIRbdPw4J7B0OP84PBmXLg39log4TbzJ5FxomM3spOQrMFeQvwlZkANYAWC/zPGwyzl+BTmA4QDiAMRVqVIlN++9UHD60Dl6v/cXFC3FUM9SQ2j+l4soPTWDBg92CnOVyk4qlZ0kieVhhw5Ep0/fbmD9enmN3GwmmjyZk0oPHEjUpQsHCnnah8aMkQ+u0Wg4kbYnW7bIBy1FRCgHMxkMPEadjicSz6LMu3bJX2s2uxdUDpaEhMCrG8kUZG3VSv7UyEj3LLnpqek0ru+XFC3F0BdPfkfWDK5k3KePfEhAlSqha9AZGTw5yD2qQOrJCvInQiMvJBzefpze6DiWoqUY6l/5aVry4wr6d2kWPf44/0hdBYJazWlZ0tKIJULz5u52YLWazRWuJhgl1q6VV//NZvZn9+Tpp+UFv9HIiTqMRudg9XqONPXU1I1GDi5y5YknvHOzxMRk32bwxhuBCXKAVwwufPmlcp1oRyBYwsXrNPKeN6mDqjfN+/wvsruMVyluSa/nvCmhsH49TyRy7bZrF+pDEuQ1QpCHCbud97/Wrw/Ppmao7Fy5l0be8yZFSzH0RJ0X6Kkem0it8raXWyy8GUtEnBRrxAjWio1Gol693O3ZRHyDsbEcWPPss04hbbcTPfSQtxDt00d+gAMHKgvCWrU4hcDLL7NNfe5c5eAdT6ljt3OqgYceYpvGvHnuIfEZGd5RrYFgt7OADlSYu/SZnMyJpRyLBYdpxKH5ntgTT/2rPE3dzQNow8KtXl3XrKksyFNSgr8VIp7/lPawO3UKrU1B3pMjghzAowDOAcgAcBnAv4FcV1AF+f79rDhaLE7vhFwqGiOL3W6nDQu30kOlX6JoKYaaYxSVwG4C3AX6e+8F3CBR376uthqWSB9/zO9nZbGNuE0bFrCzZinnFRk1SlkIGo2cj8XB2bPK5hbPwsxKJCeztq7Xs7mnVi1v04w/liwJLKLUQyMnYs178mRO9zJ0qNPZZcvfcfRQxEDqW3EYHd1xQrbb77/3vn29PnslQrOy+NHJLaDmzQu9XUHekqMaebBHQRTkVqv8D8NoJDp8OO/GdfUqkUGfReWxhu7DCIqWYqgJxlAkjv6nkS8ItGLY8uXygsxgcA/537WL1Xy5xFwOlNK8Og7XoqZpacqCvFWrwMbepYu3ndtk4hwzffpwAem5c1nC+SI2lqsfGwycAMsz/YDJxF44frDb7bTgq7+po7o3PdXgdRr10jXq1o1T5Hhm87XbeXFiMPCeq8HAm5KBWLx8sXkzKxwWC08MRiMvtITnSsFFCPJssmSJ/FJVo+EymnlFbKzTFirBSpURSw/gSYqWYqih9CnVq3qGrNYAG3vgAXlhajbzBmhyMucbd3ihmExE998vL3GUDLSOo3lz9/Pfeks+qdeKFf7HffKk/GalY9fX9T66dw9Oks2Zw07hksS+6AHsFGZaM2nCM1PYM6Xj51Q8Mu2/rQm9nh/NPhm38atXeSsikDQ1gZKUxMkyJ0wg2rs3fO0K8gYhyLPJzJnKZtxBg/JuXDt2eO9BqpFK1fE7tVMPog6q3vTp49/QxVN+ds3i45X9u81mFmgjRngHzej1RMOHe7enVGDCVVN2xWbj1LTFirHQrFaN6M8/A3sIK1cquw/K3cuyZYG1GwJJN5L/24z+cdRMim5vk93zfeCBHBuCoBAjBHk2iY+XV/ocMi6vsNt5o81TBptMROtW3qIpr02nrsb+1FnXl74Z+RNdu3BdvqHx473NCI5Dq2XVTqmyvdHobOfGDaIjR3g3WM5cotPxJquSiePcOU7cHkwEy8WL3hOMryOHytucP36Rhtz1InXW9aWlv6wiIuWAVJVKmDgEwSMEeRh45RV3WWYyEbVoQYGbLnKIc+fY7dpoZItHsWLuk8uVs9do/LBJ1FHTh7oa+9OkV6bR9cseATdffKEsDIcO5XOUpJJaze4Vjz3GbTh2g197jTdFS5RgDfupp3zb1ZcudY9gsVgCj2AZPtx94lAqKKHTBbH7Gzh71x2knqWG0KMln6Dda/b/97qS54jr3CcQBIoQ5GHAbif66y/eV2vdmui77277aOcTTpxgU0tGhvz7549fpE8f/4Y6qntTd/MA+u7Fn+nCiUv85vHj/y057AD9gUfoIfxJXVWxNHf8eXZO6dDBS0BmQaLlaE9/Rg6iLJ3MZuNffwU2eKs1exEsNhtPRpUr8yTSvbv8CsJoZJt6GFk2fQ111vWlIXVeoHPHLri999JL3is5g4GtVAJBsAhBLviP04fOsUDX9KFoKYbe7DyONizcSlkffUJ2g5GewC9kRpKbLO3Zk8h+5Cgnsbrt2ZIKA11HFDVGHKVBQZtv0YKI2IV9yxaXSFNPciKCZcMGHm9kJB8mU1h97zKtmTT1rdkULcXQa+3fo1vXvTd9U1N5UWE08hCMRs4HFqp/uKBooyTIJX4vd2nWrBnFxcXler8Cd66dT8A/U1ch9scVuHb+Ouza4riV1Rgn7Q/iOurANcux2cyZZ++/6xpsk3/Eovd3YltWY/yEYbAgGftwNyxI8e6kYkV8OOIcPvyAoNNaYbNa0bJFBiaOz4BOY0VGqhUZqRlI37UXGe+ORUa6FRnQIANqZEANK9TIqHoHrJ26wpqRiUxrFowRZpAmAuWrRiILEVi/NQopthJ4qFdxxPQzQqt1SQObmQmsW8fpdh94wD3ncJAQEc4fv4Qdy/Zgx/I92LP6AFKT0tBtWDRGfjsUGq1yev9Dh/ioXZvTHxdm7HauTyKy8YYfSZJ2EJFXynAhyAXItNrQuMpO6K4sR3HaA5VkRwYVQwIa4SbqwgYt1JIVXTta0b5tBq5fzcA3EzNAWdbbojYd3bAIdtiR7iKA0yUNkjSRSMlSQQ2ZvOUBoIUdOpMeuggTdEYdbiWpcSshBRokQ4L3d5dUelSoFgVTpBEGsx4GswFGiwH/b+/co6Oqrz3+3ZnkzCvhYQF5ChXQSilwAWkUteWNXORhy5ULiChrIeWyqi0KYtrLEhZL0Hp7S32grS8qYnWhFkRaiWBpV7kqYAwgCJTKQxHQACGBJGSy7x97xkwyZzJnkjlz5pD9WeuszEzm/M73TCb7/M7+7QdlEaqrqlF9MRT+WV33eeRx1Ouh6hCiD1FTU4OKcqmh3v7b7TBwZF/kjx2AQWP6f1NDnFnqxGdnA1de2byM2T//CcyeLc2dPB5g0iTgt78FWrd2WtmlgxpyJS6bNwMTJgDnzgHZOIc2KEIbbMdl2AWDzpnuE4KBEHtRAwMhGGiFMlyJIwigCl6E4KUaeLMJ61tMx/GvA+H3+cI/vcjKNvDM7w207eCD12/AGzDg3b8Pvll3wcsX4b1YCSOL4bntP4DnnweI8OKLwJw5kcZBIeTgPHJQCgNn4EUJvDiN3JwSDB54Bpe3rUBFeSUqyuQnM8OT40GOkQ1PTjayczzINrKRY8hjT07kceS5B55sD7Ky6lrijj06YOCovujYvX3MZ7JtGzB5snSQY5b2fGvXAr16Jff3YJa/RSAgFwQ3cOYM0KMHcPp0bVMNwwCuuUY6AjanC5qdxDPk6iNX+MUX48XIhziAYxzAMW7lO8X795TyhfIKDoVC/PDDsdGF44yNfLr3DVK2b8oU5v37uWtXc7d3MChRijE0kMFy1VXmY9Xf6vfDSAenTsV+hkRSECuZBfG1a5k7d5aIz0BAIqXcUHZ2xQrzaNPc3OQrJSjxgTZfVuIxaBAQCpn9Jgs1vk4wDODlV4CeUTPLBQukN+nSpcDJk+L7nf3YaLS6eXSdEUaOlAl1/daZXq+4HmLIzQVuv91U54kT1s4nL8/a+1LJSy/FfobM0s1u3TppCZiI996TU4+0Kr14EVi5UrruPflkyiWnlOJi8xarNTXAp5/G72+rpAZt063gO98Bxo+XW/kIOTlAx47A66+Lob755rr7EAFz5wLHj4sB++ST2PcAwC9/KY3tDaP2tUBAfKfJug0GDUr8nmAQmDUruXHNCIWs990EpHf1hQuxr1dVyWdkhcWLY43h+fNyITxn7uHKGPr3r/v9iZCVdekv7mYCasgVADKjXL5c/LndugH33APs3i3G2ett/Lhdushsbc4coG9fuWC88w4wZUrse0tKgJdfBl55RXoh1+eRR8RQ129u7/PJRN7rlX7KQ4Y0Xu+BA7K/YUjf5ilTxO+biBtvFA318XiA66+3duyDB81fz862fjfiFNOmyflH/228XvGRWz1/pQmY+Vvs3tRHrtRn1araBkGRelxmVRt372aeNEkSRYcNkyz+9eulom79qoLJcvq09JaOznkyDCmGmCidvrpaQuaji0cGAlI23SoTJpgnpAaDmZV4Fo/Dh5knTpTE3Lw85tmzJX9ASR3QOHIlUzl8WNw7FRV1X/f7gc8+A9q1s/f4p08DpaXiRvrFL2LdG7m5wIYNEobeEBcuiMto1SqZRc+aJZtVF1JxMXDddXWPHwwCBQXAwoXJnZNyaRIvakVdK4rj/PGP5v5oIjGudnHmDHDLLUCHDuICKChoeMEuEX4/MH++uKSKisSdlMw6QJ8+krs0dKgs2PboIReGBx6wPobSPFFD3kw4eFCMVjAItG0rRquqcTk6jeLYMeBnP5MFyzvuAHbtqv3d+fOxUS2ALDiaLSCminHjxF9fWSnHiXcsIqB3b2tjHjkC7NwZe3dhlQEDgHfflTuEAweAO+/UGGzFAmb+Frs39ZGnly+/lJIj0Y2Z/X7xZ6aD/fulImNODn9TwjUQEP82M/P27eYxyD6ffd2X9u+31tXN62XOz0/sIz91SmqM+3y1XXmeftoe7UrzBXF85DojbwY8+aTMNqPdFxcuSO2UeJESqWTBAplhXrwoz2tqZBZ+991iLgcMAO66S+4WiCTyIRAAfv5ziU83o7oa+PvfJfa6sjJ5TUeP1g2JjCY3V9wkLVoAM2cCmzYlnhVPnCiZnRUVcq5lZXIH8t57yWtTlGTRhKBmwAcfmN/qG4b4c3v0sO/YVVWyUGi2pn7smPipW7cGVqyQ2hxr1kjI3rRpQH5+7D6RGliTJ4sBjxjYNWuAMWOs6+rTJ/4FoKICeO01KVtghUOHgB07ai9UEc6fBx57DPjhD63rUpTGoDPyZkCfPuazz+pqoGdPe4/9k5/EGrgIRDLzjTy+6SbgqaeAxx+PNeJlZcCMGTJbHj4c+OorSZIpLZXtxz+WpByrtGkjCU1mVFcDDz5ofayTJyWByoxkNClKY1FD3gyYOzc2qcfrlYVHO7Puzp6VBB+z2TgRcNttkswTj5MngQ8/lFn7rbdKolC8BdqaGmD16uT0PfRQfJfJv/5lfZzvfc98sdYwpESBotiNGvJmQJcu4qsdOFD8z16vZCyuX2/vcb/4Iv5M1eeLXz+kqgqYOlWqB44YAbRvLxUaG/KFV1bKLD0Z/H6ZmZvRvbv1cYJBqTkTnaJuGMBllwHz5iWnSVEag/rImwn9+8vstqpKfNAej/3H7NbNPD48K6s2FNKM++8H3nhDjLPVhczcXGDUqOT0EQFLlsiianT8uN8PLFuW3Fj33itJTb/6FfDll+Kvv+8+CfVUFLvRGXkzwzCsGfFkCkYB4j4pKpKLRcTN4PdLRmJ9g+33A4sWmY8TCgG/+11y8ePBoPjXhw5NTjMgkTNPPCGzf48HuOoqcQeNHZv8WKNHA4WFsoD8yCNNy0hdt05qvvTuLZ/h1183fiylGWAWk2h1A/AogH0AigG8AaCVlf00jjwxVVXMb77J/OtfM2/ZkjiOOVVs3Fhb97t1a+aHH5a+xg2xc6f0PI7USfnWt5gLC+V3NTXMzz8vY7ZsyTxqFPNHH8Ufq7yc2eNJHN8NMGdnM//gB8x/+IPUOmksFRXMu3YxnzjR+DFSyUMP1e0b7fXK51tS4rQyxWlgR/NlACMBZIcfLwew3Mp+asgb5uhR6c2QlydFm3Jzmb//feayMnuPu3VrbJJMIMD84IPx9ykvZ27VKtbIBgLMX3wRf7+GiNdAont35o4d5XMZP16SeprKU0/JeHl5kswzdizz2bNNH7exlJSIDrPkqKVLG973wAFJQnr1VWn6rFx62GLI6wwETASw2sp7m7MhP3yYedky5oIC5m3bzGfaw4bFzkp9Pub777dX25Ah5gbU65XqhMePx+6zZo0YQbN9Ro1ibtdOMjoHD5YMTisUFsqFIFIJ0OORi1lRUWrP989/js0o9Xqlw9CzzzJfe61UPly2LH1d7wsLJTPU7O9www3m+9TUMP/0p/IdCQTk79GyJfP776dHs5I+0mHI1wOY1sDvZwHYDmD7FVdckZaTzjTWrJEZr2GIkQoGmWfMqGvMy8pqU9nrb5dfbq++Dh3MjxspperzMS9eXHefFSvMZ5AR10f9MfbutaZl504pV/vd7zLfeWdqZt/1iXfhysqqe2fi9zP37y/uLrvZtcu8XAGRdM8zY/36uq6YyNauXdNcTkrm0WhDDqAQwG6TbXzUewrCPnJKNB430xn52bPm/6DBoMwMI5SWxjfkbdrYq3H48PiGPFrv5s21+3z8sfl5mW0eD/P06faeQzJY7QEKyB3Ba6+lR1e/frEXwUAg/gx73DhzzXl5zH/7W3o0K+khniFPGLXCzMOZubfJ9icAIKIZAMYCmBo+kGJCYaF5tEh5ed1Elrw8CRWsn6hiGJK9aCdLlpi364qmvFz6SEbo00fqjERHpvh85ucaCkllwExhyBDrZWbLyiSWPR1s3Cgx/36/fB9atACefjp+q7t4lRaJ0lvhUnGOJoUfEtFoAPMBjGNmk0rOSgSPxzyLkCjWmLzwgtQfiRjH3Fyga1dJOrGT/HzgrbeAfv3i6wUkJT6aVavE0Nx0k4yxeLG5gczKEsOfKRQUiJGM1moY5q3tvF6hMFEQAAAG5klEQVSgc+f06GrfXgpw7d0L/PWvwKlTUnsmHlOnmsfk19Rom7Vmg9k03eoG4CCAowCKwttKK/u51bVy4gTzokXMY8YwL1jAfOSI9X3Lysz9mMGghBfW5+xZ5pUrme+7T3zrlZWpOgtrlJaal3kNBiWcMBF33GEeAVNcbLfy5DhyhPnuu5l79JBQxnXrxLdcv+VaMNj0VnJ2cfEi84gR4v4BZA3G7zdvlae4G9i92JnM5kZDfuCAxFVHFvYMQ3yQO3ZYH2PDBjFmwaBER/j9zPPm2ae5qTz3nGiMRNAEg8zXX2/tolJVxTx/vhgXIon+2LrVfs2pYO9e5quvlnMPBpnbtze/2GYSoZB8v+bMkcnGoUNOK1LsIJ4h156dFrnlFuDtt2MzHq+9VsrEWqWkRNqXlZVJh/p49bYzheJi4JlnpI7JhAnAj34Uv36KGcziG0+m5VkmwCy12isrgV696naHVxSniNezUw25RYJB836OWVmSTh6vSYGiKEqq0ObLTSReNEdOTnoKUCnugVnuuoYNk+iT5cvlDkxR7EINuUVmzaptghAhUg5WDbkSzfz5wPTpEq64Y4fUPc/Pt7eRtNK8UUNukUWLpElApJdjICD/nL/5jdPKlEzi88+lw1F5ee1rFy4An30mVRUVxQ5ctgTlHIYBvPkmcOCAlCnt2VNKjCpKNP/4h3xX6ifplJdL79KZM53RpVzaqCFPkp497e9zqbiXdu3ER14fjwfo1Cn9epTmgbpWFCWF3HijtHirH65oGNKIWlHsQA25oqSQrCzg3XclPyAQkFopLVtKGYNevZxWp1yqqGtFUVJM9+7Anj3Avn3AuXNSu0bzDBQ7UUOuKDZABFxzjdMqlOaCulYURVFcjhpyRVEUl6OGXFEUxeWoIVcURXE5asgVRVFcjhpyRVEUl6OGXFEUxeWoIVcURXE5asgVRVFcjhpyRVEUl6OGXFEUxeWoIVcURXE5asgVRVFcjhpyRVEUl9MkQ05ES4iomIiKiOgdIuqYKmGKoiiKNZo6I3+Umfswcz8AbwH47xRoUhRFUZKgSYacmUujngYBmLSdVRRFUeykyR2CiGgpgOkAzgIY0sD7ZgGYFX5aSUS7m3rsNNMGwFdOi0gS1Ww/btMLqOZ0YYfmrmYvEnPDk2giKgTQ3uRXBcz8p6j3LQTgY+ZFiZQQ0XZmHpjofZmEak4PbtPsNr2Aak4X6dSccEbOzMMtjrUawNsAEhpyRVEUJXU0NWqlZ9TT8QD2NU2OoiiKkixN9ZEvI6KrAdQAOAxgtsX9nmnicZ1ANacHt2l2m15ANaeLtGlO6CNXFEVRMhvN7FQURXE5asgVRVFcjmOG3I3p/UT0KBHtC+t+g4haOa2pIYhoEhHtIaIaIsro0C0iGk1EnxLRQSJ6wGk9iSCi54jopJvyIYioCxFtIaJPwt+Le5zWlAgi8hHRB0T0cVjzQ05rsgIReYjoIyJ6Kx3Hc3JG7sb0/k0AejNzHwD7ASx0WE8idgO4FcBWp4U0BBF5ADwB4GYAvQD8JxH1clZVQl4AMNppEUlSDWAeM/cCkA/gv1zwOVcCGMrMfQH0AzCaiPId1mSFewDsTdfBHDPkbkzvZ+Z3mLk6/PT/AHR2Uk8imHkvM3/qtA4LDAJwkJkPMXMVgFcg4awZCzNvBVDitI5kYObjzLwz/PgcxNB0clZVw7BQFn6aE94y2lYQUWcA/w7g9+k6pqM+ciJaSkRHAUyFO2bk0dwFYKPTIi4ROgE4GvX8GDLcwLgdIuoG4N8AvO+sksSE3RRFAE4C2MTMma75fwHMh4RlpwVbDTkRFRLRbpNtPAAwcwEzd4Fkhc61U4tVEmkOv6cAcpu62jml32hJqFdRoiGiXABrAdxb7844I2HmUNgF2xnAICLq7bSmeBDRWAAnmXlHOo/b5KJZDeHG9P5EmoloBoCxAIZxBgThJ/EZZzKfA+gS9bxz+DUlxRBRDsSIr2bm153WkwzMfIaItkDWJjJ1kXkwgHFENAaAD0ALInqJmafZeVAno1Zcl95PRKMht0zjmPm803ouIT4E0JOIvk1EBoDJANY5rOmSg4gIwLMA9jLz/zitxwpE1DYSHUZEfgAjkMG2gpkXMnNnZu4G+R5vttuIA876yJeFXQDFAEZCVnkznccB5AHYFA6bXOm0oIYgoolEdAzAdQA2ENFfnNZkRngBeS6Av0AW4F5l5j3OqmoYIloDYBuAq4noGBHNdFqTBQYDuB3A0PD3tyg8c8xkOgDYErYTH0J85GkJ6XMTmqKvKIricjSzU1EUxeWoIVcURXE5asgVRVFcjhpyRVEUl6OGXFEUxeWoIVcURXE5asgVRVFczv8D6BNrlnCpFeIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgSPU__Sto9w"
      },
      "source": [
        "## 2.6 优化器\n",
        "- 待优化参数𝒘, 损失函数loss, 学习率𝒍r, 每次迭代一个batch(2^n), t表示当前batch迭代的总次数.\n",
        "  - 一阶动量:与梯度相关的函数\n",
        "  - 二阶动量:与梯度平方相关的函数\n",
        "- 优化器\n",
        "  - SGD(无momentum), 常用的梯度下降法\n",
        "  - SGDM(含momentum的SGD), 在SGD基础上增加一阶动量\n",
        "  - Adagrad，在SGD基础上增加二阶动量\n",
        "  - RMSProp，SGD基础上增加二阶动量\n",
        "  - Adam, 同时结合SGDM一阶动量和RMSProp二阶动量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5YLAp2UJwA-L",
        "outputId": "2cfd0654-c41a-4658-bb91-e92dc444e995"
      },
      "source": [
        "# p32_sgd.py\n",
        "\n",
        "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
        "\n",
        "# 导入所需模块\n",
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time  ##1##\n",
        "\n",
        "# 导入数据，分别为输入特征和标签\n",
        "x_data = datasets.load_iris().data\n",
        "y_data = datasets.load_iris().target\n",
        "\n",
        "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
        "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
        "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
        "np.random.shuffle(x_data)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y_data)\n",
        "tf.random.set_seed(116)\n",
        "\n",
        "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
        "x_train = x_data[:-30]\n",
        "y_train = y_data[:-30]\n",
        "x_test = x_data[-30:]\n",
        "y_test = y_data[-30:]\n",
        "\n",
        "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "x_test = tf.cast(x_test, tf.float32)\n",
        "\n",
        "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
        "# 用tf.Variable()标记参数可训练\n",
        "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
        "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
        "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n",
        "\n",
        "lr = 0.1  # 学习率为0.1\n",
        "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
        "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
        "epoch = 500  # 循环500轮\n",
        "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
        "\n",
        "# 训练部分\n",
        "now_time = time.time()  ##2##\n",
        "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
        "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
        "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
        "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
        "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
        "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
        "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
        "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
        "        # 计算loss对各个参数的梯度\n",
        "        grads = tape.gradient(loss, [w1, b1])\n",
        "\n",
        "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad\n",
        "        w1.assign_sub(lr * grads[0])  # 参数w1自更新\n",
        "        b1.assign_sub(lr * grads[1])  # 参数b自更新\n",
        "\n",
        "    # 每个epoch，打印loss信息\n",
        "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
        "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
        "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
        "\n",
        "    # 测试部分\n",
        "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
        "    total_correct, total_number = 0, 0\n",
        "    for x_test, y_test in test_db:\n",
        "        # 使用更新后的参数进行预测\n",
        "        y = tf.matmul(x_test, w1) + b1\n",
        "        y = tf.nn.softmax(y)\n",
        "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
        "        # 将pred转换为y_test的数据类型\n",
        "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
        "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
        "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
        "        # 将每个batch的correct数加起来\n",
        "        correct = tf.reduce_sum(correct)\n",
        "        # 将所有batch中的correct数加起来\n",
        "        total_correct += int(correct)\n",
        "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
        "        total_number += x_test.shape[0]\n",
        "    # 总的准确率等于total_correct/total_number\n",
        "    acc = total_correct / total_number\n",
        "    test_acc.append(acc)\n",
        "    print(\"Test_acc:\", acc)\n",
        "    print(\"--------------------------\")\n",
        "total_time = time.time() - now_time  ##3##\n",
        "print(\"total_time\", total_time)  ##4##\n",
        "\n",
        "# 绘制 loss 曲线\n",
        "plt.title('Loss Function Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Loss')  # y轴变量名称\n",
        "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
        "plt.legend()  # 画出曲线图标\n",
        "plt.show()  # 画出图像\n",
        "\n",
        "# 绘制 Accuracy 曲线\n",
        "plt.title('Acc Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Acc')  # y轴变量名称\n",
        "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 本文件较 class1\\p45_iris.py 仅添加四处时间记录  用 ##n## 标识\n",
        "# 请将loss曲线、ACC曲线、total_time记录到 class2\\优化器对比.docx  对比各优化器收敛情况"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 0.2821310982108116\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 1, loss: 0.25459614023566246\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 2, loss: 0.22570250928401947\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 3, loss: 0.21028399094939232\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 4, loss: 0.19942265003919601\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 5, loss: 0.18873637914657593\n",
            "Test_acc: 0.5\n",
            "--------------------------\n",
            "Epoch 6, loss: 0.17851299792528152\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 7, loss: 0.16922875866293907\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 8, loss: 0.16107673197984695\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 9, loss: 0.15404683724045753\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 10, loss: 0.14802725985646248\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 11, loss: 0.14287303388118744\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 12, loss: 0.1384414117783308\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 13, loss: 0.13460607454180717\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 14, loss: 0.1312607266008854\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 15, loss: 0.12831821478903294\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 16, loss: 0.12570795975625515\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 17, loss: 0.12337299063801765\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 18, loss: 0.12126746587455273\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 19, loss: 0.11935433372855186\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 20, loss: 0.11760355345904827\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 21, loss: 0.11599067784845829\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 22, loss: 0.11449568346142769\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 23, loss: 0.11310207471251488\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 24, loss: 0.11179621890187263\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 25, loss: 0.11056671850383282\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 26, loss: 0.10940407775342464\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 27, loss: 0.10830028168857098\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 28, loss: 0.10724855773150921\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 29, loss: 0.10624313540756702\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 30, loss: 0.1052790954709053\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 31, loss: 0.10435222089290619\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 32, loss: 0.10345886647701263\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 33, loss: 0.1025958750396967\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 34, loss: 0.10176053084433079\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 35, loss: 0.10095042362809181\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 36, loss: 0.10016347467899323\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 37, loss: 0.09939785115420818\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 38, loss: 0.098651934415102\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 39, loss: 0.09792428836226463\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 40, loss: 0.09721364825963974\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 41, loss: 0.09651889465749264\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 42, loss: 0.09583901800215244\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 43, loss: 0.09517310746014118\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 44, loss: 0.09452036581933498\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 45, loss: 0.09388007409870625\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 46, loss: 0.09325156360864639\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 47, loss: 0.09263425506651402\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 48, loss: 0.09202759712934494\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 49, loss: 0.09143111854791641\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 50, loss: 0.09084435924887657\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 51, loss: 0.09026693738996983\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 52, loss: 0.08969846740365028\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 53, loss: 0.08913860842585564\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 54, loss: 0.08858705498278141\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 55, loss: 0.08804351836442947\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 56, loss: 0.08750772848725319\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 57, loss: 0.08697944693267345\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 58, loss: 0.08645843341946602\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 59, loss: 0.08594449236989021\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 60, loss: 0.08543741330504417\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 61, loss: 0.08493702113628387\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 62, loss: 0.08444313518702984\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 63, loss: 0.08395559713244438\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 64, loss: 0.08347426541149616\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 65, loss: 0.08299898356199265\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 66, loss: 0.08252961747348309\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 67, loss: 0.08206604234874249\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 68, loss: 0.08160813339054585\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 69, loss: 0.08115578815340996\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 70, loss: 0.08070887438952923\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 71, loss: 0.08026731759309769\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 72, loss: 0.07983099296689034\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 73, loss: 0.07939982041716576\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 74, loss: 0.07897370308637619\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 75, loss: 0.07855254970490932\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 76, loss: 0.07813628017902374\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 77, loss: 0.07772481627762318\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 78, loss: 0.07731806859374046\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 79, loss: 0.07691597938537598\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 80, loss: 0.07651844993233681\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 81, loss: 0.07612544856965542\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 82, loss: 0.075736865401268\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 83, loss: 0.07535266131162643\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 84, loss: 0.07497274875640869\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 85, loss: 0.0745970867574215\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 86, loss: 0.07422560174018145\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 87, loss: 0.07385823410004377\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 88, loss: 0.07349492609500885\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 89, loss: 0.0731356255710125\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 90, loss: 0.07278026919811964\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 91, loss: 0.0724288085475564\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 92, loss: 0.0720811877399683\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 93, loss: 0.07173734437674284\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 94, loss: 0.07139724120497704\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 95, loss: 0.07106082327663898\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 96, loss: 0.07072803657501936\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 97, loss: 0.07039884105324745\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 98, loss: 0.07007318269461393\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 99, loss: 0.06975101679563522\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 100, loss: 0.06943229679018259\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 101, loss: 0.06911697331815958\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 102, loss: 0.06880501005798578\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 103, loss: 0.0684963557869196\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 104, loss: 0.06819096300750971\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 105, loss: 0.06788880191743374\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 106, loss: 0.06758982222527266\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 107, loss: 0.0672939857468009\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 108, loss: 0.06700124684721231\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 109, loss: 0.06671156641095877\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 110, loss: 0.06642491556704044\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 111, loss: 0.06614124123007059\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 112, loss: 0.06586051359772682\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 113, loss: 0.06558268796652555\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 114, loss: 0.06530772987753153\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 115, loss: 0.06503561232239008\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 116, loss: 0.06476627569645643\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 117, loss: 0.06449970323592424\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 118, loss: 0.06423585955053568\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 119, loss: 0.0639747017994523\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 120, loss: 0.06371619831770658\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 121, loss: 0.06346031371504068\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 122, loss: 0.06320701539516449\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 123, loss: 0.06295627355575562\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 124, loss: 0.06270804908126593\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 125, loss: 0.06246231496334076\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 126, loss: 0.06221903674304485\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 127, loss: 0.061978189274668694\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 128, loss: 0.06173973251134157\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 129, loss: 0.06150364130735397\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 130, loss: 0.06126988772302866\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 131, loss: 0.0610384326428175\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 132, loss: 0.06080926116555929\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 133, loss: 0.060582331381738186\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 134, loss: 0.06035762559622526\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 135, loss: 0.06013511028140783\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 136, loss: 0.05991474911570549\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 137, loss: 0.05969652533531189\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 138, loss: 0.059480415657162666\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 139, loss: 0.05926638841629028\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 140, loss: 0.05905440915375948\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 141, loss: 0.05884446296840906\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 142, loss: 0.05863652378320694\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 143, loss: 0.058430569246411324\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 144, loss: 0.05822655279189348\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 145, loss: 0.05802448280155659\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 146, loss: 0.05782431177794933\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 147, loss: 0.05762602761387825\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 148, loss: 0.0574295949190855\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 149, loss: 0.05723499599844217\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 150, loss: 0.05704221688210964\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 151, loss: 0.056851224042475224\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 152, loss: 0.05666199326515198\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 153, loss: 0.05647451803088188\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 154, loss: 0.056288765743374825\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 155, loss: 0.05610471311956644\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 156, loss: 0.05592234339565039\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 157, loss: 0.05574163515120745\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 158, loss: 0.05556256137788296\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 159, loss: 0.05538511835038662\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 160, loss: 0.05520927347242832\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 161, loss: 0.05503500904887915\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 162, loss: 0.0548623101785779\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 163, loss: 0.054691143333911896\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 164, loss: 0.05452151596546173\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 165, loss: 0.054353379644453526\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 166, loss: 0.05418673437088728\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 167, loss: 0.05402155872434378\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 168, loss: 0.05385783687233925\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 169, loss: 0.053695556707680225\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 170, loss: 0.05353467911481857\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 171, loss: 0.053375206887722015\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 172, loss: 0.05321711953729391\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 173, loss: 0.053060395643115044\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 174, loss: 0.05290502496063709\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 175, loss: 0.05275098513811827\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 176, loss: 0.05259825848042965\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 177, loss: 0.05244683939963579\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 178, loss: 0.05229670833796263\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 179, loss: 0.05214784760028124\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 180, loss: 0.052000248804688454\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 181, loss: 0.051853885874152184\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 182, loss: 0.05170875322073698\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 183, loss: 0.05156483594328165\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 184, loss: 0.0514221154153347\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 185, loss: 0.051280584186315536\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 186, loss: 0.05114021711051464\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 187, loss: 0.05100101325660944\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 188, loss: 0.050862944684922695\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 189, loss: 0.05072600953280926\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 190, loss: 0.05059020034968853\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 191, loss: 0.05045549105852842\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 192, loss: 0.05032187607139349\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 193, loss: 0.050189344212412834\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 194, loss: 0.05005786940455437\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 195, loss: 0.049927459098398685\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 196, loss: 0.04979808907955885\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 197, loss: 0.049669744446873665\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 198, loss: 0.049542427994310856\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 199, loss: 0.04941611923277378\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 200, loss: 0.04929081164300442\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 201, loss: 0.0491664744913578\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 202, loss: 0.049043125472962856\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 203, loss: 0.048920733854174614\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 204, loss: 0.0487992987036705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 205, loss: 0.04867880791425705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 206, loss: 0.04855924379080534\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 207, loss: 0.04844060353934765\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 208, loss: 0.048322875052690506\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 209, loss: 0.04820605181157589\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 210, loss: 0.04809011612087488\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 211, loss: 0.04797506146132946\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 212, loss: 0.0478608813136816\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 213, loss: 0.04774756357073784\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 214, loss: 0.047635097056627274\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 215, loss: 0.04752347245812416\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 216, loss: 0.0474126860499382\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 217, loss: 0.047302727587521076\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 218, loss: 0.04719358589500189\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 219, loss: 0.04708525165915489\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 220, loss: 0.04697771091014147\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 221, loss: 0.04687096830457449\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 222, loss: 0.04676501080393791\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 223, loss: 0.04665982723236084\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 224, loss: 0.04655539896339178\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 225, loss: 0.046451738104224205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 226, loss: 0.046348835341632366\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 227, loss: 0.04624665342271328\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 228, loss: 0.046145214699208736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 229, loss: 0.046044510789215565\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 230, loss: 0.045944519340991974\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 231, loss: 0.04584524221718311\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 232, loss: 0.045746663585305214\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 233, loss: 0.04564878437668085\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 234, loss: 0.045551604591310024\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 235, loss: 0.045455098152160645\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 236, loss: 0.04535927437245846\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 237, loss: 0.045264110900461674\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 238, loss: 0.045169608667492867\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 239, loss: 0.04507576674222946\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 240, loss: 0.04498257301747799\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 241, loss: 0.044890021905303\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 242, loss: 0.0447981134057045\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 243, loss: 0.04470681585371494\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 244, loss: 0.04461615812033415\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 245, loss: 0.04452610854059458\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 246, loss: 0.044436678290367126\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 247, loss: 0.04434784408658743\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 248, loss: 0.04425961244851351\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 249, loss: 0.044171975925564766\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 250, loss: 0.04408491309732199\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 251, loss: 0.04399844352155924\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 252, loss: 0.043912545777857304\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 253, loss: 0.04382721334695816\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 254, loss: 0.04374244902282953\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 255, loss: 0.04365824814885855\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 256, loss: 0.043574594892561436\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 257, loss: 0.0434914892539382\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 258, loss: 0.04340892657637596\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 259, loss: 0.04332689940929413\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 260, loss: 0.0432454077526927\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 261, loss: 0.043164439499378204\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 262, loss: 0.04308400023728609\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 263, loss: 0.043004073202610016\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 264, loss: 0.04292465187609196\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 265, loss: 0.042845748364925385\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 266, loss: 0.04276734683662653\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 267, loss: 0.0426894361153245\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 268, loss: 0.04261201433837414\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 269, loss: 0.042535096406936646\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 270, loss: 0.042458648793399334\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 271, loss: 0.042382681742310524\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 272, loss: 0.04230719804763794\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 273, loss: 0.04223218001425266\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 274, loss: 0.042157627642154694\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 275, loss: 0.04208353813737631\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 276, loss: 0.042009901255369186\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 277, loss: 0.04193672351539135\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 278, loss: 0.04186399281024933\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 279, loss: 0.041791705414652824\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 280, loss: 0.04171985574066639\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 281, loss: 0.0416484484449029\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 282, loss: 0.0415774742141366\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 283, loss: 0.04150693118572235\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 284, loss: 0.04143680725246668\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 285, loss: 0.04136710520833731\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 286, loss: 0.04129782412201166\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 287, loss: 0.041228956542909145\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 288, loss: 0.041160495951771736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 289, loss: 0.04109245166182518\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 290, loss: 0.041024803183972836\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 291, loss: 0.0409575579687953\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 292, loss: 0.040890698321163654\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 293, loss: 0.04082423634827137\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 294, loss: 0.040758173912763596\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 295, loss: 0.04069248586893082\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 296, loss: 0.040627180598676205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 297, loss: 0.04056225158274174\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 298, loss: 0.04049770347774029\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 299, loss: 0.040433524176478386\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 300, loss: 0.040369716472923756\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 301, loss: 0.04030627757310867\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 302, loss: 0.04024319630116224\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 303, loss: 0.04018047358840704\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 304, loss: 0.04011811316013336\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 305, loss: 0.04005609964951873\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 306, loss: 0.0399944419041276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 307, loss: 0.03993312967941165\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 308, loss: 0.03987216204404831\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 309, loss: 0.039811535738408566\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 310, loss: 0.03975125262513757\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 311, loss: 0.03969130339100957\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 312, loss: 0.03963168291375041\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 313, loss: 0.0395723944529891\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 314, loss: 0.03951343335211277\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 315, loss: 0.039454799611121416\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 316, loss: 0.03939648764207959\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 317, loss: 0.0393384899944067\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 318, loss: 0.03928081365302205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 319, loss: 0.03922345116734505\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 320, loss: 0.03916640346869826\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 321, loss: 0.03910966170951724\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 322, loss: 0.039053224958479404\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 323, loss: 0.038997096475213766\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 324, loss: 0.03894126368686557\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 325, loss: 0.03888574009761214\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 326, loss: 0.03883049916476011\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 327, loss: 0.03877556277438998\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 328, loss: 0.038720916491001844\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 329, loss: 0.03866655984893441\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 330, loss: 0.0386124849319458\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 331, loss: 0.038558701518923044\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 332, loss: 0.03850520448759198\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 333, loss: 0.038451981265097857\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 334, loss: 0.03839903650805354\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 335, loss: 0.03834637440741062\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 336, loss: 0.03829398052766919\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 337, loss: 0.03824185719713569\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 338, loss: 0.03819000441581011\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 339, loss: 0.03813841845840216\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 340, loss: 0.03808710305020213\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 341, loss: 0.03803604794666171\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 342, loss: 0.037985255010426044\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 343, loss: 0.03793471958488226\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 344, loss: 0.0378844472579658\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 345, loss: 0.03783442033454776\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 346, loss: 0.03778465045616031\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 347, loss: 0.03773513436317444\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 348, loss: 0.03768586693331599\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 349, loss: 0.03763684583827853\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 350, loss: 0.03758807061240077\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 351, loss: 0.03753954125568271\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 352, loss: 0.03749125171452761\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 353, loss: 0.03744320385158062\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 354, loss: 0.03739538975059986\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 355, loss: 0.03734782012179494\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 356, loss: 0.03730047447606921\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 357, loss: 0.037253370974212885\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 358, loss: 0.03720649937167764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 359, loss: 0.037159846629947424\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 360, loss: 0.037113435566425323\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 361, loss: 0.037067238707095385\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 362, loss: 0.037021271884441376\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 363, loss: 0.0369755276478827\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 364, loss: 0.036930004600435495\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 365, loss: 0.03688469575718045\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 366, loss: 0.03683961136266589\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 367, loss: 0.036794747691601515\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 368, loss: 0.036750093568116426\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 369, loss: 0.03670565132051706\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 370, loss: 0.036661419086158276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 371, loss: 0.0366173954680562\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 372, loss: 0.036573588848114014\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 373, loss: 0.03652998572215438\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 374, loss: 0.03648658515885472\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 375, loss: 0.036443385761231184\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 376, loss: 0.036400394048541784\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 377, loss: 0.03635760163888335\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 378, loss: 0.03631501505151391\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 379, loss: 0.03627261985093355\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 380, loss: 0.036230424884706736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 381, loss: 0.03618842689320445\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 382, loss: 0.03614661982282996\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 383, loss: 0.036105002742260695\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 384, loss: 0.03606357332319021\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 385, loss: 0.036022346932440996\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 386, loss: 0.035981299821287394\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 387, loss: 0.03594044502824545\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 388, loss: 0.035899769980460405\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 389, loss: 0.03585928771644831\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 390, loss: 0.035818986129015684\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 391, loss: 0.035778868943452835\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 392, loss: 0.03573892870917916\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 393, loss: 0.03569917054846883\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 394, loss: 0.03565959073603153\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 395, loss: 0.0356201846152544\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 396, loss: 0.0355809610337019\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 397, loss: 0.03554191021248698\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 398, loss: 0.03550302796065807\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 399, loss: 0.03546432591974735\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 400, loss: 0.035425787791609764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 401, loss: 0.035387429874390364\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 402, loss: 0.03534922981634736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 403, loss: 0.03531120205298066\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 404, loss: 0.035273339599370956\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 405, loss: 0.035235646180808544\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 406, loss: 0.03519811388105154\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 407, loss: 0.035160749685019255\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 408, loss: 0.03512354427948594\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 409, loss: 0.03508649254217744\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 410, loss: 0.03504961123690009\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 411, loss: 0.03501288825646043\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 412, loss: 0.03497631987556815\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 413, loss: 0.034939908888190985\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 414, loss: 0.03490365715697408\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 415, loss: 0.034867554903030396\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 416, loss: 0.03483161702752113\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 417, loss: 0.034795820247381926\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 418, loss: 0.03476017713546753\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 419, loss: 0.03472468722611666\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 420, loss: 0.03468935331329703\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 421, loss: 0.034654161892831326\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 422, loss: 0.034619121346622705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 423, loss: 0.034584220964461565\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 424, loss: 0.034549469128251076\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 425, loss: 0.03451486863195896\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 426, loss: 0.034480401780456305\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 427, loss: 0.03444609045982361\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 428, loss: 0.03441191604360938\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 429, loss: 0.03437788272276521\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 430, loss: 0.03434399701654911\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 431, loss: 0.03431023797020316\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 432, loss: 0.03427662793546915\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 433, loss: 0.03424314735457301\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 434, loss: 0.03420981531962752\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 435, loss: 0.034176604356616735\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 436, loss: 0.03414354287087917\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 437, loss: 0.03411060757935047\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 438, loss: 0.03407781198620796\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 439, loss: 0.034045142121613026\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 440, loss: 0.03401261195540428\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 441, loss: 0.03398020751774311\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 442, loss: 0.03394793486222625\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 443, loss: 0.03391578746959567\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 444, loss: 0.033883774653077126\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 445, loss: 0.03385188477113843\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 446, loss: 0.033820128068327904\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 447, loss: 0.033788494765758514\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 448, loss: 0.03375698672607541\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 449, loss: 0.03372560767456889\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 450, loss: 0.033694347366690636\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 451, loss: 0.03366320813074708\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 452, loss: 0.03363219602033496\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 453, loss: 0.033601312432438135\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 454, loss: 0.0335705429315567\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 455, loss: 0.03353988705202937\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 456, loss: 0.033509362023323774\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 457, loss: 0.03347894921898842\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 458, loss: 0.033448657020926476\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 459, loss: 0.0334184761159122\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 460, loss: 0.03338842326775193\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 461, loss: 0.03335847472772002\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 462, loss: 0.033328655175864697\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 463, loss: 0.03329893993213773\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 464, loss: 0.033269337844103575\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 465, loss: 0.0332398503087461\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 466, loss: 0.033210481982678175\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 467, loss: 0.03318121936172247\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 468, loss: 0.033152072224766016\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 469, loss: 0.03312302893027663\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 470, loss: 0.03309410251677036\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 471, loss: 0.03306528506800532\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 472, loss: 0.033036574721336365\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 473, loss: 0.03300797659903765\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 474, loss: 0.032979479525238276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 475, loss: 0.032951084431260824\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 476, loss: 0.03292280109599233\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 477, loss: 0.032894632779061794\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 478, loss: 0.03286655526608229\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 479, loss: 0.03283859230577946\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 480, loss: 0.03281072760000825\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 481, loss: 0.032782965805381536\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 482, loss: 0.03275530831888318\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 483, loss: 0.032727754674851894\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 484, loss: 0.03270029369741678\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 485, loss: 0.0326729454100132\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 486, loss: 0.03264568652957678\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 487, loss: 0.03261853661388159\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 488, loss: 0.03259148262441158\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 489, loss: 0.03256453201174736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 490, loss: 0.03253767127171159\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 491, loss: 0.032510911114513874\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 492, loss: 0.03248424641788006\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 493, loss: 0.032457676250487566\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 494, loss: 0.03243120852857828\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 495, loss: 0.03240483347326517\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 496, loss: 0.03237855341285467\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 497, loss: 0.03235236182808876\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 498, loss: 0.0323262675665319\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 499, loss: 0.032300271559506655\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "total_time 5.976965427398682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AZJiKbjuxjD-",
        "outputId": "b31ec49b-2535-440c-87c2-edb4a5f5f18b"
      },
      "source": [
        "# p34_sgdm.py\n",
        "\n",
        "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
        "\n",
        "# 导入所需模块\n",
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time  ##1##\n",
        "\n",
        "# 导入数据，分别为输入特征和标签\n",
        "x_data = datasets.load_iris().data\n",
        "y_data = datasets.load_iris().target\n",
        "\n",
        "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
        "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
        "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
        "np.random.shuffle(x_data)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y_data)\n",
        "tf.random.set_seed(116)\n",
        "\n",
        "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
        "x_train = x_data[:-30]\n",
        "y_train = y_data[:-30]\n",
        "x_test = x_data[-30:]\n",
        "y_test = y_data[-30:]\n",
        "\n",
        "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "x_test = tf.cast(x_test, tf.float32)\n",
        "\n",
        "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
        "# 用tf.Variable()标记参数可训练\n",
        "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
        "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
        "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n",
        "\n",
        "lr = 0.1  # 学习率为0.1\n",
        "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
        "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
        "epoch = 500  # 循环500轮\n",
        "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
        "\n",
        "##########################################################################\n",
        "m_w, m_b = 0, 0\n",
        "beta = 0.9\n",
        "##########################################################################\n",
        "\n",
        "# 训练部分\n",
        "now_time = time.time()  ##2##\n",
        "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
        "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
        "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
        "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
        "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
        "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
        "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
        "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
        "        # 计算loss对各个参数的梯度\n",
        "        grads = tape.gradient(loss, [w1, b1])\n",
        "\n",
        "        ##########################################################################\n",
        "        # sgd-momentun  \n",
        "        m_w = beta * m_w + (1 - beta) * grads[0]\n",
        "        m_b = beta * m_b + (1 - beta) * grads[1]\n",
        "        w1.assign_sub(lr * m_w)\n",
        "        b1.assign_sub(lr * m_b)\n",
        "    ##########################################################################\n",
        "\n",
        "    # 每个epoch，打印loss信息\n",
        "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
        "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
        "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
        "\n",
        "    # 测试部分\n",
        "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
        "    total_correct, total_number = 0, 0\n",
        "    for x_test, y_test in test_db:\n",
        "        # 使用更新后的参数进行预测\n",
        "        y = tf.matmul(x_test, w1) + b1\n",
        "        y = tf.nn.softmax(y)\n",
        "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
        "        # 将pred转换为y_test的数据类型\n",
        "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
        "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
        "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
        "        # 将每个batch的correct数加起来\n",
        "        correct = tf.reduce_sum(correct)\n",
        "        # 将所有batch中的correct数加起来\n",
        "        total_correct += int(correct)\n",
        "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
        "        total_number += x_test.shape[0]\n",
        "    # 总的准确率等于total_correct/total_number\n",
        "    acc = total_correct / total_number\n",
        "    test_acc.append(acc)\n",
        "    print(\"Test_acc:\", acc)\n",
        "    print(\"--------------------------\")\n",
        "total_time = time.time() - now_time  ##3##\n",
        "print(\"total_time\", total_time)  ##4##\n",
        "\n",
        "# 绘制 loss 曲线\n",
        "plt.title('Loss Function Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Loss')  # y轴变量名称\n",
        "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
        "plt.legend()  # 画出曲线图标\n",
        "plt.show()  # 画出图像\n",
        "\n",
        "# 绘制 Accuracy 曲线\n",
        "plt.title('Acc Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Acc')  # y轴变量名称\n",
        "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 请将loss曲线、ACC曲线、total_time记录到 class2\\优化器对比.docx  对比各优化器收敛情况"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 0.2961867228150368\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 1, loss: 0.28081152215600014\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 2, loss: 0.26392313465476036\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 3, loss: 0.241925410926342\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 4, loss: 0.2185598537325859\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 5, loss: 0.20465287193655968\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 6, loss: 0.1955692134797573\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 7, loss: 0.18339980021119118\n",
            "Test_acc: 0.5\n",
            "--------------------------\n",
            "Epoch 8, loss: 0.17289478331804276\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 9, loss: 0.1638195775449276\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 10, loss: 0.1557205729186535\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 11, loss: 0.14825155958533287\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 12, loss: 0.14126422442495823\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 13, loss: 0.1357906050980091\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 14, loss: 0.13151294365525246\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 15, loss: 0.12771007604897022\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 16, loss: 0.12420251406729221\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 17, loss: 0.12114136479794979\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 18, loss: 0.11857618018984795\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 19, loss: 0.11636174842715263\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 20, loss: 0.11436180770397186\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 21, loss: 0.11252963729202747\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 22, loss: 0.11085251718759537\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 23, loss: 0.10932631976902485\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 24, loss: 0.10794147104024887\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 25, loss: 0.1066653672605753\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 26, loss: 0.10546092130243778\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 27, loss: 0.10430946759879589\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 28, loss: 0.103210324421525\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 29, loss: 0.10216888971626759\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 30, loss: 0.10118388943374157\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 31, loss: 0.10024458356201649\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 32, loss: 0.09933911450207233\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 33, loss: 0.09846180491149426\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 34, loss: 0.09761266596615314\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 35, loss: 0.09679243713617325\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 36, loss: 0.09599893726408482\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 37, loss: 0.09522782638669014\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 38, loss: 0.09447568841278553\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 39, loss: 0.09374142810702324\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 40, loss: 0.0930252056568861\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 41, loss: 0.09232662618160248\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 42, loss: 0.09164421632885933\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 43, loss: 0.09097621217370033\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 44, loss: 0.090321509167552\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 45, loss: 0.08967970311641693\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 46, loss: 0.08905054070055485\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 47, loss: 0.08843343891203403\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 48, loss: 0.08782758563756943\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 49, loss: 0.08723233453929424\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 50, loss: 0.08664725162088871\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 51, loss: 0.08607210405170918\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 52, loss: 0.08550657518208027\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 53, loss: 0.0849502868950367\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 54, loss: 0.08440281637012959\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 55, loss: 0.08386383950710297\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 56, loss: 0.08333313837647438\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 57, loss: 0.08281049132347107\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 58, loss: 0.08229565247893333\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 59, loss: 0.08178837038576603\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 60, loss: 0.0812884084880352\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 61, loss: 0.08079558610916138\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 62, loss: 0.08030973561108112\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 63, loss: 0.07983068935573101\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 64, loss: 0.07935826107859612\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 65, loss: 0.07889228872954845\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 66, loss: 0.07843263074755669\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 67, loss: 0.07797914370894432\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 68, loss: 0.07753170281648636\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 69, loss: 0.07709015812724829\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 70, loss: 0.0766544034704566\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 71, loss: 0.07622430007904768\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 72, loss: 0.07579974923282862\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 73, loss: 0.07538063544780016\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 74, loss: 0.07496685441583395\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 75, loss: 0.07455830369144678\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 76, loss: 0.07415488082915545\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 77, loss: 0.07375650107860565\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 78, loss: 0.07336306106299162\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 79, loss: 0.07297447603195906\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 80, loss: 0.07259066309779882\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 81, loss: 0.07221153751015663\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 82, loss: 0.07183700613677502\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 83, loss: 0.07146701496094465\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 84, loss: 0.0711014624685049\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 85, loss: 0.07074028346687555\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 86, loss: 0.0703834081068635\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 87, loss: 0.07003076747059822\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 88, loss: 0.06968228332698345\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 89, loss: 0.06933788675814867\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 90, loss: 0.06899751629680395\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 91, loss: 0.06866112072020769\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 92, loss: 0.06832861807197332\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 93, loss: 0.06799995712935925\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 94, loss: 0.06767507176846266\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 95, loss: 0.06735390704125166\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 96, loss: 0.06703640520572662\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 97, loss: 0.0667225057259202\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 98, loss: 0.06641215644776821\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 99, loss: 0.06610530614852905\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 100, loss: 0.06580190174281597\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 101, loss: 0.06550188083201647\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 102, loss: 0.06520519778132439\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 103, loss: 0.0649118134751916\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 104, loss: 0.06462167669087648\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 105, loss: 0.06433472130447626\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 106, loss: 0.06405091751366854\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 107, loss: 0.06377020757645369\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 108, loss: 0.06349255610257387\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 109, loss: 0.06321791559457779\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 110, loss: 0.06294624507427216\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 111, loss: 0.06267749238759279\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 112, loss: 0.062411616556346416\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 113, loss: 0.062148586846888065\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 114, loss: 0.06188835669308901\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 115, loss: 0.06163087673485279\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 116, loss: 0.06137612368911505\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 117, loss: 0.061124046333134174\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 118, loss: 0.06087461672723293\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 119, loss: 0.060627794824540615\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 120, loss: 0.06038353778421879\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 121, loss: 0.06014180742204189\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 122, loss: 0.059902578592300415\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 123, loss: 0.05966581590473652\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 124, loss: 0.059431481175124645\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 125, loss: 0.05919953994452953\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 126, loss: 0.058969960547983646\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 127, loss: 0.058742702938616276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 128, loss: 0.058517745696008205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 129, loss: 0.058295054361224174\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 130, loss: 0.05807459633797407\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 131, loss: 0.05785634554922581\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 132, loss: 0.0576402647420764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 133, loss: 0.05742631945759058\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 134, loss: 0.057214497588574886\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 135, loss: 0.057004762813448906\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 136, loss: 0.056797086261212826\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 137, loss: 0.05659143906086683\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 138, loss: 0.05638779513537884\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 139, loss: 0.05618612468242645\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 140, loss: 0.055986412800848484\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 141, loss: 0.055788627825677395\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 142, loss: 0.055592737160623074\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 143, loss: 0.055398713797330856\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 144, loss: 0.055206541903316975\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 145, loss: 0.05501620192080736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 146, loss: 0.05482765752822161\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 147, loss: 0.05464089848101139\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 148, loss: 0.05445588659495115\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 149, loss: 0.05427259858697653\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 150, loss: 0.05409104283899069\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 151, loss: 0.05391116160899401\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 152, loss: 0.053732939064502716\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 153, loss: 0.05355636589229107\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 154, loss: 0.05338142067193985\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 155, loss: 0.05320806801319122\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 156, loss: 0.05303631071001291\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 157, loss: 0.05286610871553421\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 158, loss: 0.05269744712859392\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 159, loss: 0.05253030825406313\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 160, loss: 0.05236467253416777\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 161, loss: 0.052200522273778915\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 162, loss: 0.05203784350305796\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 163, loss: 0.051876612938940525\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 164, loss: 0.05171679239720106\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 165, loss: 0.05155839864164591\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 166, loss: 0.051401397213339806\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 167, loss: 0.051245780661702156\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 168, loss: 0.051091513596475124\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 169, loss: 0.05093859601765871\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 170, loss: 0.05078700091689825\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 171, loss: 0.050636718980968\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 172, loss: 0.050487727858126163\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 173, loss: 0.05034002009779215\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 174, loss: 0.05019357427954674\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 175, loss: 0.05004837829619646\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 176, loss: 0.04990440793335438\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 177, loss: 0.049761660397052765\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 178, loss: 0.049620126374065876\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 179, loss: 0.04947977606207132\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 180, loss: 0.049340590834617615\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 181, loss: 0.049202569760382175\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 182, loss: 0.04906570632010698\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 183, loss: 0.048929967917501926\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 184, loss: 0.04879535548388958\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 185, loss: 0.048661849461495876\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 186, loss: 0.04852943681180477\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 187, loss: 0.04839811194688082\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 188, loss: 0.04826784320175648\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 189, loss: 0.04813864268362522\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 190, loss: 0.04801047965884209\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 191, loss: 0.04788334760814905\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 192, loss: 0.047757252119481564\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 193, loss: 0.04763214290142059\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 194, loss: 0.04750803951174021\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 195, loss: 0.047384925186634064\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 196, loss: 0.04726278409361839\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 197, loss: 0.047141607850790024\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 198, loss: 0.047021377831697464\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 199, loss: 0.04690210148692131\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 200, loss: 0.04678374528884888\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 201, loss: 0.04666632320731878\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 202, loss: 0.04654979892075062\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 203, loss: 0.04643417801707983\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 204, loss: 0.0463194465264678\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 205, loss: 0.04620560351759195\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 206, loss: 0.04609262850135565\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 207, loss: 0.045980509370565414\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 208, loss: 0.045869240537285805\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 209, loss: 0.04575882386416197\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 210, loss: 0.04564923048019409\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 211, loss: 0.045540462248027325\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 212, loss: 0.04543252009898424\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 213, loss: 0.04532538075000048\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 214, loss: 0.04521902650594711\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 215, loss: 0.045113472267985344\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 216, loss: 0.04500869568437338\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 217, loss: 0.044904692098498344\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 218, loss: 0.044801450334489346\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 219, loss: 0.04469895921647549\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 220, loss: 0.04459723178297281\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 221, loss: 0.04449624102562666\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 222, loss: 0.04439597111195326\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 223, loss: 0.04429642856121063\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 224, loss: 0.044197602197527885\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 225, loss: 0.044099489226937294\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 226, loss: 0.04400207940489054\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 227, loss: 0.04390535969287157\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 228, loss: 0.043809330090880394\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 229, loss: 0.043713975697755814\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 230, loss: 0.043619297444820404\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 231, loss: 0.04352528788149357\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 232, loss: 0.04343193303793669\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 233, loss: 0.04333923105150461\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 234, loss: 0.04324718099087477\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 235, loss: 0.04315576143562794\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 236, loss: 0.04306497983634472\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 237, loss: 0.04297482315450907\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 238, loss: 0.04288528859615326\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 239, loss: 0.042796358466148376\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 240, loss: 0.04270804859697819\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 241, loss: 0.042620341293513775\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 242, loss: 0.0425332160666585\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 243, loss: 0.0424466896802187\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 244, loss: 0.042360748164355755\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 245, loss: 0.0422753831371665\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 246, loss: 0.04219059273600578\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 247, loss: 0.04210636671632528\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 248, loss: 0.042022692039608955\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 249, loss: 0.04193959292024374\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 250, loss: 0.04185703303664923\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 251, loss: 0.04177501844242215\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 252, loss: 0.041693541686981916\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 253, loss: 0.04161260277032852\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 254, loss: 0.04153218772262335\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 255, loss: 0.04145230399444699\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 256, loss: 0.041372934356331825\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 257, loss: 0.041294082533568144\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 258, loss: 0.04121573455631733\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 259, loss: 0.041137895081192255\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 260, loss: 0.04106055339798331\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 261, loss: 0.04098371183499694\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 262, loss: 0.04090735223144293\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 263, loss: 0.04083148157224059\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 264, loss: 0.04075608728453517\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 265, loss: 0.04068118240684271\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 266, loss: 0.040606741327792406\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 267, loss: 0.040532759856432676\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 268, loss: 0.04045924870297313\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 269, loss: 0.04038619948551059\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 270, loss: 0.040313603822141886\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 271, loss: 0.04024145798757672\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 272, loss: 0.04016975639387965\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 273, loss: 0.04009849717840552\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 274, loss: 0.04002768034115434\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 275, loss: 0.03995729424059391\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 276, loss: 0.03988733096048236\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 277, loss: 0.039817800745368004\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 278, loss: 0.03974869614467025\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 279, loss: 0.03968000737950206\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 280, loss: 0.03961173491552472\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 281, loss: 0.03954387456178665\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 282, loss: 0.03947641560807824\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 283, loss: 0.039409371092915535\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 284, loss: 0.03934271866455674\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 285, loss: 0.03927646717056632\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 286, loss: 0.03921060496941209\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 287, loss: 0.03914513764902949\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 288, loss: 0.03908004891127348\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 289, loss: 0.03901534341275692\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 290, loss: 0.038951019290834665\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 291, loss: 0.03888707747682929\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 292, loss: 0.03882350539788604\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 293, loss: 0.03876030305400491\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 294, loss: 0.038697462528944016\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 295, loss: 0.03863499080762267\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 296, loss: 0.03857287857681513\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 297, loss: 0.03851112024858594\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 298, loss: 0.03844972467049956\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 299, loss: 0.038388669956475496\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 300, loss: 0.03832796402275562\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 301, loss: 0.03826760919764638\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 302, loss: 0.038207588251680136\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 303, loss: 0.03814791748300195\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 304, loss: 0.038088574074208736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 305, loss: 0.038029569666832685\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 306, loss: 0.037970893550664186\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 307, loss: 0.0379125471226871\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 308, loss: 0.037854519207030535\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 309, loss: 0.03779682004824281\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 310, loss: 0.03773944126442075\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 311, loss: 0.03768237726762891\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 312, loss: 0.03762562479823828\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 313, loss: 0.03756918711587787\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 314, loss: 0.037513060960918665\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 315, loss: 0.03745723841711879\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 316, loss: 0.03740172041580081\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 317, loss: 0.03734650369733572\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 318, loss: 0.03729158826172352\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 319, loss: 0.037236970849335194\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 320, loss: 0.03718263749033213\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 321, loss: 0.037128609139472246\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 322, loss: 0.037074864376336336\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 323, loss: 0.03702141111716628\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 324, loss: 0.03696824749931693\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 325, loss: 0.03691535023972392\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 326, loss: 0.03686273982748389\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 327, loss: 0.03681041253730655\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 328, loss: 0.03675835905596614\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 329, loss: 0.03670659102499485\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 330, loss: 0.03665507910773158\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 331, loss: 0.03660383354872465\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 332, loss: 0.036552862264215946\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 333, loss: 0.0365021638572216\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 334, loss: 0.03645171783864498\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 335, loss: 0.03640153585001826\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 336, loss: 0.03635161183774471\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 337, loss: 0.0363019541837275\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 338, loss: 0.03625253261998296\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 339, loss: 0.03620337834581733\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 340, loss: 0.03615447273477912\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 341, loss: 0.03610582510009408\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 342, loss: 0.03605741122737527\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 343, loss: 0.03600924415513873\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 344, loss: 0.03596133226528764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 345, loss: 0.035913648549467325\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 346, loss: 0.035866211634129286\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 347, loss: 0.03581901406869292\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 348, loss: 0.03577204653993249\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 349, loss: 0.03572531929239631\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 350, loss: 0.03567882673814893\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 351, loss: 0.035632557701319456\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 352, loss: 0.035586520098149776\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 353, loss: 0.03554071066901088\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 354, loss: 0.035495124757289886\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 355, loss: 0.03544976795092225\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 356, loss: 0.035404632333666086\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 357, loss: 0.03535971185192466\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 358, loss: 0.03531502094119787\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 359, loss: 0.035270534455776215\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 360, loss: 0.03522627428174019\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 361, loss: 0.0351822292432189\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 362, loss: 0.035138389095664024\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 363, loss: 0.03509476128965616\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 364, loss: 0.035051342099905014\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 365, loss: 0.035008139442652464\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 366, loss: 0.03496513981372118\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 367, loss: 0.03492234135046601\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 368, loss: 0.034879753831773996\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 369, loss: 0.03483736468479037\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 370, loss: 0.034795175306499004\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 371, loss: 0.03475318010896444\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 372, loss: 0.03471139073371887\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 373, loss: 0.03466978529468179\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 374, loss: 0.03462839173153043\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 375, loss: 0.03458718489855528\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 376, loss: 0.034546170849353075\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 377, loss: 0.03450534725561738\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 378, loss: 0.03446471132338047\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 379, loss: 0.03442425839602947\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 380, loss: 0.03438400384038687\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 381, loss: 0.03434392949566245\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 382, loss: 0.03430403582751751\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 383, loss: 0.03426433261483908\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 384, loss: 0.03422480961307883\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 385, loss: 0.03418546263128519\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 386, loss: 0.03414629865437746\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 387, loss: 0.03410730138421059\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 388, loss: 0.03406849363818765\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 389, loss: 0.03402986330911517\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 390, loss: 0.03399140015244484\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 391, loss: 0.03395311301574111\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 392, loss: 0.0339149902574718\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 393, loss: 0.033877051435410976\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 394, loss: 0.033839276526123285\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 395, loss: 0.033801662735641\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 396, loss: 0.03376422356814146\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 397, loss: 0.033726945985108614\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 398, loss: 0.033689840231090784\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 399, loss: 0.033652896992862225\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 400, loss: 0.0336161064915359\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 401, loss: 0.03357949247583747\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 402, loss: 0.03354302607476711\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 403, loss: 0.03350673243403435\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 404, loss: 0.03347058640792966\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 405, loss: 0.03343460150063038\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 406, loss: 0.033398771192878485\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 407, loss: 0.03336309315636754\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 408, loss: 0.0333275836892426\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 409, loss: 0.033292213920503855\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 410, loss: 0.033257000148296356\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 411, loss: 0.03322193585336208\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 412, loss: 0.03318702708929777\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 413, loss: 0.033152259420603514\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 414, loss: 0.03311764355748892\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 415, loss: 0.03308317577466369\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 416, loss: 0.03304885886609554\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 417, loss: 0.03301468398422003\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 418, loss: 0.03298065345734358\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 419, loss: 0.03294675890356302\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 420, loss: 0.03291301289573312\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 421, loss: 0.03287940612062812\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 422, loss: 0.032845945097506046\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 423, loss: 0.03281262516975403\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 424, loss: 0.03277944028377533\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 425, loss: 0.032746394630521536\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 426, loss: 0.03271348541602492\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 427, loss: 0.03268071310594678\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 428, loss: 0.032648075837641954\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 429, loss: 0.032615565694868565\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 430, loss: 0.03258320689201355\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 431, loss: 0.03255097195506096\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 432, loss: 0.0325188678689301\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 433, loss: 0.03248689416795969\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 434, loss: 0.03245505224913359\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 435, loss: 0.03242333186790347\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 436, loss: 0.03239175630733371\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 437, loss: 0.03236030228435993\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 438, loss: 0.032328973058611155\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 439, loss: 0.03229777282103896\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 440, loss: 0.032266690861433744\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 441, loss: 0.03223573789000511\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 442, loss: 0.03220491111278534\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 443, loss: 0.03217421751469374\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 444, loss: 0.03214363427832723\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 445, loss: 0.03211316978558898\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 446, loss: 0.032082836143672466\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 447, loss: 0.032052609603852034\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 448, loss: 0.032022515311837196\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 449, loss: 0.03199254348874092\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 450, loss: 0.03196267271414399\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 451, loss: 0.031932932790368795\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 452, loss: 0.031903310213238\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 453, loss: 0.03187379287555814\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 454, loss: 0.03184439428150654\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 455, loss: 0.03181512653827667\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 456, loss: 0.03178595285862684\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 457, loss: 0.03175689605996013\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 458, loss: 0.03172795148566365\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 459, loss: 0.031699120067059994\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 460, loss: 0.031670402735471725\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 461, loss: 0.0316417939029634\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 462, loss: 0.03161329962313175\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 463, loss: 0.031584912445396185\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 464, loss: 0.031556631438434124\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 465, loss: 0.03152845427393913\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 466, loss: 0.03150039166212082\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 467, loss: 0.03147242916747928\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 468, loss: 0.03144458122551441\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 469, loss: 0.03141683153808117\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 470, loss: 0.031389194540679455\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 471, loss: 0.031361655332148075\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 472, loss: 0.031334221828728914\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 473, loss: 0.03130688751116395\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 474, loss: 0.03127965610474348\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 475, loss: 0.03125253412872553\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 476, loss: 0.031225506216287613\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 477, loss: 0.031198586337268353\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 478, loss: 0.031171759124845266\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 479, loss: 0.0311450376175344\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 480, loss: 0.031118406914174557\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 481, loss: 0.03109187399968505\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 482, loss: 0.0310654379427433\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 483, loss: 0.03103911131620407\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 484, loss: 0.031012877821922302\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 485, loss: 0.03098673839122057\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 486, loss: 0.030960698146373034\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 487, loss: 0.03093474032357335\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 488, loss: 0.030908887274563313\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 489, loss: 0.03088312642648816\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 490, loss: 0.03085746057331562\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 491, loss: 0.030831886921077967\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 492, loss: 0.030806404072791338\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 493, loss: 0.03078101295977831\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 494, loss: 0.030755713116377592\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 495, loss: 0.030730504542589188\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 496, loss: 0.030705392360687256\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 497, loss: 0.03068035375326872\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 498, loss: 0.030655425041913986\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 499, loss: 0.030630574095994234\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "total_time 6.150214910507202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZrEgNKFKy-_r",
        "outputId": "a3e6cabd-bcb0-4521-c65e-5f6e0c8cccc9"
      },
      "source": [
        "# p36_adagrad.py\n",
        "\n",
        "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
        "\n",
        "# 导入所需模块\n",
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time  ##1##\n",
        "\n",
        "# 导入数据，分别为输入特征和标签\n",
        "x_data = datasets.load_iris().data\n",
        "y_data = datasets.load_iris().target\n",
        "\n",
        "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
        "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
        "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
        "np.random.shuffle(x_data)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y_data)\n",
        "tf.random.set_seed(116)\n",
        "\n",
        "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
        "x_train = x_data[:-30]\n",
        "y_train = y_data[:-30]\n",
        "x_test = x_data[-30:]\n",
        "y_test = y_data[-30:]\n",
        "\n",
        "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "x_test = tf.cast(x_test, tf.float32)\n",
        "\n",
        "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
        "# 用tf.Variable()标记参数可训练\n",
        "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
        "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
        "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n",
        "\n",
        "lr = 0.1  # 学习率为0.1\n",
        "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
        "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
        "epoch = 500  # 循环500轮\n",
        "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
        "\n",
        "##########################################################################\n",
        "v_w, v_b = 0, 0\n",
        "##########################################################################\n",
        "\n",
        "# 训练部分\n",
        "now_time = time.time()  ##2##\n",
        "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
        "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
        "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
        "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
        "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
        "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
        "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
        "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
        "        # 计算loss对各个参数的梯度\n",
        "        grads = tape.gradient(loss, [w1, b1])\n",
        "\n",
        "        ##########################################################################\n",
        "        # adagrad\n",
        "        v_w += tf.square(grads[0])\n",
        "        v_b += tf.square(grads[1])\n",
        "        w1.assign_sub(lr * grads[0] / tf.sqrt(v_w))\n",
        "        b1.assign_sub(lr * grads[1] / tf.sqrt(v_b))\n",
        "    ##########################################################################\n",
        "\n",
        "    # 每个epoch，打印loss信息\n",
        "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
        "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
        "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
        "\n",
        "    # 测试部分\n",
        "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
        "    total_correct, total_number = 0, 0\n",
        "    for x_test, y_test in test_db:\n",
        "        # 使用更新后的参数进行预测\n",
        "        y = tf.matmul(x_test, w1) + b1\n",
        "        y = tf.nn.softmax(y)\n",
        "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
        "        # 将pred转换为y_test的数据类型\n",
        "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
        "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
        "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
        "        # 将每个batch的correct数加起来\n",
        "        correct = tf.reduce_sum(correct)\n",
        "        # 将所有batch中的correct数加起来\n",
        "        total_correct += int(correct)\n",
        "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
        "        total_number += x_test.shape[0]\n",
        "    # 总的准确率等于total_correct/total_number\n",
        "    acc = total_correct / total_number\n",
        "    test_acc.append(acc)\n",
        "    print(\"Test_acc:\", acc)\n",
        "    print(\"--------------------------\")\n",
        "total_time = time.time() - now_time  ##3##\n",
        "print(\"total_time\", total_time)  ##4##\n",
        "\n",
        "# 绘制 loss 曲线\n",
        "plt.title('Loss Function Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Loss')  # y轴变量名称\n",
        "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
        "plt.legend()  # 画出曲线图标\n",
        "plt.show()  # 画出图像\n",
        "\n",
        "# 绘制 Accuracy 曲线\n",
        "plt.title('Acc Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Acc')  # y轴变量名称\n",
        "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 请将loss曲线、ACC曲线、total_time记录到 class2\\优化器对比.docx  对比各优化器收敛情况"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 0.2528788596391678\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 1, loss: 0.17821525782346725\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 2, loss: 0.15621443092823029\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 3, loss: 0.1420477293431759\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 4, loss: 0.13362513855099678\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 5, loss: 0.12754760682582855\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 6, loss: 0.12286805920302868\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 7, loss: 0.11908590793609619\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 8, loss: 0.1159136202186346\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 9, loss: 0.11317718215286732\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 10, loss: 0.11076570861041546\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 11, loss: 0.10860516130924225\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 12, loss: 0.10664406046271324\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 13, loss: 0.1048453338444233\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 14, loss: 0.10318147018551826\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 15, loss: 0.10163156874477863\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 16, loss: 0.10017936117947102\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 17, loss: 0.09881195984780788\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 18, loss: 0.09751898422837257\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 19, loss: 0.09629195556044579\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 20, loss: 0.09512384794652462\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 21, loss: 0.09400876797735691\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 22, loss: 0.09294173680245876\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 23, loss: 0.09191850572824478\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 24, loss: 0.09093539416790009\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 25, loss: 0.08998922444880009\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 26, loss: 0.08907719701528549\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 27, loss: 0.0881968792527914\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 28, loss: 0.08734606951475143\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 29, loss: 0.08652284555137157\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 30, loss: 0.08572547510266304\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 31, loss: 0.08495240099728107\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 32, loss: 0.08420219831168652\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 33, loss: 0.08347360789775848\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 34, loss: 0.08276545442640781\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 35, loss: 0.082076670601964\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 36, loss: 0.08140628598630428\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 37, loss: 0.08075340464711189\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 38, loss: 0.08011719025671482\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 39, loss: 0.07949688658118248\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 40, loss: 0.07889176905155182\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 41, loss: 0.07830119132995605\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 42, loss: 0.0777245257049799\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 43, loss: 0.07716120406985283\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 44, loss: 0.07661068439483643\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 45, loss: 0.07607246562838554\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 46, loss: 0.07554607093334198\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 47, loss: 0.0750310504809022\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 48, loss: 0.07452699355781078\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 49, loss: 0.07403350155800581\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 50, loss: 0.07355019170790911\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 51, loss: 0.07307672034949064\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 52, loss: 0.07261274103075266\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 53, loss: 0.07215795014053583\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 54, loss: 0.07171202544122934\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 55, loss: 0.07127469498664141\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 56, loss: 0.07084567844867706\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 57, loss: 0.07042471133172512\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 58, loss: 0.07001155614852905\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 59, loss: 0.06960596796125174\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 60, loss: 0.06920771952718496\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 61, loss: 0.068816595710814\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 62, loss: 0.0684323888272047\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 63, loss: 0.06805489957332611\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 64, loss: 0.06768393702805042\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 65, loss: 0.06731931213289499\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 66, loss: 0.06696086283773184\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 67, loss: 0.06660841312259436\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 68, loss: 0.06626180279999971\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 69, loss: 0.06592087727040052\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 70, loss: 0.0655854819342494\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 71, loss: 0.06525547802448273\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 72, loss: 0.06493072677403688\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 73, loss: 0.06461109686642885\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 74, loss: 0.06429645232856274\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 75, loss: 0.06398667860776186\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 76, loss: 0.0636816406622529\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 77, loss: 0.06338123697787523\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 78, loss: 0.06308535020798445\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 79, loss: 0.06279388163238764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 80, loss: 0.0625067101791501\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 81, loss: 0.062223742716014385\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 82, loss: 0.06194488797336817\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 83, loss: 0.06167005002498627\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 84, loss: 0.06139912363141775\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 85, loss: 0.0611320361495018\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 86, loss: 0.06086869444698095\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 87, loss: 0.06060901936143637\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 88, loss: 0.0603529280051589\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 89, loss: 0.06010034121572971\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 90, loss: 0.05985118541866541\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 91, loss: 0.059605387039482594\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 92, loss: 0.05936287622898817\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 93, loss: 0.05912358406931162\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 94, loss: 0.05888743884861469\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 95, loss: 0.05865438003093004\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 96, loss: 0.058424340561032295\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 97, loss: 0.058197264559566975\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 98, loss: 0.05797308776527643\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 99, loss: 0.05775175150483847\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 100, loss: 0.057533202692866325\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 101, loss: 0.05731738545000553\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 102, loss: 0.05710424482822418\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 103, loss: 0.05689372029155493\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 104, loss: 0.056685772724449635\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 105, loss: 0.05648035276681185\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 106, loss: 0.05627741012722254\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 107, loss: 0.056076896376907825\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 108, loss: 0.055878765881061554\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 109, loss: 0.05568297579884529\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 110, loss: 0.055489485152065754\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 111, loss: 0.055298241786658764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 112, loss: 0.055109220556914806\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 113, loss: 0.05492236837744713\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 114, loss: 0.05473764520138502\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 115, loss: 0.05455502960830927\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 116, loss: 0.05437446478754282\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 117, loss: 0.054195922799408436\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 118, loss: 0.05401937384158373\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 119, loss: 0.05384476762264967\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 120, loss: 0.053672087378799915\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 121, loss: 0.053501288406550884\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 122, loss: 0.05333233904093504\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 123, loss: 0.05316521879285574\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 124, loss: 0.05299988575279713\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 125, loss: 0.05283631384372711\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 126, loss: 0.05267447419464588\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 127, loss: 0.05251433979719877\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 128, loss: 0.052355872467160225\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 129, loss: 0.052199059166014194\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 130, loss: 0.052043866366147995\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 131, loss: 0.051890263333916664\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 132, loss: 0.051738232374191284\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 133, loss: 0.051587751135230064\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 134, loss: 0.05143878050148487\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 135, loss: 0.05129131209105253\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 136, loss: 0.05114530958235264\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 137, loss: 0.05100075528025627\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 138, loss: 0.05085762869566679\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 139, loss: 0.0507159074768424\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 140, loss: 0.05057556554675102\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 141, loss: 0.050436592660844326\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 142, loss: 0.05029895715415478\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 143, loss: 0.05016263388097286\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 144, loss: 0.05002762656658888\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 145, loss: 0.04989389330148697\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 146, loss: 0.04976142197847366\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 147, loss: 0.04963019210845232\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 148, loss: 0.049500186927616596\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 149, loss: 0.04937139339745045\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 150, loss: 0.04924378823488951\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 151, loss: 0.04911735374480486\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 152, loss: 0.048992074094712734\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 153, loss: 0.04886793624609709\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 154, loss: 0.04874492064118385\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 155, loss: 0.04862301144748926\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 156, loss: 0.04850219190120697\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 157, loss: 0.04838245548307896\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 158, loss: 0.04826377797871828\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 159, loss: 0.04814614076167345\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 160, loss: 0.04802953824400902\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 161, loss: 0.04791395366191864\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 162, loss: 0.04779937490820885\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 163, loss: 0.04768578428775072\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 164, loss: 0.04757317155599594\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 165, loss: 0.04746152088046074\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 166, loss: 0.04735081922262907\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 167, loss: 0.04724105913192034\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 168, loss: 0.047132221050560474\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 169, loss: 0.04702429939061403\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 170, loss: 0.04691727552562952\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 171, loss: 0.046811146661639214\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 172, loss: 0.04670589044690132\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 173, loss: 0.04660149943083525\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 174, loss: 0.04649797081947327\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 175, loss: 0.04639527574181557\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 176, loss: 0.046293421648442745\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 177, loss: 0.04619238618761301\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 178, loss: 0.04609217122197151\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 179, loss: 0.045992753468453884\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 180, loss: 0.045894126407802105\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 181, loss: 0.04579627700150013\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 182, loss: 0.04569920524954796\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 183, loss: 0.04560289904475212\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 184, loss: 0.045507344417274\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 185, loss: 0.04541252553462982\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 186, loss: 0.04531844984740019\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 187, loss: 0.04522509966045618\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 188, loss: 0.0451324675232172\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 189, loss: 0.04504053946584463\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 190, loss: 0.04494931362569332\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 191, loss: 0.044858780689537525\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 192, loss: 0.0447689238935709\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 193, loss: 0.04467975161969662\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 194, loss: 0.04459124431014061\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 195, loss: 0.04450339172035456\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 196, loss: 0.044416194781661034\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 197, loss: 0.04432963766157627\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 198, loss: 0.04424372222274542\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 199, loss: 0.04415843263268471\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 200, loss: 0.04407376516610384\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 201, loss: 0.04398971702903509\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 202, loss: 0.043906270526349545\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 203, loss: 0.043823426589369774\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 204, loss: 0.04374117683619261\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 205, loss: 0.04365951381623745\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 206, loss: 0.0435784375295043\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 207, loss: 0.04349792655557394\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 208, loss: 0.04341799486428499\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 209, loss: 0.04333861265331507\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 210, loss: 0.04325978923588991\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 211, loss: 0.0431815180927515\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 212, loss: 0.04310378897935152\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 213, loss: 0.04302659630775452\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 214, loss: 0.04294993635267019\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 215, loss: 0.04287380166351795\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 216, loss: 0.04279818665236235\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 217, loss: 0.042723084799945354\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 218, loss: 0.04264849051833153\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 219, loss: 0.04257440194487572\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 220, loss: 0.042500811628997326\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 221, loss: 0.042427715845406055\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 222, loss: 0.042355106212198734\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 223, loss: 0.042282973416149616\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 224, loss: 0.04221132583916187\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 225, loss: 0.04214014671742916\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 226, loss: 0.04206943418830633\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 227, loss: 0.041999186389148235\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 228, loss: 0.04192939214408398\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 229, loss: 0.041860053315758705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 230, loss: 0.0417911596596241\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 231, loss: 0.04172271862626076\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 232, loss: 0.04165470786392689\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 233, loss: 0.041587140411138535\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 234, loss: 0.041519997641444206\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 235, loss: 0.04145328514277935\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 236, loss: 0.04138698987662792\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 237, loss: 0.04132111184298992\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 238, loss: 0.0412556529045105\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 239, loss: 0.04119059722870588\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 240, loss: 0.041125948540866375\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 241, loss: 0.041061703115701675\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 242, loss: 0.04099785536527634\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 243, loss: 0.04093439970165491\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 244, loss: 0.04087133426219225\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 245, loss: 0.04080865625292063\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 246, loss: 0.04074635449796915\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 247, loss: 0.04068443924188614\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 248, loss: 0.04062290024012327\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 249, loss: 0.040561722591519356\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 250, loss: 0.04050091467797756\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 251, loss: 0.040440475568175316\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 252, loss: 0.04038039781153202\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 253, loss: 0.040320673026144505\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 254, loss: 0.040261304937303066\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 255, loss: 0.04020228190347552\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 256, loss: 0.04014361696317792\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 257, loss: 0.0400852900929749\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 258, loss: 0.04002729756757617\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 259, loss: 0.03996965242549777\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 260, loss: 0.03991234162822366\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 261, loss: 0.03985535493120551\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 262, loss: 0.03979870257899165\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 263, loss: 0.03974237898364663\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 264, loss: 0.03968636831268668\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 265, loss: 0.039630684070289135\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 266, loss: 0.03957531647756696\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 267, loss: 0.03952026041224599\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 268, loss: 0.039465518202632666\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 269, loss: 0.039411081466823816\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 270, loss: 0.039356951136142015\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 271, loss: 0.03930312441661954\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 272, loss: 0.039249598514288664\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 273, loss: 0.03919636458158493\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 274, loss: 0.0391434314660728\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 275, loss: 0.039090790785849094\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 276, loss: 0.03903843881562352\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 277, loss: 0.038986371364444494\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 278, loss: 0.038934593088924885\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 279, loss: 0.038883095141500235\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 280, loss: 0.03883187286555767\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 281, loss: 0.03878093184903264\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 282, loss: 0.03873026603832841\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 283, loss: 0.038679874036461115\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 284, loss: 0.038629746064543724\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 285, loss: 0.03857989190146327\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 286, loss: 0.03853029711171985\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 287, loss: 0.03848097426816821\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 288, loss: 0.03843191033229232\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 289, loss: 0.03838310344144702\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 290, loss: 0.038334555458277464\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 291, loss: 0.03828625939786434\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 292, loss: 0.03823821572586894\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 293, loss: 0.03819042583927512\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 294, loss: 0.0381428780965507\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 295, loss: 0.03809558367356658\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 296, loss: 0.03804853046312928\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 297, loss: 0.038001717533916235\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 298, loss: 0.037955152336508036\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 299, loss: 0.03790882136672735\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 300, loss: 0.03786272322759032\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 301, loss: 0.03781686397269368\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 302, loss: 0.037771235685795546\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 303, loss: 0.037725839763879776\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 304, loss: 0.03768067108467221\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 305, loss: 0.03763573104515672\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 306, loss: 0.037591015454381704\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 307, loss: 0.03754652151837945\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 308, loss: 0.03750225203111768\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 309, loss: 0.03745819814503193\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 310, loss: 0.03741436870768666\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 311, loss: 0.03737074928358197\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 312, loss: 0.037327347323298454\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 313, loss: 0.03728415863588452\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 314, loss: 0.037241182290017605\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 315, loss: 0.03719841269776225\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 316, loss: 0.03715585498139262\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 317, loss: 0.037113499362021685\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 318, loss: 0.037071353290230036\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 319, loss: 0.03702941071242094\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 320, loss: 0.036987670697271824\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 321, loss: 0.036946123000234365\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 322, loss: 0.03690478065982461\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 323, loss: 0.0368636348284781\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 324, loss: 0.03682268550619483\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 325, loss: 0.03678192803636193\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 326, loss: 0.03674136148765683\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 327, loss: 0.0367009905166924\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 328, loss: 0.03666080255061388\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 329, loss: 0.03662081062793732\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 330, loss: 0.036580999847501516\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 331, loss: 0.03654138371348381\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 332, loss: 0.036501944065093994\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 333, loss: 0.03646268928423524\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 334, loss: 0.03642361657693982\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 335, loss: 0.036384725011885166\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 336, loss: 0.036346007604151964\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 337, loss: 0.03630747413262725\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 338, loss: 0.03626911249011755\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 339, loss: 0.036230925004929304\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 340, loss: 0.03619291307404637\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 341, loss: 0.036155075300484896\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 342, loss: 0.03611740516498685\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 343, loss: 0.03607990499585867\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 344, loss: 0.03604257758706808\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 345, loss: 0.03600541828200221\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 346, loss: 0.03596841776743531\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 347, loss: 0.03593158721923828\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 348, loss: 0.03589492104947567\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 349, loss: 0.03585842018947005\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 350, loss: 0.035822069738060236\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 351, loss: 0.0357858925126493\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 352, loss: 0.03574986895546317\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 353, loss: 0.03571400558575988\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 354, loss: 0.03567830054089427\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 355, loss: 0.0356427445076406\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 356, loss: 0.03560735331848264\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 357, loss: 0.03557210694998503\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 358, loss: 0.03553701704367995\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 359, loss: 0.035502079874277115\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 360, loss: 0.03546729264780879\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 361, loss: 0.03543265722692013\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 362, loss: 0.035398163832724094\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 363, loss: 0.03536382457241416\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 364, loss: 0.035329627338796854\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 365, loss: 0.03529558191075921\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 366, loss: 0.03526167897507548\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 367, loss: 0.035227912943810225\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 368, loss: 0.03519429778680205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 369, loss: 0.035160819068551064\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 370, loss: 0.035127483773976564\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 371, loss: 0.03509428910911083\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 372, loss: 0.035061230417340994\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 373, loss: 0.03502831142395735\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 374, loss: 0.03499552933499217\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 375, loss: 0.0349628790281713\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 376, loss: 0.0349303730763495\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 377, loss: 0.03489799238741398\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 378, loss: 0.034865750931203365\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 379, loss: 0.034833642188459635\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 380, loss: 0.03480165870860219\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 381, loss: 0.03476980933919549\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 382, loss: 0.03473809827119112\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 383, loss: 0.03470650315284729\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 384, loss: 0.03467504121363163\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 385, loss: 0.034643704537302256\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 386, loss: 0.0346125029027462\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 387, loss: 0.03458141861483455\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 388, loss: 0.0345504623837769\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 389, loss: 0.034519626293331385\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 390, loss: 0.03448891593143344\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 391, loss: 0.03445833222940564\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 392, loss: 0.03442787053063512\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 393, loss: 0.0343975224532187\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 394, loss: 0.03436729405075312\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 395, loss: 0.034337193705141544\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 396, loss: 0.034307206980884075\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 397, loss: 0.03427733946591616\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 398, loss: 0.03424758790060878\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 399, loss: 0.03421795507892966\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 400, loss: 0.0341884340159595\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 401, loss: 0.034159034956246614\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 402, loss: 0.03412974579259753\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 403, loss: 0.03410056699067354\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 404, loss: 0.034071503672748804\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 405, loss: 0.03404255444183946\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 406, loss: 0.0340137192979455\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 407, loss: 0.03398498985916376\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 408, loss: 0.03395637357607484\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 409, loss: 0.03392786206677556\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 410, loss: 0.033899462316185236\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 411, loss: 0.03387116873636842\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 412, loss: 0.03384298365563154\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 413, loss: 0.033814909402281046\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 414, loss: 0.03378693386912346\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 415, loss: 0.03375907288864255\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 416, loss: 0.033731311559677124\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 417, loss: 0.03370365034788847\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 418, loss: 0.03367610089480877\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 419, loss: 0.03364864643663168\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 420, loss: 0.03362130047753453\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 421, loss: 0.033594051375985146\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 422, loss: 0.03356690797954798\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 423, loss: 0.03353986144065857\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 424, loss: 0.033512921538203955\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 425, loss: 0.03348607337102294\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 426, loss: 0.03345932997763157\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 427, loss: 0.0334326783195138\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 428, loss: 0.03340613003820181\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 429, loss: 0.03337967535480857\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 430, loss: 0.033353318460285664\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 431, loss: 0.033327057026326656\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 432, loss: 0.0333008891902864\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 433, loss: 0.03327482286840677\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 434, loss: 0.033248838968575\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 435, loss: 0.03322295751422644\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 436, loss: 0.033197167329490185\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 437, loss: 0.03317146981135011\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 438, loss: 0.03314586030319333\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 439, loss: 0.03312034858390689\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 440, loss: 0.03309492999687791\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 441, loss: 0.03306959383189678\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 442, loss: 0.03304435219615698\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 443, loss: 0.03301919577643275\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 444, loss: 0.03299413435161114\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 445, loss: 0.03296915953978896\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 446, loss: 0.032944268081337214\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 447, loss: 0.03291946882382035\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 448, loss: 0.03289475850760937\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 449, loss: 0.0328701282851398\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 450, loss: 0.03284558979794383\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 451, loss: 0.03282113326713443\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 452, loss: 0.03279676102101803\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 453, loss: 0.03277247445657849\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 454, loss: 0.032748271245509386\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 455, loss: 0.03272415604442358\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 456, loss: 0.032700121868401766\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 457, loss: 0.03267616266384721\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 458, loss: 0.03265229566022754\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 459, loss: 0.03262850875034928\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 460, loss: 0.03260479960590601\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 461, loss: 0.03258117102086544\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 462, loss: 0.032557628117501736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 463, loss: 0.03253416018560529\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 464, loss: 0.032510776072740555\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 465, loss: 0.032487462274730206\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 466, loss: 0.032464233227074146\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 467, loss: 0.032441085670143366\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 468, loss: 0.03241801355034113\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 469, loss: 0.032395017333328724\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 470, loss: 0.032372099347412586\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 471, loss: 0.03234925540164113\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 472, loss: 0.03232648782432079\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 473, loss: 0.03230379894375801\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 474, loss: 0.032281185034662485\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 475, loss: 0.03225864749401808\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 476, loss: 0.03223618119955063\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 477, loss: 0.03221378801390529\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 478, loss: 0.03219147119671106\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 479, loss: 0.03216922655701637\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 480, loss: 0.032147055957466364\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 481, loss: 0.03212495893239975\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 482, loss: 0.032102929428219795\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 483, loss: 0.03208097815513611\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 484, loss: 0.032059093937277794\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 485, loss: 0.03203728049993515\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 486, loss: 0.032015540171414614\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 487, loss: 0.031993867829442024\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 488, loss: 0.031972269993275404\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 489, loss: 0.031950735952705145\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 490, loss: 0.03192927269265056\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 491, loss: 0.0319078816100955\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 492, loss: 0.031886558048427105\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 493, loss: 0.03186529967933893\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 494, loss: 0.03184410836547613\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 495, loss: 0.031822989229112864\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 496, loss: 0.03180193621665239\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 497, loss: 0.031780948862433434\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 498, loss: 0.03176002483814955\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 499, loss: 0.031739167869091034\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "total_time 6.076268434524536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FaggJTB_zZc1",
        "outputId": "292e6cb1-b716-4fa2-9338-0a5f8f247759"
      },
      "source": [
        "# p38_rmsprop.py\n",
        "\n",
        "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
        "\n",
        "# 导入所需模块\n",
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time  ##1##\n",
        "\n",
        "# 导入数据，分别为输入特征和标签\n",
        "x_data = datasets.load_iris().data\n",
        "y_data = datasets.load_iris().target\n",
        "\n",
        "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
        "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
        "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
        "np.random.shuffle(x_data)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y_data)\n",
        "tf.random.set_seed(116)\n",
        "\n",
        "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
        "x_train = x_data[:-30]\n",
        "y_train = y_data[:-30]\n",
        "x_test = x_data[-30:]\n",
        "y_test = y_data[-30:]\n",
        "\n",
        "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "x_test = tf.cast(x_test, tf.float32)\n",
        "\n",
        "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
        "# 用tf.Variable()标记参数可训练\n",
        "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
        "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
        "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n",
        "\n",
        "lr = 0.1  # 学习率为0.1\n",
        "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
        "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
        "epoch = 500  # 循环500轮\n",
        "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
        "\n",
        "##########################################################################\n",
        "v_w, v_b = 0, 0\n",
        "beta = 0.9\n",
        "##########################################################################\n",
        "\n",
        "# 训练部分\n",
        "now_time = time.time()  ##2##\n",
        "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
        "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
        "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
        "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
        "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
        "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
        "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
        "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
        "        # 计算loss对各个参数的梯度\n",
        "        grads = tape.gradient(loss, [w1, b1])\n",
        "\n",
        "        ##########################################################################\n",
        "        # rmsprop\n",
        "        v_w = beta * v_w + (1 - beta) * tf.square(grads[0])\n",
        "        v_b = beta * v_b + (1 - beta) * tf.square(grads[1])\n",
        "        w1.assign_sub(lr * grads[0] / tf.sqrt(v_w))\n",
        "        b1.assign_sub(lr * grads[1] / tf.sqrt(v_b))\n",
        "    ##########################################################################\n",
        "\n",
        "    # 每个epoch，打印loss信息\n",
        "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
        "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
        "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
        "\n",
        "    # 测试部分\n",
        "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
        "    total_correct, total_number = 0, 0\n",
        "    for x_test, y_test in test_db:\n",
        "        # 使用更新后的参数进行预测\n",
        "        y = tf.matmul(x_test, w1) + b1\n",
        "        y = tf.nn.softmax(y)\n",
        "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
        "        # 将pred转换为y_test的数据类型\n",
        "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
        "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
        "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
        "        # 将每个batch的correct数加起来\n",
        "        correct = tf.reduce_sum(correct)\n",
        "        # 将所有batch中的correct数加起来\n",
        "        total_correct += int(correct)\n",
        "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
        "        total_number += x_test.shape[0]\n",
        "    # 总的准确率等于total_correct/total_number\n",
        "    acc = total_correct / total_number\n",
        "    test_acc.append(acc)\n",
        "    print(\"Test_acc:\", acc)\n",
        "    print(\"--------------------------\")\n",
        "total_time = time.time() - now_time  ##3##\n",
        "print(\"total_time\", total_time)  ##4##\n",
        "\n",
        "# 绘制 loss 曲线\n",
        "plt.title('Loss Function Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Loss')  # y轴变量名称\n",
        "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
        "plt.legend()  # 画出曲线图标\n",
        "plt.show()  # 画出图像\n",
        "\n",
        "# 绘制 Accuracy 曲线\n",
        "plt.title('Acc Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Acc')  # y轴变量名称\n",
        "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 请将loss曲线、ACC曲线、total_time记录到 class2\\优化器对比.docx  对比各优化器收敛情况"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 0.392601415514946\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 1, loss: 0.20467259176075459\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 2, loss: 0.17201907187700272\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 3, loss: 0.15918354131281376\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 4, loss: 0.15706952288746834\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 5, loss: 0.21631581708788872\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 6, loss: 0.14704442024230957\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 7, loss: 0.18439018353819847\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 8, loss: 0.13945917785167694\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 9, loss: 0.19464711099863052\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 10, loss: 0.17245551943778992\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 11, loss: 0.1566553208976984\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 12, loss: 0.17631667666137218\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 13, loss: 0.18123364821076393\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 14, loss: 0.1651042178273201\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 15, loss: 0.15545541420578957\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 16, loss: 0.13856995198875666\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 17, loss: 0.14923829212784767\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 18, loss: 0.17947611957788467\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 19, loss: 0.15877642668783665\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 20, loss: 0.163470976985991\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 21, loss: 0.09798431489616632\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 22, loss: 0.1356021100655198\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 23, loss: 0.17630531266331673\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 24, loss: 0.12512844149023294\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 25, loss: 0.17260492220520973\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 26, loss: 0.11726886127144098\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 27, loss: 0.12418998405337334\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 28, loss: 0.11339506320655346\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 29, loss: 0.10823221690952778\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 30, loss: 0.10021131113171577\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 31, loss: 0.0972977876663208\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 32, loss: 0.0684580160304904\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 33, loss: 0.07624228857457638\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 34, loss: 0.09842338878661394\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 35, loss: 0.13617543317377567\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 36, loss: 0.133752703666687\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 37, loss: 0.11338153388351202\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 38, loss: 0.08611440192908049\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 39, loss: 0.09435220342129469\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 40, loss: 0.08705766825005412\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 41, loss: 0.08437714679166675\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 42, loss: 0.08447429304942489\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 43, loss: 0.09062403533607721\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 44, loss: 0.0715167485177517\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 45, loss: 0.06954420218244195\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 46, loss: 0.06465024966746569\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 47, loss: 0.07228156132623553\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 48, loss: 0.07577539002522826\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 49, loss: 0.08712489251047373\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 50, loss: 0.054731579730287194\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 51, loss: 0.08698647562414408\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 52, loss: 0.05977427726611495\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 53, loss: 0.07003174675628543\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 54, loss: 0.052806438179686666\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 55, loss: 0.08014782425016165\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 56, loss: 0.05249739531427622\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 57, loss: 0.07553031761199236\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 58, loss: 0.05050932359881699\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 59, loss: 0.07542205043137074\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 60, loss: 0.04919805680401623\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 61, loss: 0.07369921542704105\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 62, loss: 0.04798313626088202\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 63, loss: 0.07184229418635368\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 64, loss: 0.04696501977741718\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 65, loss: 0.07005912065505981\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 66, loss: 0.0461419050116092\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 67, loss: 0.0680556371808052\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 68, loss: 0.045491571770980954\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 69, loss: 0.06599770300090313\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 70, loss: 0.04499787651002407\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 71, loss: 0.0639898469671607\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 72, loss: 0.044655751902610064\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 73, loss: 0.06202745158225298\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 74, loss: 0.04447570024058223\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 75, loss: 0.06005757488310337\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 76, loss: 0.04448384325951338\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 77, loss: 0.05801852233707905\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 78, loss: 0.04471643874421716\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 79, loss: 0.055855317041277885\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 80, loss: 0.04520490067079663\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 81, loss: 0.053544122725725174\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 82, loss: 0.04592406004667282\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 83, loss: 0.05115509033203125\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 84, loss: 0.04665278922766447\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 85, loss: 0.04892720328643918\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 86, loss: 0.04686511913314462\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 87, loss: 0.047134753316640854\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 88, loss: 0.046228577848523855\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 89, loss: 0.04576328117400408\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 90, loss: 0.045170440804213285\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 91, loss: 0.044651339296251535\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 92, loss: 0.04416694864630699\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 93, loss: 0.04371932381764054\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 94, loss: 0.043300313875079155\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 95, loss: 0.04290229268372059\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 96, loss: 0.04252018081024289\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 97, loss: 0.04215051047503948\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 98, loss: 0.04179124487563968\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 99, loss: 0.04144103592261672\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 100, loss: 0.04109902726486325\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 101, loss: 0.040764577221125364\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 102, loss: 0.040437199641019106\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 103, loss: 0.04011652898043394\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 104, loss: 0.039802216459065676\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 105, loss: 0.039494012482464314\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 106, loss: 0.03919157199561596\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 107, loss: 0.03889477252960205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 108, loss: 0.038603415712714195\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 109, loss: 0.03831732552498579\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 110, loss: 0.03803628636524081\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 111, loss: 0.03776018274948001\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 112, loss: 0.03748884843662381\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 113, loss: 0.03722222801297903\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 114, loss: 0.03696009935811162\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 115, loss: 0.03670242568477988\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 116, loss: 0.03644912363961339\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 117, loss: 0.03620001068338752\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 118, loss: 0.03595502162352204\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 119, loss: 0.03571410896256566\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 120, loss: 0.03547710692510009\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 121, loss: 0.035243996884673834\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 122, loss: 0.0350146871060133\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 123, loss: 0.03478908049874008\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 124, loss: 0.0345671393442899\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 125, loss: 0.03434880939312279\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 126, loss: 0.034133984008803964\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 127, loss: 0.03392253955826163\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 128, loss: 0.033714519115164876\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 129, loss: 0.03350984794087708\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 130, loss: 0.033308490412309766\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 131, loss: 0.033110294956713915\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 132, loss: 0.03291531256400049\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 133, loss: 0.03272347757592797\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 134, loss: 0.032534707337617874\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 135, loss: 0.03234899486415088\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 136, loss: 0.03216626518405974\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 137, loss: 0.031986515736207366\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 138, loss: 0.03180971019901335\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 139, loss: 0.03163582202978432\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 140, loss: 0.031464752508327365\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 141, loss: 0.03129656962119043\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 142, loss: 0.031131235416978598\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 143, loss: 0.0309686369728297\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 144, loss: 0.030808869982138276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 145, loss: 0.03065178613178432\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 146, loss: 0.030497561441734433\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 147, loss: 0.030346029438078403\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 148, loss: 0.030197230400517583\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 149, loss: 0.030051174107939005\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 150, loss: 0.029907820047810674\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 151, loss: 0.029767235973849893\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 152, loss: 0.029629406053572893\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 153, loss: 0.02949432749301195\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 154, loss: 0.0293619844596833\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 155, loss: 0.029232527129352093\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 156, loss: 0.029105844208970666\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 157, loss: 0.02898205886594951\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 158, loss: 0.028861158061772585\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 159, loss: 0.028743270551785827\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 160, loss: 0.028628427302464843\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 161, loss: 0.02851664717309177\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 162, loss: 0.028408090816810727\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 163, loss: 0.028302802937105298\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 164, loss: 0.028200915781781077\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 165, loss: 0.028102550422772765\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 166, loss: 0.028007831424474716\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 167, loss: 0.02791693154722452\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 168, loss: 0.027830085484310985\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 169, loss: 0.027747426414862275\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 170, loss: 0.0276692365296185\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 171, loss: 0.027595763094723225\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 172, loss: 0.027527339523658156\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 173, loss: 0.02746432926505804\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 174, loss: 0.027407054090872407\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 175, loss: 0.02735601714812219\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 176, loss: 0.027311688754707575\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 177, loss: 0.0272747203707695\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 178, loss: 0.027245644945651293\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 179, loss: 0.027225209749303758\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 180, loss: 0.027214192668907344\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 181, loss: 0.02721342269796878\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 182, loss: 0.02722374547738582\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 183, loss: 0.027246166137047112\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 184, loss: 0.02728162577841431\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 185, loss: 0.02733091393020004\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 186, loss: 0.027394826873205602\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 187, loss: 0.02747390780132264\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 188, loss: 0.027568216435611248\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 189, loss: 0.02767743158619851\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 190, loss: 0.027800431358627975\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 191, loss: 0.02793521829880774\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 192, loss: 0.02807902346830815\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 193, loss: 0.028228063136339188\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 194, loss: 0.028377993032336235\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 195, loss: 0.028524130932055414\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 196, loss: 0.028662171331234276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 197, loss: 0.028788481664378196\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 198, loss: 0.02890063897939399\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 199, loss: 0.028997684770729393\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 200, loss: 0.02907972363755107\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 201, loss: 0.029148022702429444\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 202, loss: 0.02920412231469527\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 203, loss: 0.02925002557458356\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 204, loss: 0.02928752574371174\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 205, loss: 0.029318205488380045\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 206, loss: 0.02934343443484977\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 207, loss: 0.029364290356170386\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 208, loss: 0.029381530068349093\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 209, loss: 0.029395786521490663\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 210, loss: 0.029407576541416347\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 211, loss: 0.02941722032846883\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 212, loss: 0.02942499896744266\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 213, loss: 0.029431170783936977\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 214, loss: 0.029435876989737153\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 215, loss: 0.029439273464959115\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 216, loss: 0.029441448859870434\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 217, loss: 0.02944255922921002\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 218, loss: 0.029442662082146853\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 219, loss: 0.02944187802495435\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 220, loss: 0.02944024873431772\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 221, loss: 0.02943784632952884\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 222, loss: 0.029434760857839137\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 223, loss: 0.02943106251768768\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 224, loss: 0.029426727211102843\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 225, loss: 0.029421839863061905\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 226, loss: 0.029416470497380942\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 227, loss: 0.029410631163045764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 228, loss: 0.029404390777926892\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 229, loss: 0.029397716920357198\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 230, loss: 0.029390714829787612\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 231, loss: 0.029383390035945922\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 232, loss: 0.0293757165200077\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 233, loss: 0.0293677628505975\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 234, loss: 0.029359580163145438\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 235, loss: 0.02935116644948721\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 236, loss: 0.029342538764467463\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 237, loss: 0.029333700047573075\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 238, loss: 0.029324694216484204\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 239, loss: 0.029315563588170335\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 240, loss: 0.029306245502084494\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 241, loss: 0.029296845983481035\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 242, loss: 0.02928727786638774\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 243, loss: 0.029277634719619527\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 244, loss: 0.02926790082710795\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 245, loss: 0.029258078517159447\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 246, loss: 0.02924821004853584\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 247, loss: 0.02923829641076736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 248, loss: 0.02922832194599323\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 249, loss: 0.02921827635145746\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 250, loss: 0.029208251071395352\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 251, loss: 0.029198161559179425\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 252, loss: 0.029188081854954362\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 253, loss: 0.029178013821365312\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 254, loss: 0.02916789209120907\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 255, loss: 0.029157818527892232\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 256, loss: 0.029147764580557123\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 257, loss: 0.029137699777493253\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 258, loss: 0.02912765380460769\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 259, loss: 0.029117655707523227\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 260, loss: 0.029107671143719926\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 261, loss: 0.029097748134518042\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 262, loss: 0.029087837698170915\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 263, loss: 0.029077991232043132\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 264, loss: 0.029068189847748727\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 265, loss: 0.0290583903552033\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 266, loss: 0.02904871344799176\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 267, loss: 0.029039057611953467\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 268, loss: 0.029029487632215023\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 269, loss: 0.029019941517617553\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 270, loss: 0.029010484169702977\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 271, loss: 0.029001084389165044\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 272, loss: 0.028991796832997352\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 273, loss: 0.028982505726162344\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 274, loss: 0.02897330158157274\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 275, loss: 0.028964196040760726\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 276, loss: 0.02895513566909358\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 277, loss: 0.028946173144504428\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 278, loss: 0.028937308758031577\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 279, loss: 0.02892847708426416\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 280, loss: 0.02891974471276626\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 281, loss: 0.028911088651511818\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 282, loss: 0.028902520367410034\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 283, loss: 0.028894025541376323\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 284, loss: 0.028885593870654702\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 285, loss: 0.02887728135101497\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 286, loss: 0.02886904706247151\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 287, loss: 0.028860876394901425\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 288, loss: 0.02885275922017172\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 289, loss: 0.028844812943134457\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 290, loss: 0.028836847108323127\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 291, loss: 0.02882901072734967\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 292, loss: 0.028821264335419983\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 293, loss: 0.02881357102887705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 294, loss: 0.028806000482290983\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 295, loss: 0.028798497223760933\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 296, loss: 0.028791062533855438\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 297, loss: 0.028783718880731612\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 298, loss: 0.02877644164254889\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 299, loss: 0.02876927045872435\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 300, loss: 0.028762157715391368\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 301, loss: 0.028755126695614308\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 302, loss: 0.028748185373842716\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 303, loss: 0.028741319256369025\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 304, loss: 0.02873451163759455\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 305, loss: 0.02872782392660156\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 306, loss: 0.02872115810168907\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 307, loss: 0.028714593907352537\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 308, loss: 0.028708107711281627\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 309, loss: 0.02870168670779094\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 310, loss: 0.02869537629885599\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 311, loss: 0.02868906408548355\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 312, loss: 0.028682869393378496\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 313, loss: 0.028676742978859693\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 314, loss: 0.028670688450802118\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 315, loss: 0.028664683748502284\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 316, loss: 0.02865878929151222\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 317, loss: 0.028652923414483666\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 318, loss: 0.028647163708228618\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 319, loss: 0.028641432523727417\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 320, loss: 0.02863578574033454\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 321, loss: 0.02863017952768132\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 322, loss: 0.02862466312944889\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 323, loss: 0.028619194112252444\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 324, loss: 0.028613809263333678\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 325, loss: 0.02860845811665058\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 326, loss: 0.028603139624465257\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 327, loss: 0.02859795279800892\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 328, loss: 0.028592782618943602\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 329, loss: 0.028587675013113767\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 330, loss: 0.028582622297108173\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 331, loss: 0.028577660967130214\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 332, loss: 0.028572692710440606\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 333, loss: 0.028567842207849026\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 334, loss: 0.028562977677211165\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 335, loss: 0.02855820389231667\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 336, loss: 0.028553517069667578\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 337, loss: 0.028548864123877138\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 338, loss: 0.028544234111905098\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 339, loss: 0.028539694205392152\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 340, loss: 0.02853517112089321\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 341, loss: 0.0285307252779603\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 342, loss: 0.028526293870527297\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 343, loss: 0.028521929867565632\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 344, loss: 0.02851762023055926\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 345, loss: 0.02851338923210278\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 346, loss: 0.028509160794783384\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 347, loss: 0.028505004942417145\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 348, loss: 0.028500901244115084\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 349, loss: 0.028496822982560843\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 350, loss: 0.028492804907727987\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 351, loss: 0.028488842479418963\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 352, loss: 0.02848490868927911\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 353, loss: 0.028481026936788112\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 354, loss: 0.028477192856371403\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 355, loss: 0.02847344893962145\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 356, loss: 0.028469676210079342\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 357, loss: 0.02846602298086509\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 358, loss: 0.028462357819080353\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 359, loss: 0.028458763379603624\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 360, loss: 0.028455253050196916\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 361, loss: 0.028451718215364963\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 362, loss: 0.02844825986539945\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 363, loss: 0.028444874507840723\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 364, loss: 0.028441531991120428\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 365, loss: 0.028438206354621798\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 366, loss: 0.028434973035473377\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 367, loss: 0.028431721962988377\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 368, loss: 0.028428573335986584\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 369, loss: 0.02842547104228288\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 370, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 371, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 372, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 373, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 374, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 375, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 376, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 377, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 378, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 379, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 380, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 381, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 382, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 383, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 384, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 385, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 386, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 387, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 388, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 389, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 390, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 391, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 392, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 393, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 394, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 395, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 396, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 397, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 398, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 399, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 400, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 401, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 402, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 403, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 404, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 405, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 406, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 407, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 408, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 409, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 410, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 411, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 412, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 413, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 414, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 415, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 416, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 417, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 418, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 419, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 420, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 421, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 422, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 423, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 424, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 425, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 426, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 427, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 428, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 429, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 430, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 431, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 432, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 433, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 434, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 435, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 436, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 437, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 438, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 439, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 440, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 441, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 442, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 443, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 444, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 445, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 446, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 447, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 448, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 449, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 450, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 451, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 452, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 453, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 454, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 455, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 456, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 457, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 458, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 459, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 460, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 461, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 462, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 463, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 464, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 465, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 466, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 467, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 468, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 469, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 470, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 471, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 472, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 473, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 474, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 475, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 476, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 477, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 478, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 479, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 480, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 481, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 482, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 483, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 484, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 485, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 486, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 487, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 488, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 489, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 490, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 491, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 492, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 493, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 494, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 495, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 496, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 497, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 498, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "Epoch 499, loss: nan\n",
            "Test_acc: 0.36666666666666664\n",
            "--------------------------\n",
            "total_time 6.4246602058410645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AoypxRCz0IrY",
        "outputId": "8fcf3ba9-ea3a-40b5-f0c5-99216e7e05c4"
      },
      "source": [
        "# p40_adam.py\n",
        "\n",
        "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
        "\n",
        "# 导入所需模块\n",
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time  ##1##\n",
        "\n",
        "# 导入数据，分别为输入特征和标签\n",
        "x_data = datasets.load_iris().data\n",
        "y_data = datasets.load_iris().target\n",
        "\n",
        "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
        "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
        "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
        "np.random.shuffle(x_data)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y_data)\n",
        "tf.random.set_seed(116)\n",
        "\n",
        "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
        "x_train = x_data[:-30]\n",
        "y_train = y_data[:-30]\n",
        "x_test = x_data[-30:]\n",
        "y_test = y_data[-30:]\n",
        "\n",
        "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "x_test = tf.cast(x_test, tf.float32)\n",
        "\n",
        "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
        "# 用tf.Variable()标记参数可训练\n",
        "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
        "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
        "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n",
        "\n",
        "lr = 0.1  # 学习率为0.1\n",
        "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
        "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
        "epoch = 500  # 循环500轮\n",
        "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
        "\n",
        "##########################################################################\n",
        "m_w, m_b = 0, 0\n",
        "v_w, v_b = 0, 0\n",
        "beta1, beta2 = 0.9, 0.999\n",
        "delta_w, delta_b = 0, 0\n",
        "global_step = 0\n",
        "##########################################################################\n",
        "\n",
        "# 训练部分\n",
        "now_time = time.time()  ##2##\n",
        "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
        "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
        " ##########################################################################       \n",
        "        global_step += 1\n",
        " ##########################################################################       \n",
        "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
        "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
        "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
        "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
        "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
        "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
        "        # 计算loss对各个参数的梯度\n",
        "        grads = tape.gradient(loss, [w1, b1])\n",
        "\n",
        "##########################################################################\n",
        " # adam\n",
        "        m_w = beta1 * m_w + (1 - beta1) * grads[0]\n",
        "        m_b = beta1 * m_b + (1 - beta1) * grads[1]\n",
        "        v_w = beta2 * v_w + (1 - beta2) * tf.square(grads[0])\n",
        "        v_b = beta2 * v_b + (1 - beta2) * tf.square(grads[1])\n",
        "\n",
        "        m_w_correction = m_w / (1 - tf.pow(beta1, int(global_step)))\n",
        "        m_b_correction = m_b / (1 - tf.pow(beta1, int(global_step)))\n",
        "        v_w_correction = v_w / (1 - tf.pow(beta2, int(global_step)))\n",
        "        v_b_correction = v_b / (1 - tf.pow(beta2, int(global_step)))\n",
        "\n",
        "        w1.assign_sub(lr * m_w_correction / tf.sqrt(v_w_correction))\n",
        "        b1.assign_sub(lr * m_b_correction / tf.sqrt(v_b_correction))\n",
        "##########################################################################\n",
        "\n",
        "    # 每个epoch，打印loss信息\n",
        "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
        "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
        "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
        "\n",
        "    # 测试部分\n",
        "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
        "    total_correct, total_number = 0, 0\n",
        "    for x_test, y_test in test_db:\n",
        "        # 使用更新后的参数进行预测\n",
        "        y = tf.matmul(x_test, w1) + b1\n",
        "        y = tf.nn.softmax(y)\n",
        "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
        "        # 将pred转换为y_test的数据类型\n",
        "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
        "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
        "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
        "        # 将每个batch的correct数加起来\n",
        "        correct = tf.reduce_sum(correct)\n",
        "        # 将所有batch中的correct数加起来\n",
        "        total_correct += int(correct)\n",
        "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
        "        total_number += x_test.shape[0]\n",
        "    # 总的准确率等于total_correct/total_number\n",
        "    acc = total_correct / total_number\n",
        "    test_acc.append(acc)\n",
        "    print(\"Test_acc:\", acc)\n",
        "    print(\"--------------------------\")\n",
        "total_time = time.time() - now_time  ##3##\n",
        "print(\"total_time\", total_time)  ##4##\n",
        "\n",
        "# 绘制 loss 曲线\n",
        "plt.title('Loss Function Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Loss')  # y轴变量名称\n",
        "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
        "plt.legend()  # 画出曲线图标\n",
        "plt.show()  # 画出图像\n",
        "\n",
        "# 绘制 Accuracy 曲线\n",
        "plt.title('Acc Curve')  # 图片标题\n",
        "plt.xlabel('Epoch')  # x轴变量名称\n",
        "plt.ylabel('Acc')  # y轴变量名称\n",
        "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 请将loss曲线、ACC曲线、total_time记录到 class2\\优化器对比.docx  对比各优化器收敛情况"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 0.21984169632196426\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 1, loss: 0.14480622299015522\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 2, loss: 0.10274341888725758\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 3, loss: 0.08922167494893074\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 4, loss: 0.0860079163685441\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 5, loss: 0.06994976568967104\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 6, loss: 0.06724478863179684\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 7, loss: 0.061045446433126926\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 8, loss: 0.05573806166648865\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 9, loss: 0.054052925668656826\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 10, loss: 0.0490919379517436\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 11, loss: 0.048258728347718716\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 12, loss: 0.04458608292043209\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 13, loss: 0.04371033748611808\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 14, loss: 0.04151799250394106\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 15, loss: 0.04042437206953764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 16, loss: 0.03921917639672756\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 17, loss: 0.03770230803638697\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 18, loss: 0.0374674373306334\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 19, loss: 0.03545612562447786\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 20, loss: 0.03618236118927598\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 21, loss: 0.033532270696014166\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 22, loss: 0.035104355309158564\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 23, loss: 0.03179900534451008\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 24, loss: 0.03405485488474369\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 25, loss: 0.030265103559941053\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 26, loss: 0.032883827574551105\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 27, loss: 0.02898176060989499\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 28, loss: 0.03153967252001166\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 29, loss: 0.028038084506988525\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 30, loss: 0.030121189542114735\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 31, loss: 0.027460415847599506\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 32, loss: 0.028777138330042362\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 33, loss: 0.027132836636155844\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 34, loss: 0.027615349739789963\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 35, loss: 0.026862101163715124\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 36, loss: 0.026687222998589277\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 37, loss: 0.026502934750169516\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 38, loss: 0.025996240321546793\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 39, loss: 0.026023716665804386\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 40, loss: 0.025497335009276867\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 41, loss: 0.025481844786554575\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 42, loss: 0.025107065215706825\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 43, loss: 0.024957625661045313\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 44, loss: 0.024743789341300726\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 45, loss: 0.02450238959863782\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 46, loss: 0.02436817344278097\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 47, loss: 0.024121187161654234\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 48, loss: 0.02398699033074081\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 49, loss: 0.023787254700437188\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 50, loss: 0.023625548230484128\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 51, loss: 0.023471767315641046\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 52, loss: 0.023299255408346653\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 53, loss: 0.023163850186392665\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 54, loss: 0.023004945600405335\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 55, loss: 0.022868593456223607\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 56, loss: 0.022730694385245442\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 57, loss: 0.02259322814643383\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 58, loss: 0.022468629758805037\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 59, loss: 0.022338305367156863\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 60, loss: 0.022218436701223254\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 61, loss: 0.02209913171827793\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 62, loss: 0.021982432110235095\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 63, loss: 0.021871638484299183\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 64, loss: 0.021760673727840185\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 65, loss: 0.02165489736944437\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 66, loss: 0.021550960838794708\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 67, loss: 0.02144931862130761\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 68, loss: 0.021351237781345844\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 69, loss: 0.021254501538351178\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 70, loss: 0.021160792326554656\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 71, loss: 0.021069135749712586\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 72, loss: 0.020979412831366062\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 73, loss: 0.0208921586163342\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 74, loss: 0.020806540036574006\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 75, loss: 0.02072301134467125\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 76, loss: 0.020641349721699953\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 77, loss: 0.020561330253258348\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 78, loss: 0.02048318716697395\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 79, loss: 0.02040658425539732\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 80, loss: 0.020331617211923003\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 81, loss: 0.020258212694898248\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 82, loss: 0.020186258712783456\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 83, loss: 0.020115776918828487\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 84, loss: 0.020046672085300088\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 85, loss: 0.01997891068458557\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 86, loss: 0.019912459421902895\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 87, loss: 0.019847265677526593\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 88, loss: 0.01978330174461007\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 89, loss: 0.019720508717000484\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 90, loss: 0.019658863777294755\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 91, loss: 0.019598338287323713\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 92, loss: 0.019538882421329618\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 93, loss: 0.019480486633256078\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 94, loss: 0.019423092249780893\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 95, loss: 0.019366696942597628\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 96, loss: 0.019311251817271113\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 97, loss: 0.01925673708319664\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 98, loss: 0.019203123170882463\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 99, loss: 0.019150403328239918\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 100, loss: 0.01909852074459195\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 101, loss: 0.019047490321099758\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 102, loss: 0.01899725291877985\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 103, loss: 0.018947813427075744\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 104, loss: 0.018899130634963512\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 105, loss: 0.01885121059603989\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 106, loss: 0.018804014893248677\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 107, loss: 0.01875753398053348\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 108, loss: 0.018711725482717156\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 109, loss: 0.018666616873815656\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 110, loss: 0.018622152972966433\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 111, loss: 0.018578326562419534\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 112, loss: 0.01853514788672328\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 113, loss: 0.01849256339482963\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 114, loss: 0.018450587056577206\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 115, loss: 0.018409185810014606\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 116, loss: 0.018368361750617623\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 117, loss: 0.018328096019104123\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 118, loss: 0.01828836463391781\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 119, loss: 0.018249177373945713\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 120, loss: 0.018210511654615402\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 121, loss: 0.01817234978079796\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 122, loss: 0.018134690588340163\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 123, loss: 0.01809750869870186\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 124, loss: 0.01806082366965711\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 125, loss: 0.018024591030552983\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 126, loss: 0.017988818231970072\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 127, loss: 0.017953493632376194\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 128, loss: 0.01791860954836011\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 129, loss: 0.0178841610904783\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 130, loss: 0.017850114032626152\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 131, loss: 0.017816500971093774\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 132, loss: 0.017783280927687883\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 133, loss: 0.017750468105077744\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 134, loss: 0.01771803293377161\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 135, loss: 0.01768599427305162\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 136, loss: 0.017654319060966372\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 137, loss: 0.01762300613336265\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 138, loss: 0.017592077376320958\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 139, loss: 0.017561479937285185\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 140, loss: 0.017531235935166478\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 141, loss: 0.017501337453722954\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 142, loss: 0.017471772152930498\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 143, loss: 0.017442531185224652\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 144, loss: 0.017413605004549026\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 145, loss: 0.017385017592459917\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 146, loss: 0.017356736352667212\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 147, loss: 0.01732873427681625\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 148, loss: 0.017301081912592053\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 149, loss: 0.017273690551519394\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 150, loss: 0.01724658254534006\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 151, loss: 0.017219797242432833\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 152, loss: 0.01719326456077397\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 153, loss: 0.017167018493637443\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 154, loss: 0.017141049727797508\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 155, loss: 0.0171153349801898\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 156, loss: 0.017089889151975513\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 157, loss: 0.01706470805220306\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 158, loss: 0.0170397802721709\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 159, loss: 0.017015095567330718\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 160, loss: 0.016990663250908256\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 161, loss: 0.016966479364782572\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 162, loss: 0.016942528542131186\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 163, loss: 0.016918811248615384\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 164, loss: 0.016895328415557742\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 165, loss: 0.016872070729732513\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 166, loss: 0.016849046805873513\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 167, loss: 0.01682624756358564\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 168, loss: 0.01680366159416735\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 169, loss: 0.016781280282884836\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 170, loss: 0.016759126912802458\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 171, loss: 0.016737165860831738\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 172, loss: 0.016715419944375753\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 173, loss: 0.016693867975845933\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 174, loss: 0.016672530211508274\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 175, loss: 0.016651400132104754\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 176, loss: 0.016630436293780804\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 177, loss: 0.01660967874340713\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 178, loss: 0.016589110484346747\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 179, loss: 0.016568719875067472\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 180, loss: 0.016548522282391787\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 181, loss: 0.016528504434973\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 182, loss: 0.016508661676198244\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 183, loss: 0.01648900005966425\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 184, loss: 0.016469506081193686\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 185, loss: 0.016450192779302597\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 186, loss: 0.01643104455433786\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 187, loss: 0.016412060242146254\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 188, loss: 0.01639324170537293\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 189, loss: 0.016374599654227495\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 190, loss: 0.016356092412024736\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 191, loss: 0.016337771899998188\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 192, loss: 0.016319590155035257\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 193, loss: 0.016301556024700403\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 194, loss: 0.01628370233811438\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 195, loss: 0.016265965066850185\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 196, loss: 0.016248396830633283\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 197, loss: 0.01623098086565733\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 198, loss: 0.016213684575632215\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 199, loss: 0.016196554759517312\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 200, loss: 0.01617956254631281\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 201, loss: 0.016162707237526774\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 202, loss: 0.01614597998559475\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 203, loss: 0.016129409661516547\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 204, loss: 0.01611294597387314\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 205, loss: 0.016096648294478655\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 206, loss: 0.016080466099083424\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 207, loss: 0.016064401250332594\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 208, loss: 0.016048480523750186\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 209, loss: 0.0160326911136508\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 210, loss: 0.016017003217712045\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 211, loss: 0.016001460142433643\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 212, loss: 0.01598603744059801\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 213, loss: 0.01597071858122945\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 214, loss: 0.015955533366650343\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 215, loss: 0.015940478770062327\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 216, loss: 0.01592551078647375\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 217, loss: 0.015910682501271367\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 218, loss: 0.015895956195890903\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 219, loss: 0.015881337458267808\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 220, loss: 0.015866851899772882\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 221, loss: 0.015852445270866156\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 222, loss: 0.015838172053918242\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 223, loss: 0.01582400966435671\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 224, loss: 0.01580992480739951\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 225, loss: 0.01579597545787692\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 226, loss: 0.01578212366439402\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 227, loss: 0.01576835778541863\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 228, loss: 0.01575471949763596\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 229, loss: 0.01574115641415119\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 230, loss: 0.01572770904749632\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 231, loss: 0.015714365523308516\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 232, loss: 0.015701097203418612\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 233, loss: 0.01568794180639088\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 234, loss: 0.015674882102757692\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 235, loss: 0.01566190691664815\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 236, loss: 0.015649033477529883\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 237, loss: 0.01563624874688685\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 238, loss: 0.015623553656041622\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 239, loss: 0.015610957983881235\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 240, loss: 0.015598439611494541\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 241, loss: 0.015586017863824964\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 242, loss: 0.01557368936482817\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 243, loss: 0.01556142105255276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 244, loss: 0.015549278585240245\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 245, loss: 0.015537197585217655\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 246, loss: 0.015525195631198585\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 247, loss: 0.015513293561525643\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 248, loss: 0.015501459478400648\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 249, loss: 0.015489711542613804\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 250, loss: 0.015478046494536102\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 251, loss: 0.015466457465663552\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 252, loss: 0.015454947832040489\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 253, loss: 0.015443521784618497\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 254, loss: 0.015432172920554876\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 255, loss: 0.015420895186252892\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 256, loss: 0.015409698942676187\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 257, loss: 0.015398562652990222\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 258, loss: 0.015387522871606052\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 259, loss: 0.015376549796201289\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 260, loss: 0.015365648199804127\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 261, loss: 0.015354806906543672\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 262, loss: 0.0153440524591133\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 263, loss: 0.015333377639763057\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 264, loss: 0.015322740306146443\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 265, loss: 0.015312199830077589\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 266, loss: 0.015301716513931751\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 267, loss: 0.015291304211132228\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 268, loss: 0.015280962106771767\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 269, loss: 0.015270686824806035\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 270, loss: 0.01526046812068671\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 271, loss: 0.01525033637881279\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 272, loss: 0.015240254229865968\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 273, loss: 0.015230232267640531\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 274, loss: 0.015220287488773465\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 275, loss: 0.01521038741338998\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 276, loss: 0.015200567664578557\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 277, loss: 0.015190808451734483\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 278, loss: 0.015181108727119863\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 279, loss: 0.015171458711847663\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 280, loss: 0.015161881688982248\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 281, loss: 0.015152366133406758\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 282, loss: 0.015142893535085022\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 283, loss: 0.01513349695596844\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 284, loss: 0.015124148107133806\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 285, loss: 0.015114850946702063\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 286, loss: 0.015105648315511644\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 287, loss: 0.01509644917678088\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 288, loss: 0.015087346429936588\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 289, loss: 0.015078279771842062\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 290, loss: 0.015069274115376174\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 291, loss: 0.01506031968165189\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 292, loss: 0.015051420661620796\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 293, loss: 0.015042576822452247\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 294, loss: 0.015033778385259211\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 295, loss: 0.015025053871795535\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 296, loss: 0.015016354154795408\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 297, loss: 0.015007729874923825\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 298, loss: 0.014999142033047974\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 299, loss: 0.01499060564674437\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 300, loss: 0.014982124674133956\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 301, loss: 0.01497369003482163\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 302, loss: 0.014965310343541205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 303, loss: 0.014956981525756419\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 304, loss: 0.014948697527870536\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 305, loss: 0.01494044961873442\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 306, loss: 0.014932271908037364\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 307, loss: 0.014924131683073938\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 308, loss: 0.014916034764610231\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 309, loss: 0.014907981385476887\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 310, loss: 0.014899998088367283\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 311, loss: 0.014892028062604368\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 312, loss: 0.0148841222980991\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 313, loss: 0.01487625960726291\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 314, loss: 0.014868436031974852\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 315, loss: 0.014860658906400204\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 316, loss: 0.014852939289994538\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 317, loss: 0.014845235156826675\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 318, loss: 0.01483759912662208\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 319, loss: 0.01482999895233661\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 320, loss: 0.01482243335340172\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 321, loss: 0.014814924099482596\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 322, loss: 0.014807450934313238\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 323, loss: 0.014800020260736346\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 324, loss: 0.014792610658332705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 325, loss: 0.014785276493057609\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 326, loss: 0.014777957694604993\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 327, loss: 0.014770684530958533\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 328, loss: 0.01476346084382385\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 329, loss: 0.014756261487491429\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 330, loss: 0.014749116962775588\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 331, loss: 0.014742008876055479\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 332, loss: 0.014734930591657758\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 333, loss: 0.01472788758110255\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 334, loss: 0.014720902196131647\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 335, loss: 0.014713926357217133\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 336, loss: 0.014707017107866704\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 337, loss: 0.014700125786475837\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 338, loss: 0.0146932682255283\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 339, loss: 0.014686472015455365\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 340, loss: 0.014679686049930751\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 341, loss: 0.014672945020720363\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 342, loss: 0.01466625218745321\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 343, loss: 0.01465957670006901\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 344, loss: 0.014652944635599852\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 345, loss: 0.014646340045146644\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 346, loss: 0.014639781205914915\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 347, loss: 0.014633245766162872\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 348, loss: 0.014626753982156515\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 349, loss: 0.014620290836319327\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 350, loss: 0.014613856328651309\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 351, loss: 0.014607469667680562\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 352, loss: 0.01460110698826611\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 353, loss: 0.014594772132113576\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 354, loss: 0.014588485355488956\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 355, loss: 0.014582208590582013\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 356, loss: 0.01457598665729165\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 357, loss: 0.014569775550626218\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 358, loss: 0.014563611359335482\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 359, loss: 0.014557466027326882\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 360, loss: 0.014551367377862334\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 361, loss: 0.014545284444466233\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 362, loss: 0.014539249474182725\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 363, loss: 0.014533229754306376\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 364, loss: 0.014527245191857219\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 365, loss: 0.014521296485327184\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 366, loss: 0.014515357906930149\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 367, loss: 0.014509467058815062\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 368, loss: 0.014503604732453823\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 369, loss: 0.014497758937068284\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 370, loss: 0.014491962036117911\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 371, loss: 0.014486183528788388\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 372, loss: 0.014480433543212712\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 373, loss: 0.014474707306362689\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 374, loss: 0.014469014713540673\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 375, loss: 0.014463339583016932\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 376, loss: 0.014457702403888106\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 377, loss: 0.01445209316443652\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 378, loss: 0.014446515473537147\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 379, loss: 0.014440940576605499\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 380, loss: 0.01443541853222996\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 381, loss: 0.014429921982809901\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 382, loss: 0.014424434048123658\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 383, loss: 0.014418994542211294\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 384, loss: 0.014413560391403735\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 385, loss: 0.014408161281608045\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 386, loss: 0.014402795233763754\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 387, loss: 0.014397437567822635\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 388, loss: 0.014392125885933638\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 389, loss: 0.014386822585947812\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 390, loss: 0.01438155653886497\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 391, loss: 0.014376309118233621\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 392, loss: 0.014371077879332006\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 393, loss: 0.014365883311256766\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 394, loss: 0.014360731118358672\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 395, loss: 0.01435555296484381\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 396, loss: 0.014350437792018056\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 397, loss: 0.01434535428415984\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 398, loss: 0.014340260997414589\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 399, loss: 0.014335198677144945\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 400, loss: 0.014330184319987893\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 401, loss: 0.014325169147923589\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 402, loss: 0.014320177142508328\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 403, loss: 0.014315232983790338\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 404, loss: 0.014310286031104624\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 405, loss: 0.014305364456959069\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 406, loss: 0.014300483162514865\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 407, loss: 0.01429560431279242\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 408, loss: 0.014290759456343949\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 409, loss: 0.014285926939919591\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 410, loss: 0.014281129348091781\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 411, loss: 0.014276353642344475\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 412, loss: 0.014271580963395536\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 413, loss: 0.01426683843601495\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 414, loss: 0.014262120821513236\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 415, loss: 0.014257427887059748\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 416, loss: 0.014252753811888397\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 417, loss: 0.014248087187297642\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 418, loss: 0.014243460143916309\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 419, loss: 0.014238846837542951\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 420, loss: 0.014234247733838856\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 421, loss: 0.014229675522074103\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 422, loss: 0.014225115766748786\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 423, loss: 0.01422058918979019\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 424, loss: 0.014216074021533132\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 425, loss: 0.014211566653102636\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 426, loss: 0.014207112486474216\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 427, loss: 0.01420265540946275\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 428, loss: 0.014198210556060076\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 429, loss: 0.014193799230270088\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 430, loss: 0.01418940897565335\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 431, loss: 0.01418502617161721\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 432, loss: 0.014180655125528574\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 433, loss: 0.014176334836520255\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 434, loss: 0.014171996619552374\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 435, loss: 0.014167705085128546\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 436, loss: 0.014163424028083682\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 437, loss: 0.014159152167849243\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 438, loss: 0.014154900913126767\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 439, loss: 0.014150675968267024\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 440, loss: 0.014146464294753969\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 441, loss: 0.01414227404166013\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 442, loss: 0.014138094848021865\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 443, loss: 0.014133933349512517\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 444, loss: 0.014129789196886122\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 445, loss: 0.01412566821090877\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 446, loss: 0.014121566666290164\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 447, loss: 0.0141174818854779\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 448, loss: 0.014113405486568809\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 449, loss: 0.014109352021478117\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 450, loss: 0.014105310547165573\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 451, loss: 0.01410129142459482\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 452, loss: 0.01409728650469333\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 453, loss: 0.014093304402194917\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 454, loss: 0.014089327771216631\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 455, loss: 0.014085379778407514\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 456, loss: 0.01408143900334835\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 457, loss: 0.014077511499635875\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 458, loss: 0.014073612983338535\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 459, loss: 0.014069716562516987\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 460, loss: 0.014065847732126713\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 461, loss: 0.014061983674764633\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 462, loss: 0.014058151165954769\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 463, loss: 0.014054323313757777\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 464, loss: 0.01405050395987928\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 465, loss: 0.014046715456061065\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 466, loss: 0.01404293265659362\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 467, loss: 0.014039159403182566\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 468, loss: 0.014035413158126175\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 469, loss: 0.014031682047061622\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 470, loss: 0.014027960714884102\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 471, loss: 0.014024260453879833\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 472, loss: 0.014020562404766679\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 473, loss: 0.014016890083439648\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 474, loss: 0.014013236272148788\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 475, loss: 0.014009582460857928\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 476, loss: 0.014005950302816927\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 477, loss: 0.014002347830682993\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 478, loss: 0.013998731621541083\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 479, loss: 0.01399514137301594\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 480, loss: 0.013991573941893876\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 481, loss: 0.013988003716804087\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 482, loss: 0.013984459335915744\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 483, loss: 0.013980936841107905\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 484, loss: 0.013977403054013848\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 485, loss: 0.01397390419151634\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 486, loss: 0.013970409170724452\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 487, loss: 0.013966933591291308\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 488, loss: 0.013963473727926612\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 489, loss: 0.013960012351162732\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 490, loss: 0.013956579263322055\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 491, loss: 0.013953157351352274\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 492, loss: 0.013949732878245413\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 493, loss: 0.013946345541626215\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 494, loss: 0.013942959369160235\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 495, loss: 0.013939585536718369\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 496, loss: 0.01393623382318765\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 497, loss: 0.013932879781350493\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 498, loss: 0.013929543900303543\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 499, loss: 0.013926230720244348\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "total_time 7.38898777961731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}